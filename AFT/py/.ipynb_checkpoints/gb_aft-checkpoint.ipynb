{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                                   as np\n",
    "import pandas                                  as pd\n",
    "import matplotlib.pyplot                       as plt\n",
    "import math\n",
    "import random\n",
    "from   sklearn                                 import ensemble\n",
    "from   sklearn                                 import datasets\n",
    "from   sklearn.utils                           import shuffle\n",
    "from   sklearn.metrics                         import mean_squared_error\n",
    "from   sklearn.datasets                        import load_boston\n",
    "from   sklearn.model_selection                 import cross_val_score\n",
    "from   sklearn.tree                            import DecisionTreeRegressor\n",
    "from   sklearn.model_selection                 import train_test_split\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stages\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stage\n",
    "from   abc                                     import abstractmethod\n",
    "from   scipy.special                           import expit\n",
    "from   sklearn.utils                           import check_array\n",
    "from   sklearn.tree._tree                      import DTYPE\n",
    "from   sklearn.tree._tree                      import TREE_LEAF\n",
    "from   scipy.special                           import logsumexp\n",
    "from   sklearn.utils                           import check_random_state\n",
    "from   sklearn.ensemble.gradient_boosting      import ZeroEstimator\n",
    "from   _aft_loss                               import loss, negative_gradient,hessian\n",
    "import sys\n",
    "import graphviz\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.externals.six import StringIO  \n",
    "from   IPython.display import Image  \n",
    "from   sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(object):\n",
    "    \n",
    "    \"\"\"Abstract base class for various loss functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        Number of classes\n",
    "    Attributes\n",
    "    ----------\n",
    "    K : int\n",
    "        The number of regression trees to be induced;\n",
    "        1 for regression and binary classification;\n",
    "        ``n_classes`` for multi-class classification.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    is_multi_class = False\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        self.K = n_classes\n",
    "\n",
    "    def init_estimator(self):\n",
    "        \n",
    "        \"\"\"Default ``init`` estimator for loss function. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, y_lower, y_higher,pred,dist,sigma,metrics,sample_weight=None):\n",
    "        \n",
    "        \"\"\"Compute the loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            True labels\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted labels\n",
    "        sample_weight : array-like, shape (n_samples,), optional\n",
    "            Sample weights.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def negative_gradient(self, y_lower, y_higher, pred,dist,sigma, **kargs):\n",
    "        \n",
    "        \"\"\"Compute the negative gradient.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            The target labels.\n",
    "        pred : array, shape (n_samples,)\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_terminal_regions(self, tree, X, y_lower,y_higher, residual, y_pred, dist, sigma, sample_weight, sample_mask, learning_rate=1.0):\n",
    "        \n",
    "        \"\"\"Update the terminal regions (=leaves) of the given tree and\n",
    "        updates the current predictions of the model. Traverses tree\n",
    "        and invokes template method '_update_terminal_region'.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : tree.Tree\n",
    "            The tree object.\n",
    "        X : array, shape (n, m)\n",
    "            The data array.\n",
    "        y : array, shape (n,)\n",
    "            The target labels.\n",
    "        residual : array, shape (n,)\n",
    "            The residuals (usually the negative gradient).\n",
    "        y_pred : array, shape (n,)\n",
    "            The predictions.\n",
    "        sample_weight : array, shape (n,)\n",
    "            The weight of each sample.\n",
    "        sample_mask : array, shape (n,)\n",
    "            The sample mask to be used.\n",
    "        learning_rate : float, default=0.1\n",
    "            learning rate shrinks the contribution of each tree by\n",
    "             ``learning_rate``.\n",
    "        k : int, default 0\n",
    "            The index of the estimator being updated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute leaf for each sample in ''X''.\n",
    "        \n",
    "        terminal_regions                      = tree.apply(X)\n",
    "\n",
    "        # mask all which are not in sample mask.\n",
    "        masked_terminal_regions               = terminal_regions.copy()\n",
    "        masked_terminal_regions[~sample_mask] = -1\n",
    "\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            \n",
    "            self._update_terminal_region(tree, masked_terminal_regions,\n",
    "                                         leaf, X, y_lower, y_higher, residual, y_pred,dist,sigma, sample_weight)\n",
    "        \n",
    "        y_pred = y_pred + (learning_rate* tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
    "        return y_pred\n",
    "\n",
    "    @abstractmethod\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual,pred,dist,sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Template method for updating terminal regions (=leaves).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroEstimator:\n",
    "    \n",
    "    \"\"\"An estimator that simply predicts zero.\n",
    "    .. deprecated:: 0.21\n",
    "        Using ``ZeroEstimator`` or ``init='zero'`` is deprecated in version\n",
    "        0.21 and will be removed in version 0.23.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y_lower,y_higher,X_val, y_lower_val,y_higher_val, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Fit the estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : numpy, shape (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary\n",
    "        sample_weight : array, shape (n_samples,)\n",
    "            Individual weights for each sample\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.issubdtype(y_lower.dtype, np.signedinteger):\n",
    "            # classification\n",
    "            self.n_classes = np.unique(y_lower).shape[0]\n",
    "            if self.n_classes == 2:\n",
    "                self.n_classes = 1\n",
    "        else:\n",
    "            # regression\n",
    "            self.n_classes = 1\n",
    "\n",
    "    def predict(self, X,X_val):\n",
    "        \"\"\"Predict labels\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : array, shape (n_samples,)\n",
    "            Returns predicted values.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, 'n_classes')\n",
    "\n",
    "        y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y.fill(0.0)\n",
    "        \n",
    "        y_val = np.empty((X_val.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y_val.fill(0.0)\n",
    "        return y,y_val\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFT(LossFunction):\n",
    "    \"\"\"Cox Partial Likelihood\"\"\"\n",
    "\n",
    "    def __call__(self, y_lower, y_higher, y_pred, dist, sigma, metrics, sample_weight=None):\n",
    "        \"\"\"Compute the partial likelihood of prediction ``y_pred`` and ``y``.\"\"\"\n",
    "        # TODO add support for sample weights\n",
    "        return loss(y_lower, y_higher, y_pred.ravel(),dist, sigma,metrics)\n",
    "\n",
    "    def negative_gradient(self, y_lower, y_higher, y_pred,dist,sigma,k=0,sample_weight=None, **kwargs):\n",
    "        \"\"\"Negative gradient of partial likelihood\n",
    "        Parameters\n",
    "        ---------\n",
    "        y : tuple, len = 2\n",
    "            First element is boolean event indicator and second element survival/censoring time.\n",
    "        y_pred : np.ndarray, shape=(n,):\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "        ret = negative_gradient(y_lower, y_higher, y_pred.ravel(), dist, sigma)\n",
    "        if sample_weight is not None:\n",
    "            ret *= sample_weight\n",
    "        return ret\n",
    "\n",
    "    def init_estimator(self):  # pragma: no cover\n",
    "        return ZeroEstimator()\n",
    "\n",
    "\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual, pred, dist, sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Least squares does not need to update terminal regions\"\"\"\n",
    "        \n",
    "        \"\"\"Make a single Newton-Raphson step.\n",
    "        our node estimate is given by:\n",
    "            sum(w * gradient) / sum(w * hessian)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        hess            = np.array(hessian(y_lower, y_higher, pred, dist, sigma))\n",
    "        terminal_region = np.where(terminal_regions == leaf)[0]\n",
    "        residual        = residual.take(terminal_region, axis=0)\n",
    "        hess            = hess.take(terminal_region, axis=0)\n",
    "        sample_weight   = sample_weight.take(terminal_region, axis=0)\n",
    "        pred            = pred.take(terminal_region, axis=0)\n",
    "\n",
    "        numerator       = np.sum(sample_weight * residual)\n",
    "        denominator     = np.sum(sample_weight * hess)\n",
    "\n",
    "        # prevents overflow and division by zero\n",
    "        \n",
    "        if abs(denominator) < 1e-2:\n",
    "            tree.value[leaf, 0, 0] = 0.0\n",
    "        else:\n",
    "            tree.value[leaf, 0, 0] = numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample_mask(n_total_samples,n_total_in_bag, random_state):\n",
    "    \n",
    "    \"\"\"Create a random sample mask where ``n_total_in_bag`` elements are set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_total_samples : int\n",
    "        The length of the resulting mask.\n",
    "\n",
    "    n_total_in_bag : int\n",
    "        The number of elements in the sample mask which are set to 1.\n",
    "        \n",
    "    random_state : np.RandomState\n",
    "        A numpy ``RandomState`` object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample_mask : np.ndarray, shape=[n_total_samples]\n",
    "         An ndarray where ``n_total_in_bag`` elements are set to ``True``\n",
    "         the others are ``False``.\n",
    "    \"\"\"\n",
    "    \n",
    "    #random_state = np.random.RandomState(random_state)\n",
    "    rand         = random_state.rand(n_total_samples)\n",
    "    sample_mask  = np.zeros((n_total_samples,), dtype=np.bool)\n",
    "    n_bagged     = 0\n",
    "    \n",
    "    for i in range(n_total_samples):\n",
    "        \n",
    "        if rand[i] * (n_total_samples - i) < (n_total_in_bag - n_bagged):\n",
    "            sample_mask[i] = 1\n",
    "            n_bagged += 1\n",
    "            \n",
    "    return sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Attributes and Parameters\n",
    "\n",
    "class BaseGradientBoosting():\n",
    "    \"\"\"Abstract base class for Gradient Boosting. \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, loss, learning_rate, n_estimators, criterion,\n",
    "                 min_samples_split, min_samples_leaf, min_weight_fraction_leaf,\n",
    "                 max_depth, min_impurity_decrease, min_impurity_split,\n",
    "                 init, subsample, max_features,\n",
    "                 random_state, alpha=0.9, verbose=0, max_leaf_nodes=None,\n",
    "                 warm_start=False, presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,metrics = 'logloss', Nestrov=False,dist='normal',sigma =1,\n",
    "                 tol=1e-4):\n",
    "        \n",
    "        #Initial = 1\n",
    "        self.n_estimators             = n_estimators + 1\n",
    "        self.learning_rate            = learning_rate\n",
    "        self.loss                     = loss\n",
    "        self.criterion                = criterion\n",
    "        self.min_samples_split        = min_samples_split\n",
    "        self.min_samples_leaf         = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.subsample                = subsample\n",
    "        self.max_features             = max_features\n",
    "        self.max_depth                = max_depth\n",
    "        self.min_impurity_decrease    = min_impurity_decrease\n",
    "        self.min_impurity_split       = min_impurity_split\n",
    "        self.init                     = init\n",
    "        self.random_state             = random_state\n",
    "        self.alpha                    = alpha\n",
    "        self.verbose                  = verbose\n",
    "        self.max_leaf_nodes           = max_leaf_nodes\n",
    "        self.warm_start               = warm_start\n",
    "        self.presort                  = presort\n",
    "        self.validation_fraction      = validation_fraction\n",
    "        self.n_iter_no_change         = n_iter_no_change\n",
    "        self.tol                      = tol\n",
    "        self.Nestrov                  = Nestrov\n",
    "        self.dist                     = dist\n",
    "        self.sigma                    = sigma\n",
    "        self.metrics                  = metrics\n",
    "\n",
    "    #Very Important loss class is defined here.\n",
    "    \n",
    "    def _init_state(self):\n",
    "        \n",
    "        self.estimators_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.fitted_        = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.prev_valid_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.train_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.valid_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.random_state   = check_random_state(self.random_state)\n",
    "        \n",
    "        if self.Nestrov == True:\n",
    "            \n",
    "            self.g_fitted_      = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.g_prev_valid_  = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.lamb           = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma          = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma[0]       = 1\n",
    "            \n",
    "            for i in range(1,self.n_estimators):\n",
    "                self.lamb[i] = 0.5*(1+math.sqrt(1+4*self.lamb[i-1]**2))\n",
    "                \n",
    "            for i in range(1,self.n_estimators-1):\n",
    "                self.gamma[i] = (1-self.lamb[i])/self.lamb[i+1]\n",
    "                \n",
    "        \n",
    "        #do oob?\n",
    "        if self.init is None:\n",
    "            self.init_ = self.loss_.init_estimator()\n",
    "        elif isinstance(self.init, str):\n",
    "            self.init_ = INIT_ESTIMATORS[self.init]()\n",
    "        else:\n",
    "            self.init_ = self.init\n",
    "\n",
    "        \"\"\"Initialize model state and allocate model state data structures. \"\"\"\n",
    "\n",
    "        if self.subsample < 1.0:\n",
    "            self.oob_improvement_ = np.zeros((self.n_estimators),dtype=np.float64)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        \n",
    "        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n",
    "        \n",
    "        \n",
    "        if self.loss == 'aft':\n",
    "            self.loss_ =  AFT(1)\n",
    "            \n",
    "\n",
    "    def _fit_stage(self, i, X, y_lower, y_higher, sample_weight, sample_mask, random_state):\n",
    "        \n",
    "        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n",
    "        \n",
    "        assert sample_mask.dtype == np.bool\n",
    "        loss       = self.loss_\n",
    "        #original_y = y_lower\n",
    "        pred       = np.zeros((X.shape[0],self.loss_.K),dtype=np.float64)\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "            if self.Nestrov == True:\n",
    "                pred[:,k] = self.g_fitted_[i-1,k]    \n",
    "            else:\n",
    "                pred[:,k] = self.fitted_[i-1,k]\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "   \n",
    "            residual = loss.negative_gradient(y_lower,y_higher,pred,self.dist,self.sigma,k=k,sample_weight=sample_weight)\n",
    "        \n",
    "            # induce regression tree on residuals\n",
    "            tree     = DecisionTreeRegressor(\n",
    "                                            criterion                 = self.criterion,\n",
    "                                            splitter                  = 'best',\n",
    "                                            max_depth                 = self.max_depth,\n",
    "                                            min_samples_split         = self.min_samples_split,\n",
    "                                            min_samples_leaf          = self.min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf  = self.min_weight_fraction_leaf,\n",
    "                                            min_impurity_decrease     = self.min_impurity_decrease,\n",
    "                                            min_impurity_split        = self.min_impurity_split,\n",
    "                                            max_features              = self.max_features,\n",
    "                                            max_leaf_nodes            = self.max_leaf_nodes,\n",
    "                                            random_state              = random_state,\n",
    "                                            presort                   = self.presort\n",
    "                                            )\n",
    "\n",
    "            if self.subsample < 1.0:\n",
    "                # no inplace multiplication!\n",
    "                sample_weight = sample_weight * sample_mask.astype(np.float64)\n",
    "                \n",
    "\n",
    "            tree.fit(X, residual, sample_weight=sample_weight)\n",
    "            \n",
    "            dot_data = StringIO()\n",
    "            export_graphviz(tree, out_file=dot_data,  \n",
    "                            filled=True, rounded=True,\n",
    "                            special_characters=True)\n",
    "            graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "            Image(graph.create_png())\n",
    "            filename = \"tree\"+str(i)+\".png\"\n",
    "            graph.write_png(filename)\n",
    "\n",
    "            # update tree leaves    \n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                y_pred                  = self.g_fitted_[i-1,k]\n",
    "                self.fitted_[i,k]       = loss.update_terminal_regions(tree.tree_, X, y_lower, y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "                self.g_fitted_[i,k]     = (1-self.gamma[i-1])*self.fitted_[i,k]+self.gamma[i-1]*self.fitted_[i-1,k]\n",
    "                \n",
    "            else:\n",
    "                y_pred            = self.fitted_[i-1,k]\n",
    "                self.fitted_[i,k] = loss.update_terminal_regions(tree.tree_, X, y_lower,y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "    \n",
    "    def n_features(self):\n",
    "        return self.n_features_\n",
    "    \n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        self.classes_    = np.unique(y)\n",
    "        self.n_classes_  = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def _fit_stages(self, X, y_lower, y_higher,sample_weight, random_state,\n",
    "                    X_val, y_lower_val, y_higher_val,sample_weight_val,begin_at_stage=0):\n",
    "        \n",
    "        \n",
    "        n_samples    = X.shape[0]\n",
    "        do_oob       = self.subsample < 1.0\n",
    "        sample_mask  = np.ones((n_samples, ), dtype=np.bool)\n",
    "        n_inbag      = max(1, int(self.subsample * n_samples))\n",
    "        loss_        = self.loss_\n",
    "        \n",
    "        # create one-hot label encoding\n",
    "        pred         = np.zeros((n_samples, self.loss_.K), dtype=np.float64)\n",
    "        pred_val     = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            pred[:,k] = self.fitted_[0,k]\n",
    "            pred_val[:,k] = self.prev_valid_[0,k]\n",
    "            \n",
    "        if do_oob:\n",
    "            \n",
    "            sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "            self.train_score_[0] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,self.metrics,sample_weight[sample_mask])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.train_score_[0] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,self.metrics,sample_weight)\n",
    "        self.valid_score_[0] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,self.metrics,sample_weight_val)\n",
    "\n",
    "        # perform boosting iterations\n",
    "        # validation loss performance\n",
    "        \n",
    "        for i in range(begin_at_stage, self.n_estimators):\n",
    "\n",
    "            # subsampling\n",
    "            if do_oob:\n",
    "                sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "                \n",
    "            # fit next stage of trees\n",
    "            self._fit_stage(i, X, y_lower,y_higher, sample_weight,sample_mask, random_state)\n",
    "\n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.g_prev_valid_[i-1,k].copy()\n",
    "                    \n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "\n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "                    \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.g_prev_valid_[i,k] = (1-self.gamma[i-1])*self.prev_valid_[i,k]+self.gamma[i-1]*self.prev_valid_[i-1,k]\n",
    "            else:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.prev_valid_[i-1,k].copy()\n",
    "\n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "\n",
    "            for k in range(self.loss_.K):\n",
    "                \n",
    "                pred[:,k] = self.fitted_[i,k]\n",
    "                pred_val[:,k] = self.prev_valid_[i,k]\n",
    "            \n",
    "            if do_oob:\n",
    "                self.train_score_[i] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,self.metrics,sample_weight[sample_mask])\n",
    "            else:\n",
    "                self.train_score_[i] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,self.metrics,sample_weight)\n",
    "   \n",
    "            self.valid_score_[i] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,self.metrics,sample_weight_val)\n",
    "    \n",
    "        return i + 1\n",
    "\n",
    "    \n",
    "    def fit(self, X, y_lower,y_higher, sample_weight=None):\n",
    "        \n",
    "        # Check input\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        #y_lower                     = self._validate_y(y_lower, sample_weight)\n",
    "        #y_higher                    = self._validate_y(y_higher, sample_weight)\n",
    "        X                           = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        sample_weight               = np.ones(n_samples, dtype=np.float32)\n",
    "        \n",
    "        X, X_val, y_lower, y_lower_val,y_higher,y_higher_val,sample_weight, sample_weight_val \\\n",
    "        = train_test_split(X, y_lower,y_higher,sample_weight,random_state=self.random_state,test_size=self.validation_fraction)\n",
    "        self._check_params()\n",
    "        self._init_state()\n",
    "\n",
    "        # fit initial model - FIXME make sample_weight optional\n",
    "        #For Binomial       - init_ = LogOddsEstimator\n",
    "        #For Multinomial    - init_ = PriorProbabilityEstimator\n",
    "\n",
    "        self.init_.fit(X, y_lower,y_higher, X_val, y_lower_val,y_higher_val, sample_weight)\n",
    "        # init predictions and update in the inplace self\n",
    "        initial_pred,initial_val_pred  = self.init_.predict(X,X_val)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            self.fitted_[0,k], self.prev_valid_[0,k]          = initial_pred[:,k],initial_val_pred[:,k]\n",
    "            if self.Nestrov == True:\n",
    "                self.g_fitted_[0,k], self.g_prev_valid_[0,k]  = initial_pred[:,k],initial_val_pred[:,k]\n",
    "\n",
    "        begin_at_stage = 1\n",
    "        # fit the boosting stages\n",
    "        \n",
    "        n_stages = self._fit_stages(X, y_lower,y_higher, sample_weight, self.random_state,\n",
    "                                    X_val, y_lower_val,y_higher_val, sample_weight_val,begin_at_stage)\n",
    "        # change shape of arrays after fit (early-stopping or additional ests)\n",
    "        self.n_estimators_ = n_stages\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _make_estimator(self, append=True):\n",
    "        # we don't need _make_estimator\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def _init_decision_function(self, X):\n",
    "        \n",
    "        \"\"\"Check input and compute prediction of ``init``. \"\"\"\n",
    "        #self._check_initialized()\n",
    "        #X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
    "                self.n_features_, X.shape[1]))\n",
    "        score = self.init_.predict(X).astype(np.float64)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _decision_function(self, X):\n",
    "        \n",
    "        # for use in inner loop, not raveling the output in single-class case,\n",
    "        # not doing input validation.\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        predict_stages(self.estimators_, X, self.learning_rate, score)\n",
    "        return score\n",
    "\n",
    "    def _staged_decision_function(self, X):\n",
    "        \n",
    "        #X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        for i in range(self.estimators_.shape[0]):\n",
    "            predict_stage(self.estimators_, i, X, self.learning_rate, score)\n",
    "            yield score.copy()\n",
    "    \n",
    "\n",
    "\n",
    "class GradientBoostingClassifier(BaseGradientBoosting):\n",
    "\n",
    "    _SUPPORTED_LOSS = ('survival')\n",
    "\n",
    "    def __init__(self, loss='aft', learning_rate=0.1, n_estimators=100,\n",
    "                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n",
    "                 max_depth=3, min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None, init=None,\n",
    "                 random_state=None, max_features=None, verbose=0,\n",
    "                 max_leaf_nodes=None, warm_start=False,\n",
    "                 presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,Nestrov=False,metrics = 'logloss',dist='normal',sigma=1,tol=1e-4):\n",
    "\n",
    "        super().__init__(\n",
    "            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "            criterion=criterion, min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth, init=init, subsample=subsample,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state, verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            warm_start=warm_start, presort=presort,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,Nestrov=Nestrov,metrics=metrics,\n",
    "            dist=dist,sigma=sigma,tol=tol)\n",
    "\n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        #check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        n_trim_classes = np.count_nonzero(np.bincount(y, sample_weight))\n",
    "        if n_trim_classes < 2:\n",
    "            raise ValueError(\"y contains %d class after sample_weight \"\n",
    "                             \"trimmed classes with zero weights, while a \"\n",
    "                             \"minimum of 2 classes are required.\"\n",
    "                             % n_trim_classes)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        score = self._decision_function(X)\n",
    "        if score.shape[1] == 1:\n",
    "            return score.ravel()\n",
    "        return score\n",
    "\n",
    "    #def staged_decision_function(self, X):\n",
    "    #    \n",
    "    #    yield from self._staged_decision_function(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        score     = self.decision_function(X)\n",
    "        decisions = self.loss_._score_to_decision(score)\n",
    "        return self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def staged_predict(self, X):\n",
    "       \n",
    "        for score in self._staged_decision_function(X):\n",
    "            decisions = self.loss_._score_to_decision(score)\n",
    "            yield self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        score = self.decision_function(X)\n",
    "        try:\n",
    "            return self.loss_._score_to_proba(score)\n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        proba = self.predict_proba(X)\n",
    "        return np.log(proba)\n",
    "\n",
    "    def staged_predict_proba(self, X):\n",
    "       \n",
    "        try:\n",
    "            for score in self._staged_decision_function(X):\n",
    "                yield self.loss_._score_to_proba(score)\n",
    "                \n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "def data_creation(file_name,K=5):\n",
    "    \n",
    "    df_train   = pd.read_csv(file_name)\n",
    "    y          = list(df_train['Y'])\n",
    "    req_cols   = [i for i in df_train.columns if i != 'Y']\n",
    "    X          = np.array(df_train[req_cols])\n",
    "    y_median   = np.percentile(y, 50) # return 50th percentile, e.g median.\n",
    "    bin_y      = list(map(lambda x : 0 if x < y_median else 1,y))\n",
    "\n",
    "    percentile = np.percentile(y, np.arange(0, 100, 100/K)) # deciles\n",
    "    multi_y    = list(map(lambda x : 0 if x >= percentile[0] and x< percentile[1] else 1 if x >= percentile[1] and x< percentile[2] else 2 if x >= percentile[2] and x< percentile[3] else 3,y))\n",
    "    \n",
    "    return X,y,bin_y,multi_y\n",
    "\n",
    "def chart_creation(gb,chart_title,chart_name):\n",
    "    \n",
    "    min_valid = round(np.min(gb.valid_score_),4)\n",
    "    min_train = round(np.min(gb.train_score_),4)\n",
    "    min_iter  = round(np.nanargmin(gb.valid_score_),0)\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "                    'Min Train = %.2f' % (min_train, ),\n",
    "                    'Min Valid = %.2f' % (min_valid, ),\n",
    "                    'Min Iter  = %.2f' % (min_iter, )))\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5,edgecolor=\"black\")\n",
    "    \n",
    "    fig,ax1       = plt.subplots()\n",
    "    ax2           = ax1.twinx()\n",
    "\n",
    "    ln1 = ax1.plot(gb.train_score_,color='blue',label='Training')\n",
    "    ln2 = ax2.plot(gb.valid_score_,color='orange',label='Validation')\n",
    "    \n",
    "    #ax1.axvline(x=np.nanargmin(gb.valid_score_),color='r')\n",
    "    #ax2.axhline(y=np.min(gb.valid_score_),color='b')\n",
    "    lns = ln1 + ln2\n",
    "    \n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of Iterations(Trees)\")\n",
    "    ax1.set_ylabel(\"Training Negative Likelihood(Loss)\")\n",
    "    ax2.set_ylabel(\"Validation Negative Likelihood(Loss)\")\n",
    "    #ax1.legend([\"Training\",\"Validation\"],loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax2.text(0.7, 0.90, textstr, transform=ax1.transAxes, fontsize=8,\n",
    "        verticalalignment='top', bbox=props)\n",
    "    plt.title(chart_title)\n",
    "    plt.show()\n",
    "    fig.savefig(chart_name)\n",
    "    \n",
    "def generate_result(X,y_lower,y_higher,param):\n",
    "    \n",
    "    gb_manual = GradientBoostingClassifier(**param)\n",
    "    gb_manual.fit(X,y_lower,y_higher)\n",
    "    \n",
    "    return gb_manual    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data     = pd.read_csv('simulate_survival_uncen.csv')\n",
    "    X        = data[['x1','x2','x3']]\n",
    "    y_lower  = data['left']\n",
    "    y_higher = data['right']\n",
    "\n",
    "    param    = {'n_estimators' : 5,'learning_rate': 0.01,'Nestrov' : False,'subsample': 0.5,'min_samples_split': 10,\n",
    "                 'max_depth': 2,'metrics':'logloss','dist':'normal','sigma':2,'random_state' : 0}\n",
    "\n",
    "    gb_manual = generate_result(X,y_lower,y_higher,param)\n",
    "    chart_creation(gb_manual,'Nesterov=False,Loss=Logloss,Data=Uncensored','Nesterov_False_Loss_Logloss_Data_Uncensored.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
