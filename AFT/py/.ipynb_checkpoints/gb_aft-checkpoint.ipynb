{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                                   as np\n",
    "import pandas                                  as pd\n",
    "import matplotlib.pyplot                       as plt\n",
    "import math\n",
    "import random\n",
    "from   sklearn                                 import ensemble\n",
    "from   sklearn                                 import datasets\n",
    "from   sklearn.utils                           import shuffle\n",
    "from   sklearn.metrics                         import mean_squared_error\n",
    "from   sklearn.datasets                        import load_boston\n",
    "from   sklearn.model_selection                 import cross_val_score\n",
    "from   sklearn.tree                            import DecisionTreeRegressor\n",
    "from   sklearn.model_selection                 import train_test_split\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stages\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stage\n",
    "from   abc                                     import abstractmethod\n",
    "from   scipy.special                           import expit\n",
    "from   sklearn.utils                           import check_array\n",
    "from   sklearn.tree._tree                      import DTYPE\n",
    "from   sklearn.tree._tree                      import TREE_LEAF\n",
    "from   scipy.special                           import logsumexp\n",
    "from   sklearn.utils                           import check_random_state\n",
    "from   sklearn.ensemble.gradient_boosting      import ZeroEstimator\n",
    "from   _aft_loss                               import loss, negative_gradient,hessian\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(object):\n",
    "    \n",
    "    \"\"\"Abstract base class for various loss functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        Number of classes\n",
    "    Attributes\n",
    "    ----------\n",
    "    K : int\n",
    "        The number of regression trees to be induced;\n",
    "        1 for regression and binary classification;\n",
    "        ``n_classes`` for multi-class classification.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    is_multi_class = False\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        self.K = n_classes\n",
    "\n",
    "    def init_estimator(self):\n",
    "        \n",
    "        \"\"\"Default ``init`` estimator for loss function. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, y_lower, y_higher,pred,dist,sigma, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Compute the loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            True labels\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted labels\n",
    "        sample_weight : array-like, shape (n_samples,), optional\n",
    "            Sample weights.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def negative_gradient(self, y_lower, y_higher, pred,dist,sigma, **kargs):\n",
    "        \n",
    "        \"\"\"Compute the negative gradient.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            The target labels.\n",
    "        pred : array, shape (n_samples,)\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_terminal_regions(self, tree, X, y_lower,y_higher, residual, y_pred, dist, sigma, sample_weight, sample_mask, learning_rate=1.0):\n",
    "        \n",
    "        \"\"\"Update the terminal regions (=leaves) of the given tree and\n",
    "        updates the current predictions of the model. Traverses tree\n",
    "        and invokes template method '_update_terminal_region'.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : tree.Tree\n",
    "            The tree object.\n",
    "        X : array, shape (n, m)\n",
    "            The data array.\n",
    "        y : array, shape (n,)\n",
    "            The target labels.\n",
    "        residual : array, shape (n,)\n",
    "            The residuals (usually the negative gradient).\n",
    "        y_pred : array, shape (n,)\n",
    "            The predictions.\n",
    "        sample_weight : array, shape (n,)\n",
    "            The weight of each sample.\n",
    "        sample_mask : array, shape (n,)\n",
    "            The sample mask to be used.\n",
    "        learning_rate : float, default=0.1\n",
    "            learning rate shrinks the contribution of each tree by\n",
    "             ``learning_rate``.\n",
    "        k : int, default 0\n",
    "            The index of the estimator being updated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute leaf for each sample in ''X''.\n",
    "        \n",
    "        terminal_regions                      = tree.apply(X)\n",
    "\n",
    "        # mask all which are not in sample mask.\n",
    "        masked_terminal_regions               = terminal_regions.copy()\n",
    "        masked_terminal_regions[~sample_mask] = -1\n",
    "\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            \n",
    "            self._update_terminal_region(tree, masked_terminal_regions,\n",
    "                                         leaf, X, y_lower, y_higher, residual, y_pred,dist,sigma, sample_weight)\n",
    "        \n",
    "        y_pred = y_pred + (learning_rate* tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
    "        return y_pred\n",
    "\n",
    "    @abstractmethod\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual,pred,dist,sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Template method for updating terminal regions (=leaves).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroEstimator:\n",
    "    \n",
    "    \"\"\"An estimator that simply predicts zero.\n",
    "    .. deprecated:: 0.21\n",
    "        Using ``ZeroEstimator`` or ``init='zero'`` is deprecated in version\n",
    "        0.21 and will be removed in version 0.23.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y_lower,y_higher,X_val, y_lower_val,y_higher_val, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Fit the estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : numpy, shape (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary\n",
    "        sample_weight : array, shape (n_samples,)\n",
    "            Individual weights for each sample\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.issubdtype(y_lower.dtype, np.signedinteger):\n",
    "            # classification\n",
    "            self.n_classes = np.unique(y_lower).shape[0]\n",
    "            if self.n_classes == 2:\n",
    "                self.n_classes = 1\n",
    "        else:\n",
    "            # regression\n",
    "            self.n_classes = 1\n",
    "\n",
    "    def predict(self, X,X_val):\n",
    "        \"\"\"Predict labels\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : array, shape (n_samples,)\n",
    "            Returns predicted values.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, 'n_classes')\n",
    "\n",
    "        y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y.fill(0.0)\n",
    "        \n",
    "        y_val = np.empty((X_val.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y_val.fill(0.0)\n",
    "        return y,y_val\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFT(LossFunction):\n",
    "    \"\"\"Cox Partial Likelihood\"\"\"\n",
    "\n",
    "    def __call__(self, y_lower, y_higher, y_pred, dist, sigma, sample_weight=None):\n",
    "        \"\"\"Compute the partial likelihood of prediction ``y_pred`` and ``y``.\"\"\"\n",
    "        # TODO add support for sample weights\n",
    "        return loss(y_lower, y_higher, y_pred.ravel(),dist, sigma)\n",
    "\n",
    "    def negative_gradient(self, y_lower, y_higher, y_pred,dist,sigma,k=0,sample_weight=None, **kwargs):\n",
    "        \"\"\"Negative gradient of partial likelihood\n",
    "        Parameters\n",
    "        ---------\n",
    "        y : tuple, len = 2\n",
    "            First element is boolean event indicator and second element survival/censoring time.\n",
    "        y_pred : np.ndarray, shape=(n,):\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "        ret = negative_gradient(y_lower, y_higher, y_pred.ravel(), dist, sigma)\n",
    "        if sample_weight is not None:\n",
    "            ret *= sample_weight\n",
    "        return ret\n",
    "\n",
    "    def init_estimator(self):  # pragma: no cover\n",
    "        return ZeroEstimator()\n",
    "\n",
    "\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual, pred, dist, sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Least squares does not need to update terminal regions\"\"\"\n",
    "        \n",
    "        \"\"\"Make a single Newton-Raphson step.\n",
    "        our node estimate is given by:\n",
    "            sum(w * gradient) / sum(w * hessian)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        hess            = np.array(hessian(y_lower, y_higher, pred, dist, sigma))\n",
    "        terminal_region = np.where(terminal_regions == leaf)[0]\n",
    "        residual        = residual.take(terminal_region, axis=0)\n",
    "        hess            = hess.take(terminal_region, axis=0)\n",
    "        sample_weight   = sample_weight.take(terminal_region, axis=0)\n",
    "        pred            = pred.take(terminal_region, axis=0)\n",
    "\n",
    "        numerator       = np.sum(sample_weight * residual)\n",
    "        denominator     = np.sum(sample_weight * hess)\n",
    "\n",
    "        # prevents overflow and division by zero\n",
    "        \n",
    "        if abs(denominator) < 1e-2:\n",
    "            tree.value[leaf, 0, 0] = 0.0\n",
    "        else:\n",
    "            tree.value[leaf, 0, 0] = numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample_mask(n_total_samples,n_total_in_bag, random_state):\n",
    "    \n",
    "    \"\"\"Create a random sample mask where ``n_total_in_bag`` elements are set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_total_samples : int\n",
    "        The length of the resulting mask.\n",
    "\n",
    "    n_total_in_bag : int\n",
    "        The number of elements in the sample mask which are set to 1.\n",
    "        \n",
    "    random_state : np.RandomState\n",
    "        A numpy ``RandomState`` object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample_mask : np.ndarray, shape=[n_total_samples]\n",
    "         An ndarray where ``n_total_in_bag`` elements are set to ``True``\n",
    "         the others are ``False``.\n",
    "    \"\"\"\n",
    "    \n",
    "    #random_state = np.random.RandomState(random_state)\n",
    "    rand         = random_state.rand(n_total_samples)\n",
    "    sample_mask  = np.zeros((n_total_samples,), dtype=np.bool)\n",
    "    n_bagged     = 0\n",
    "    \n",
    "    for i in range(n_total_samples):\n",
    "        \n",
    "        if rand[i] * (n_total_samples - i) < (n_total_in_bag - n_bagged):\n",
    "            sample_mask[i] = 1\n",
    "            n_bagged += 1\n",
    "            \n",
    "    return sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Attributes and Parameters\n",
    "\n",
    "class BaseGradientBoosting():\n",
    "    \"\"\"Abstract base class for Gradient Boosting. \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, loss, learning_rate, n_estimators, criterion,\n",
    "                 min_samples_split, min_samples_leaf, min_weight_fraction_leaf,\n",
    "                 max_depth, min_impurity_decrease, min_impurity_split,\n",
    "                 init, subsample, max_features,\n",
    "                 random_state, alpha=0.9, verbose=0, max_leaf_nodes=None,\n",
    "                 warm_start=False, presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None, Nestrov=False,dist='normal',sigma =1,\n",
    "                 tol=1e-4):\n",
    "        \n",
    "        #Initial = 1\n",
    "        self.n_estimators             = n_estimators + 1\n",
    "        self.learning_rate            = learning_rate\n",
    "        self.loss                     = loss\n",
    "        self.criterion                = criterion\n",
    "        self.min_samples_split        = min_samples_split\n",
    "        self.min_samples_leaf         = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.subsample                = subsample\n",
    "        self.max_features             = max_features\n",
    "        self.max_depth                = max_depth\n",
    "        self.min_impurity_decrease    = min_impurity_decrease\n",
    "        self.min_impurity_split       = min_impurity_split\n",
    "        self.init                     = init\n",
    "        self.random_state             = random_state\n",
    "        self.alpha                    = alpha\n",
    "        self.verbose                  = verbose\n",
    "        self.max_leaf_nodes           = max_leaf_nodes\n",
    "        self.warm_start               = warm_start\n",
    "        self.presort                  = presort\n",
    "        self.validation_fraction      = validation_fraction\n",
    "        self.n_iter_no_change         = n_iter_no_change\n",
    "        self.tol                      = tol\n",
    "        self.Nestrov                  = Nestrov\n",
    "        self.dist                     = dist\n",
    "        self.sigma                    = sigma\n",
    "\n",
    "    #Very Important loss class is defined here.\n",
    "    \n",
    "    def _init_state(self):\n",
    "        \n",
    "        self.estimators_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.fitted_        = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.prev_valid_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.train_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.valid_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.random_state   = check_random_state(self.random_state)\n",
    "        \n",
    "        if self.Nestrov == True:\n",
    "            \n",
    "            self.g_fitted_      = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.g_prev_valid_  = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.lamb           = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma          = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma[0]       = 1\n",
    "            \n",
    "            for i in range(1,self.n_estimators):\n",
    "                self.lamb[i] = 0.5*(1+math.sqrt(1+4*self.lamb[i-1]**2))\n",
    "                \n",
    "            for i in range(1,self.n_estimators-1):\n",
    "                self.gamma[i] = (1-self.lamb[i])/self.lamb[i+1]\n",
    "                \n",
    "        \n",
    "        #do oob?\n",
    "        if self.init is None:\n",
    "            self.init_ = self.loss_.init_estimator()\n",
    "        elif isinstance(self.init, str):\n",
    "            self.init_ = INIT_ESTIMATORS[self.init]()\n",
    "        else:\n",
    "            self.init_ = self.init\n",
    "\n",
    "        \"\"\"Initialize model state and allocate model state data structures. \"\"\"\n",
    "\n",
    "        if self.subsample < 1.0:\n",
    "            self.oob_improvement_ = np.zeros((self.n_estimators),dtype=np.float64)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        \n",
    "        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n",
    "        \n",
    "        \n",
    "        if self.loss == 'aft':\n",
    "            self.loss_ =  AFT(1)\n",
    "            \n",
    "\n",
    "    def _fit_stage(self, i, X, y_lower, y_higher, sample_weight, sample_mask, random_state):\n",
    "        \n",
    "        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n",
    "        \n",
    "        assert sample_mask.dtype == np.bool\n",
    "        loss       = self.loss_\n",
    "        #original_y = y_lower\n",
    "        pred       = np.zeros((X.shape[0],self.loss_.K),dtype=np.float64)\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "            if self.Nestrov == True:\n",
    "                pred[:,k] = self.g_fitted_[i-1,k]    \n",
    "            else:\n",
    "                pred[:,k] = self.fitted_[i-1,k]\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "   \n",
    "            residual = loss.negative_gradient(y_lower,y_higher,pred,self.dist,self.sigma,k=k,sample_weight=sample_weight)\n",
    "        \n",
    "            # induce regression tree on residuals\n",
    "            tree     = DecisionTreeRegressor(\n",
    "                                            criterion                 = self.criterion,\n",
    "                                            splitter                  = 'best',\n",
    "                                            max_depth                 = self.max_depth,\n",
    "                                            min_samples_split         = self.min_samples_split,\n",
    "                                            min_samples_leaf          = self.min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf  = self.min_weight_fraction_leaf,\n",
    "                                            min_impurity_decrease     = self.min_impurity_decrease,\n",
    "                                            min_impurity_split        = self.min_impurity_split,\n",
    "                                            max_features              = self.max_features,\n",
    "                                            max_leaf_nodes            = self.max_leaf_nodes,\n",
    "                                            random_state              = random_state,\n",
    "                                            presort                   = self.presort\n",
    "                                            )\n",
    "\n",
    "            if self.subsample < 1.0:\n",
    "                # no inplace multiplication!\n",
    "                sample_weight = sample_weight * sample_mask.astype(np.float64)\n",
    "                \n",
    "\n",
    "            tree.fit(X, residual, sample_weight=sample_weight)\n",
    "\n",
    "            # update tree leaves    \n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                y_pred                  = self.g_fitted_[i-1,k]\n",
    "                self.fitted_[i,k]       = loss.update_terminal_regions(tree.tree_, X, y_lower, y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "                self.g_fitted_[i,k]     = (1-self.gamma[i-1])*self.fitted_[i,k]+self.gamma[i-1]*self.fitted_[i-1,k]\n",
    "                \n",
    "            else:\n",
    "                y_pred            = self.fitted_[i-1,k]\n",
    "                self.fitted_[i,k] = loss.update_terminal_regions(tree.tree_, X, y_lower,y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "    \n",
    "    def n_features(self):\n",
    "        return self.n_features_\n",
    "    \n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        self.classes_    = np.unique(y)\n",
    "        self.n_classes_  = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def _fit_stages(self, X, y_lower, y_higher,sample_weight, random_state,\n",
    "                    X_val, y_lower_val, y_higher_val,sample_weight_val,begin_at_stage=0):\n",
    "        \n",
    "        \n",
    "        n_samples    = X.shape[0]\n",
    "        do_oob       = self.subsample < 1.0\n",
    "        sample_mask  = np.ones((n_samples, ), dtype=np.bool)\n",
    "        n_inbag      = max(1, int(self.subsample * n_samples))\n",
    "        loss_        = self.loss_\n",
    "        \n",
    "        # create one-hot label encoding\n",
    "        pred     = np.zeros((n_samples, self.loss_.K), dtype=np.float64)\n",
    "        pred_val = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            pred[:,k] = self.fitted_[0,k]\n",
    "            pred_val[:,k] = self.prev_valid_[0,k]\n",
    "            \n",
    "        if do_oob:\n",
    "            \n",
    "            sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "            self.train_score_[0] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,sample_weight[sample_mask])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.train_score_[0] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,sample_weight)\n",
    "            \n",
    "            \n",
    "        self.valid_score_[0] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,sample_weight_val)\n",
    "\n",
    "        # perform boosting iterations\n",
    "        # validation loss performance\n",
    "        \n",
    "        for i in range(begin_at_stage, self.n_estimators):\n",
    "\n",
    "            # subsampling\n",
    "            if do_oob:\n",
    "                sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "                #file_name   = \"sample_mask\" + str(i) + \".csv\"\n",
    "                #temp_date   = pd.DataFrame()\n",
    "                #temp_date['col'] = list(sample_mask)\n",
    "                #temp_date.to_csv(file_name)\n",
    "                \n",
    "                \n",
    "            # fit next stage of trees\n",
    "            self._fit_stage(i, X, y_lower,y_higher, sample_weight,sample_mask, random_state)\n",
    "\n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.g_prev_valid_[i-1,k].copy()\n",
    "                    \n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "\n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "                    \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.g_prev_valid_[i,k] = (1-self.gamma[i-1])*self.prev_valid_[i,k]+self.gamma[i-1]*self.prev_valid_[i-1,k]\n",
    "            else:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.prev_valid_[i-1,k].copy()\n",
    "\n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "\n",
    "            for k in range(self.loss_.K):\n",
    "                \n",
    "                pred[:,k] = self.fitted_[i,k]\n",
    "                pred_val[:,k] = self.prev_valid_[i,k]\n",
    "            \n",
    "            if do_oob:\n",
    "                self.train_score_[i] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,sample_weight[sample_mask])\n",
    "            else:\n",
    "                self.train_score_[i] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,sample_weight)\n",
    "                \n",
    "                \n",
    "            self.valid_score_[i] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,sample_weight_val)\n",
    "    \n",
    "        return i + 1\n",
    "\n",
    "    \n",
    "    def fit(self, X, y_lower,y_higher, sample_weight=None):\n",
    "        \n",
    "        # Check input\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        #y_lower                     = self._validate_y(y_lower, sample_weight)\n",
    "        #y_higher                    = self._validate_y(y_higher, sample_weight)\n",
    "        X                           = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        sample_weight               = np.ones(n_samples, dtype=np.float32)\n",
    "        \n",
    "        X, X_val, y_lower, y_lower_val,y_higher,y_higher_val,sample_weight, sample_weight_val \\\n",
    "        = train_test_split(X, y_lower,y_higher,sample_weight,random_state=self.random_state,test_size=self.validation_fraction)\n",
    "        self._check_params()\n",
    "        self._init_state()\n",
    "\n",
    "        # fit initial model - FIXME make sample_weight optional\n",
    "        #For Binomial       - init_ = LogOddsEstimator\n",
    "        #For Multinomial    - init_ = PriorProbabilityEstimator\n",
    "\n",
    "        self.init_.fit(X, y_lower,y_higher, X_val, y_lower_val,y_higher_val, sample_weight)\n",
    "        # init predictions and update in the inplace self\n",
    "        initial_pred,initial_val_pred  = self.init_.predict(X,X_val)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            self.fitted_[0,k], self.prev_valid_[0,k]          = initial_pred[:,k],initial_val_pred[:,k]\n",
    "            if self.Nestrov == True:\n",
    "                self.g_fitted_[0,k], self.g_prev_valid_[0,k]  = initial_pred[:,k],initial_val_pred[:,k]\n",
    "\n",
    "        begin_at_stage = 1\n",
    "        # fit the boosting stages\n",
    "        \n",
    "        n_stages = self._fit_stages(X, y_lower,y_higher, sample_weight, self.random_state,\n",
    "                                    X_val, y_lower_val,y_higher_val, sample_weight_val,begin_at_stage)\n",
    "        # change shape of arrays after fit (early-stopping or additional ests)\n",
    "        self.n_estimators_ = n_stages\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _make_estimator(self, append=True):\n",
    "        # we don't need _make_estimator\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def _init_decision_function(self, X):\n",
    "        \n",
    "        \"\"\"Check input and compute prediction of ``init``. \"\"\"\n",
    "        #self._check_initialized()\n",
    "        #X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
    "                self.n_features_, X.shape[1]))\n",
    "        score = self.init_.predict(X).astype(np.float64)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _decision_function(self, X):\n",
    "        \n",
    "        # for use in inner loop, not raveling the output in single-class case,\n",
    "        # not doing input validation.\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        predict_stages(self.estimators_, X, self.learning_rate, score)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def _staged_decision_function(self, X):\n",
    "        \n",
    "        #X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        for i in range(self.estimators_.shape[0]):\n",
    "            predict_stage(self.estimators_, i, X, self.learning_rate, score)\n",
    "            yield score.copy()\n",
    "    \n",
    "\n",
    "\n",
    "class GradientBoostingClassifier(BaseGradientBoosting):\n",
    "\n",
    "    _SUPPORTED_LOSS = ('survival')\n",
    "\n",
    "    def __init__(self, loss='aft', learning_rate=0.1, n_estimators=100,\n",
    "                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n",
    "                 max_depth=3, min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None, init=None,\n",
    "                 random_state=None, max_features=None, verbose=0,\n",
    "                 max_leaf_nodes=None, warm_start=False,\n",
    "                 presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,Nestrov=False,dist='normal',sigma=1,tol=1e-4):\n",
    "\n",
    "        super().__init__(\n",
    "            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "            criterion=criterion, min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth, init=init, subsample=subsample,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state, verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            warm_start=warm_start, presort=presort,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,Nestrov=Nestrov,\n",
    "            dist=dist,sigma=sigma,tol=tol)\n",
    "\n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        #check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        n_trim_classes = np.count_nonzero(np.bincount(y, sample_weight))\n",
    "        if n_trim_classes < 2:\n",
    "            raise ValueError(\"y contains %d class after sample_weight \"\n",
    "                             \"trimmed classes with zero weights, while a \"\n",
    "                             \"minimum of 2 classes are required.\"\n",
    "                             % n_trim_classes)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        score = self._decision_function(X)\n",
    "        if score.shape[1] == 1:\n",
    "            return score.ravel()\n",
    "        return score\n",
    "\n",
    "    #def staged_decision_function(self, X):\n",
    "    #    \n",
    "    #    yield from self._staged_decision_function(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        score     = self.decision_function(X)\n",
    "        decisions = self.loss_._score_to_decision(score)\n",
    "        return self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def staged_predict(self, X):\n",
    "       \n",
    "        for score in self._staged_decision_function(X):\n",
    "            decisions = self.loss_._score_to_decision(score)\n",
    "            yield self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        score = self.decision_function(X)\n",
    "        try:\n",
    "            return self.loss_._score_to_proba(score)\n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        proba = self.predict_proba(X)\n",
    "        return np.log(proba)\n",
    "\n",
    "    def staged_predict_proba(self, X):\n",
    "       \n",
    "        try:\n",
    "            for score in self._staged_decision_function(X):\n",
    "                yield self.loss_._score_to_proba(score)\n",
    "                \n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "def data_creation(file_name,K=5):\n",
    "    \n",
    "    df_train   = pd.read_csv(file_name)\n",
    "    y          = list(df_train['Y'])\n",
    "    req_cols   = [i for i in df_train.columns if i != 'Y']\n",
    "    X          = np.array(df_train[req_cols])\n",
    "    y_median   = np.percentile(y, 50) # return 50th percentile, e.g median.\n",
    "    bin_y      = list(map(lambda x : 0 if x < y_median else 1,y))\n",
    "\n",
    "    percentile = np.percentile(y, np.arange(0, 100, 100/K)) # deciles\n",
    "    multi_y    = list(map(lambda x : 0 if x >= percentile[0] and x< percentile[1] else 1 if x >= percentile[1] and x< percentile[2] else 2 if x >= percentile[2] and x< percentile[3] else 3,y))\n",
    "    \n",
    "    return X,y,bin_y,multi_y\n",
    "\n",
    "def chart_creation(gb,chart_title,chart_name):\n",
    "    \n",
    "    min_valid = round(np.min(gb.valid_score_),4)\n",
    "    min_train = round(np.min(gb.train_score_),4)\n",
    "    min_iter  = round(np.nanargmin(gb.valid_score_),0)\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "                    'Min Train = %.2f' % (min_train, ),\n",
    "                    'Min Valid = %.2f' % (min_valid, ),\n",
    "                    'Min Iter  = %.2f' % (min_iter, )))\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5,edgecolor=\"black\")\n",
    "    \n",
    "    fig,ax1       = plt.subplots()\n",
    "    ax2           = ax1.twinx()\n",
    "\n",
    "    ln1 = ax1.plot(gb.train_score_,color='blue',label='Training')\n",
    "    ln2 = ax2.plot(gb.valid_score_,color='orange',label='Validation')\n",
    "    \n",
    "    #ax1.axvline(x=np.nanargmin(gb.valid_score_),color='r')\n",
    "    #ax2.axhline(y=np.min(gb.valid_score_),color='b')\n",
    "    lns = ln1 + ln2\n",
    "    \n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of Iterations(Trees)\")\n",
    "    ax1.set_ylabel(\"Training Mean Square Error\")\n",
    "    ax2.set_ylabel(\"Validation Mean Square Error\")\n",
    "    #ax1.legend([\"Training\",\"Validation\"],loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax2.text(0.7, 0.90, textstr, transform=ax1.transAxes, fontsize=8,\n",
    "        verticalalignment='top', bbox=props)\n",
    "    plt.title(chart_title)\n",
    "    plt.show()\n",
    "    fig.savefig(chart_name)\n",
    "    \n",
    "def generate_result(X,y_lower,y_higher,param):\n",
    "    \n",
    "    gb_manual = GradientBoostingClassifier(**param)\n",
    "    gb_manual.fit(X,y_lower,y_higher)\n",
    "    \n",
    "    return gb_manual    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n",
      "/Users/avinashbarnwal/Desktop/Personal/GSOC-2019/AFT/py/_aft_loss.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  hess     = -((1-F_z)*grad_f_z+f_z**2)/(sigma**2*(1-F_z)**2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data     = pd.read_csv('simulate_survival.csv')\n",
    "    X        = data[['x1','x2','x3']]\n",
    "    y_lower  = data['left']\n",
    "    y_higher = data['right']\n",
    "\n",
    "    param    = {'n_estimators' : 100,'learning_rate': 0.01,'Nestrov' : False,'subsample': 0.5,'min_samples_split': 10,\n",
    "                 'max_depth': 2,'dist':'normal','sigma':1,'random_state' : 0}\n",
    "\n",
    "    gb_manual = generate_result(X,y_lower,y_higher,param)\n",
    "    #gb_manual = generate_result(X,multi_y,param)\n",
    "    chart_creation(gb_manual,'Nesterov=False','Nesterov_False.png')\n",
    "    #chart_creation(gb_manual,'K=2,Nesterov=True','K_2_Nesterov_True.png')\n",
    "    #chart_creation(gb_manual,'K=5,Nesterov=False','K_5_Nesterov_False.png')\n",
    "    #chart_creation(gb_manual,'K=5,Nesterov=True','K_5_Nesterov_True.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
