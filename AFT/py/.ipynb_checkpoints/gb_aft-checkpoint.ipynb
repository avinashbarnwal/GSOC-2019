{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                                   as np\n",
    "import pandas                                  as pd\n",
    "import matplotlib.pyplot                       as plt\n",
    "import math\n",
    "import random\n",
    "from   sklearn                                 import ensemble\n",
    "from   sklearn                                 import datasets\n",
    "from   sklearn.utils                           import shuffle\n",
    "from   sklearn.metrics                         import mean_squared_error\n",
    "from   sklearn.datasets                        import load_boston\n",
    "from   sklearn.model_selection                 import cross_val_score\n",
    "from   sklearn.tree                            import DecisionTreeRegressor\n",
    "from   sklearn.model_selection                 import train_test_split\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stages\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stage\n",
    "from   abc                                     import abstractmethod\n",
    "from   scipy.special                           import expit\n",
    "from   sklearn.utils                           import check_array\n",
    "from   sklearn.tree._tree                      import DTYPE\n",
    "from   sklearn.tree._tree                      import TREE_LEAF\n",
    "from   scipy.special                           import logsumexp\n",
    "from   sklearn.utils                           import check_random_state\n",
    "from   sklearn.ensemble.gradient_boosting      import ZeroEstimator\n",
    "from   _aft_loss                               import loss, negative_gradient,hessian\n",
    "import sys\n",
    "import graphviz\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.externals.six import StringIO  \n",
    "from   IPython.display import Image  \n",
    "from   sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(object):\n",
    "    \n",
    "    \"\"\"Abstract base class for various loss functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        Number of classes\n",
    "    Attributes\n",
    "    ----------\n",
    "    K : int\n",
    "        The number of regression trees to be induced;\n",
    "        1 for regression and binary classification;\n",
    "        ``n_classes`` for multi-class classification.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    is_multi_class = False\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        self.K = n_classes\n",
    "\n",
    "    def init_estimator(self):\n",
    "        \n",
    "        \"\"\"Default ``init`` estimator for loss function. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, y_lower, y_higher,pred,dist,sigma,metrics,sample_weight=None):\n",
    "        \n",
    "        \"\"\"Compute the loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            True labels\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted labels\n",
    "        sample_weight : array-like, shape (n_samples,), optional\n",
    "            Sample weights.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def negative_gradient(self, y_lower, y_higher, pred,dist,sigma, **kargs):\n",
    "        \n",
    "        \"\"\"Compute the negative gradient.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            The target labels.\n",
    "        pred : array, shape (n_samples,)\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_terminal_regions(self, tree, X, y_lower,y_higher, residual, y_pred, dist, sigma, sample_weight, sample_mask, learning_rate=1.0):\n",
    "        \n",
    "        \"\"\"Update the terminal regions (=leaves) of the given tree and\n",
    "        updates the current predictions of the model. Traverses tree\n",
    "        and invokes template method '_update_terminal_region'.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : tree.Tree\n",
    "            The tree object.\n",
    "        X : array, shape (n, m)\n",
    "            The data array.\n",
    "        y : array, shape (n,)\n",
    "            The target labels.\n",
    "        residual : array, shape (n,)\n",
    "            The residuals (usually the negative gradient).\n",
    "        y_pred : array, shape (n,)\n",
    "            The predictions.\n",
    "        sample_weight : array, shape (n,)\n",
    "            The weight of each sample.\n",
    "        sample_mask : array, shape (n,)\n",
    "            The sample mask to be used.\n",
    "        learning_rate : float, default=0.1\n",
    "            learning rate shrinks the contribution of each tree by\n",
    "             ``learning_rate``.\n",
    "        k : int, default 0\n",
    "            The index of the estimator being updated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute leaf for each sample in ''X''.\n",
    "        \n",
    "        terminal_regions                      = tree.apply(X)\n",
    "\n",
    "        # mask all which are not in sample mask.\n",
    "        masked_terminal_regions               = terminal_regions.copy()\n",
    "        masked_terminal_regions[~sample_mask] = -1\n",
    "\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            \n",
    "            self._update_terminal_region(tree, masked_terminal_regions,\n",
    "                                         leaf, X, y_lower, y_higher, residual, y_pred,dist,sigma, sample_weight)\n",
    "        \n",
    "        y_pred = y_pred + (learning_rate* tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
    "        return y_pred\n",
    "\n",
    "    @abstractmethod\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual,pred,dist,sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Template method for updating terminal regions (=leaves).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroEstimator:\n",
    "    \n",
    "    \"\"\"An estimator that simply predicts zero.\n",
    "    .. deprecated:: 0.21\n",
    "        Using ``ZeroEstimator`` or ``init='zero'`` is deprecated in version\n",
    "        0.21 and will be removed in version 0.23.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y_lower,y_higher,X_val, y_lower_val,y_higher_val, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Fit the estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : numpy, shape (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary\n",
    "        sample_weight : array, shape (n_samples,)\n",
    "            Individual weights for each sample\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.issubdtype(y_lower.dtype, np.signedinteger):\n",
    "            # classification\n",
    "            self.n_classes = np.unique(y_lower).shape[0]\n",
    "            if self.n_classes == 2:\n",
    "                self.n_classes = 1\n",
    "        else:\n",
    "            # regression\n",
    "            self.n_classes = 1\n",
    "\n",
    "    def predict(self, X,X_val):\n",
    "        \"\"\"Predict labels\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : array, shape (n_samples,)\n",
    "            Returns predicted values.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, 'n_classes')\n",
    "\n",
    "        y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y.fill(0.0)\n",
    "        \n",
    "        y_val = np.empty((X_val.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y_val.fill(0.0)\n",
    "        return y,y_val\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFT(LossFunction):\n",
    "    \"\"\"Cox Partial Likelihood\"\"\"\n",
    "\n",
    "    def __call__(self, y_lower, y_higher, y_pred, dist, sigma, metrics, sample_weight=None):\n",
    "        \"\"\"Compute the partial likelihood of prediction ``y_pred`` and ``y``.\"\"\"\n",
    "        # TODO add support for sample weights\n",
    "        return loss(y_lower, y_higher, y_pred.ravel(),dist, sigma,metrics)\n",
    "\n",
    "    def negative_gradient(self, y_lower, y_higher, y_pred,dist,sigma,k=0,sample_weight=None, **kwargs):\n",
    "        \"\"\"Negative gradient of partial likelihood\n",
    "        Parameters\n",
    "        ---------\n",
    "        y : tuple, len = 2\n",
    "            First element is boolean event indicator and second element survival/censoring time.\n",
    "        y_pred : np.ndarray, shape=(n,):\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "        ret = negative_gradient(y_lower, y_higher, y_pred.ravel(), dist, sigma)\n",
    "        if sample_weight is not None:\n",
    "            ret *= sample_weight\n",
    "        return ret\n",
    "\n",
    "    def init_estimator(self):  # pragma: no cover\n",
    "        return ZeroEstimator()\n",
    "\n",
    "\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual, pred, dist, sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Least squares does not need to update terminal regions\"\"\"\n",
    "        \n",
    "        \"\"\"Make a single Newton-Raphson step.\n",
    "        our node estimate is given by:\n",
    "            sum(w * gradient) / sum(w * hessian)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        hess            = np.array(hessian(y_lower, y_higher, pred, dist, sigma))\n",
    "        terminal_region = np.where(terminal_regions == leaf)[0]\n",
    "        residual        = residual.take(terminal_region, axis=0)\n",
    "        hess            = hess.take(terminal_region, axis=0)\n",
    "        sample_weight   = sample_weight.take(terminal_region, axis=0)\n",
    "        pred            = pred.take(terminal_region, axis=0)\n",
    "\n",
    "        numerator       = np.sum(sample_weight * residual)\n",
    "        denominator     = np.sum(sample_weight * hess)\n",
    "\n",
    "        # prevents overflow and division by zero\n",
    "        \n",
    "        if abs(denominator) < 1e-2:\n",
    "            tree.value[leaf, 0, 0] = 0.0\n",
    "        else:\n",
    "            tree.value[leaf, 0, 0] = numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample_mask(n_total_samples,n_total_in_bag, random_state):\n",
    "    \n",
    "    \"\"\"Create a random sample mask where ``n_total_in_bag`` elements are set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_total_samples : int\n",
    "        The length of the resulting mask.\n",
    "\n",
    "    n_total_in_bag : int\n",
    "        The number of elements in the sample mask which are set to 1.\n",
    "        \n",
    "    random_state : np.RandomState\n",
    "        A numpy ``RandomState`` object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample_mask : np.ndarray, shape=[n_total_samples]\n",
    "         An ndarray where ``n_total_in_bag`` elements are set to ``True``\n",
    "         the others are ``False``.\n",
    "    \"\"\"\n",
    "    \n",
    "    #random_state = np.random.RandomState(random_state)\n",
    "    rand         = random_state.rand(n_total_samples)\n",
    "    sample_mask  = np.zeros((n_total_samples,), dtype=np.bool)\n",
    "    n_bagged     = 0\n",
    "    \n",
    "    for i in range(n_total_samples):\n",
    "        \n",
    "        if rand[i] * (n_total_samples - i) < (n_total_in_bag - n_bagged):\n",
    "            sample_mask[i] = 1\n",
    "            n_bagged += 1\n",
    "            \n",
    "    return sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Attributes and Parameters\n",
    "\n",
    "class BaseGradientBoosting():\n",
    "    \"\"\"Abstract base class for Gradient Boosting. \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, loss, learning_rate, n_estimators, criterion,\n",
    "                 min_samples_split, min_samples_leaf, min_weight_fraction_leaf,\n",
    "                 max_depth, min_impurity_decrease, min_impurity_split,\n",
    "                 init, subsample, max_features,\n",
    "                 random_state, alpha=0.9, verbose=0, max_leaf_nodes=None,\n",
    "                 warm_start=False, presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,metrics = 'logloss', Nestrov=False,dist='normal',sigma =1,\n",
    "                 tol=1e-4):\n",
    "        \n",
    "        #Initial = 1\n",
    "        self.n_estimators             = n_estimators + 1\n",
    "        self.learning_rate            = learning_rate\n",
    "        self.loss                     = loss\n",
    "        self.criterion                = criterion\n",
    "        self.min_samples_split        = min_samples_split\n",
    "        self.min_samples_leaf         = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.subsample                = subsample\n",
    "        self.max_features             = max_features\n",
    "        self.max_depth                = max_depth\n",
    "        self.min_impurity_decrease    = min_impurity_decrease\n",
    "        self.min_impurity_split       = min_impurity_split\n",
    "        self.init                     = init\n",
    "        self.random_state             = random_state\n",
    "        self.alpha                    = alpha\n",
    "        self.verbose                  = verbose\n",
    "        self.max_leaf_nodes           = max_leaf_nodes\n",
    "        self.warm_start               = warm_start\n",
    "        self.presort                  = presort\n",
    "        self.validation_fraction      = validation_fraction\n",
    "        self.n_iter_no_change         = n_iter_no_change\n",
    "        self.tol                      = tol\n",
    "        self.Nestrov                  = Nestrov\n",
    "        self.dist                     = dist\n",
    "        self.sigma                    = sigma\n",
    "        self.metrics                  = metrics\n",
    "\n",
    "    #Very Important loss class is defined here.\n",
    "    \n",
    "    def _init_state(self):\n",
    "        \n",
    "        self.estimators_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.fitted_        = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.prev_valid_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.train_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.valid_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.random_state   = check_random_state(self.random_state)\n",
    "        \n",
    "        if self.Nestrov == True:\n",
    "            \n",
    "            self.g_fitted_      = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.g_prev_valid_  = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.lamb           = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma          = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma[0]       = 1\n",
    "            \n",
    "            for i in range(1,self.n_estimators):\n",
    "                self.lamb[i] = 0.5*(1+math.sqrt(1+4*self.lamb[i-1]**2))\n",
    "                \n",
    "            for i in range(1,self.n_estimators-1):\n",
    "                self.gamma[i] = (1-self.lamb[i])/self.lamb[i+1]\n",
    "                \n",
    "        \n",
    "        #do oob?\n",
    "        if self.init is None:\n",
    "            self.init_ = self.loss_.init_estimator()\n",
    "        elif isinstance(self.init, str):\n",
    "            self.init_ = INIT_ESTIMATORS[self.init]()\n",
    "        else:\n",
    "            self.init_ = self.init\n",
    "\n",
    "        \"\"\"Initialize model state and allocate model state data structures. \"\"\"\n",
    "\n",
    "        if self.subsample < 1.0:\n",
    "            self.oob_improvement_ = np.zeros((self.n_estimators),dtype=np.float64)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        \n",
    "        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n",
    "        \n",
    "        \n",
    "        if self.loss == 'aft':\n",
    "            self.loss_ =  AFT(1)\n",
    "            \n",
    "\n",
    "    def _fit_stage(self, i, X, y_lower, y_higher, sample_weight, sample_mask, random_state):\n",
    "        \n",
    "        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n",
    "        \n",
    "        assert sample_mask.dtype == np.bool\n",
    "        loss       = self.loss_\n",
    "        #original_y = y_lower\n",
    "        pred       = np.zeros((X.shape[0],self.loss_.K),dtype=np.float64)\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "            if self.Nestrov == True:\n",
    "                pred[:,k] = self.g_fitted_[i-1,k]    \n",
    "            else:\n",
    "                pred[:,k] = self.fitted_[i-1,k]\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "   \n",
    "            residual = loss.negative_gradient(y_lower,y_higher,pred,self.dist,self.sigma,k=k,sample_weight=sample_weight)\n",
    "        \n",
    "            # induce regression tree on residuals\n",
    "            tree     = DecisionTreeRegressor(\n",
    "                                            criterion                 = self.criterion,\n",
    "                                            splitter                  = 'best',\n",
    "                                            max_depth                 = self.max_depth,\n",
    "                                            min_samples_split         = self.min_samples_split,\n",
    "                                            min_samples_leaf          = self.min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf  = self.min_weight_fraction_leaf,\n",
    "                                            min_impurity_decrease     = self.min_impurity_decrease,\n",
    "                                            min_impurity_split        = self.min_impurity_split,\n",
    "                                            max_features              = self.max_features,\n",
    "                                            max_leaf_nodes            = self.max_leaf_nodes,\n",
    "                                            random_state              = random_state,\n",
    "                                            presort                   = self.presort\n",
    "                                            )\n",
    "\n",
    "            if self.subsample < 1.0:\n",
    "                # no inplace multiplication!\n",
    "                sample_weight = sample_weight * sample_mask.astype(np.float64)\n",
    "                \n",
    "\n",
    "            tree.fit(X, residual, sample_weight=sample_weight)\n",
    "            \n",
    "            #dot_data = StringIO()\n",
    "            #export_graphviz(tree, out_file=dot_data,  \n",
    "            #                filled=True, rounded=True,\n",
    "            #                special_characters=True)\n",
    "            #graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "            #Image(graph.create_png())\n",
    "            #filename = \"tree\"+str(i)+\".png\"\n",
    "            #graph.write_png(filename)\n",
    "\n",
    "            # update tree leaves    \n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                y_pred                  = self.g_fitted_[i-1,k]\n",
    "                self.fitted_[i,k]       = loss.update_terminal_regions(tree.tree_, X, y_lower, y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "                self.g_fitted_[i,k]     = (1-self.gamma[i-1])*self.fitted_[i,k]+self.gamma[i-1]*self.fitted_[i-1,k]\n",
    "                \n",
    "            else:\n",
    "                y_pred            = self.fitted_[i-1,k]\n",
    "                self.fitted_[i,k] = loss.update_terminal_regions(tree.tree_, X, y_lower,y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "    \n",
    "    def n_features(self):\n",
    "        return self.n_features_\n",
    "    \n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        self.classes_    = np.unique(y)\n",
    "        self.n_classes_  = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def _fit_stages(self, X, y_lower, y_higher,sample_weight, random_state,\n",
    "                    X_val, y_lower_val, y_higher_val,sample_weight_val,begin_at_stage=0):\n",
    "        \n",
    "        \n",
    "        n_samples    = X.shape[0]\n",
    "        do_oob       = self.subsample < 1.0\n",
    "        sample_mask  = np.ones((n_samples, ), dtype=np.bool)\n",
    "        n_inbag      = max(1, int(self.subsample * n_samples))\n",
    "        loss_        = self.loss_\n",
    "        \n",
    "        # create one-hot label encoding\n",
    "        pred         = np.zeros((n_samples, self.loss_.K), dtype=np.float64)\n",
    "        pred_val     = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            pred[:,k] = self.fitted_[0,k]\n",
    "            pred_val[:,k] = self.prev_valid_[0,k]\n",
    "            \n",
    "        if do_oob:\n",
    "            \n",
    "            sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "            self.train_score_[0] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,self.metrics,sample_weight[sample_mask])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.train_score_[0] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,self.metrics,sample_weight)\n",
    "        self.valid_score_[0] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,self.metrics,sample_weight_val)\n",
    "\n",
    "        # perform boosting iterations\n",
    "        # validation loss performance\n",
    "        \n",
    "        for i in range(begin_at_stage, self.n_estimators):\n",
    "\n",
    "            # subsampling\n",
    "            if do_oob:\n",
    "                sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "                \n",
    "            # fit next stage of trees\n",
    "            self._fit_stage(i, X, y_lower,y_higher, sample_weight,sample_mask, random_state)\n",
    "\n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.g_prev_valid_[i-1,k].copy()\n",
    "                    \n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "\n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "                    \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.g_prev_valid_[i,k] = (1-self.gamma[i-1])*self.prev_valid_[i,k]+self.gamma[i-1]*self.prev_valid_[i-1,k]\n",
    "            else:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.prev_valid_[i-1,k].copy()\n",
    "\n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "\n",
    "            for k in range(self.loss_.K):\n",
    "                \n",
    "                pred[:,k] = self.fitted_[i,k]\n",
    "                pred_val[:,k] = self.prev_valid_[i,k]\n",
    "            \n",
    "            if do_oob:\n",
    "                self.train_score_[i] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,self.metrics,sample_weight[sample_mask])\n",
    "            else:\n",
    "                self.train_score_[i] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,self.metrics,sample_weight)\n",
    "   \n",
    "            self.valid_score_[i] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,self.metrics,sample_weight_val)\n",
    "    \n",
    "        return i + 1\n",
    "\n",
    "    \n",
    "    def fit(self, X, y_lower,y_higher, sample_weight=None):\n",
    "        \n",
    "        # Check input\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        #y_lower                     = self._validate_y(y_lower, sample_weight)\n",
    "        #y_higher                    = self._validate_y(y_higher, sample_weight)\n",
    "        X                           = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        sample_weight               = np.ones(n_samples, dtype=np.float32)\n",
    "        \n",
    "        X, X_val, y_lower, y_lower_val,y_higher,y_higher_val,sample_weight, sample_weight_val \\\n",
    "        = train_test_split(X, y_lower,y_higher,sample_weight,random_state=self.random_state,test_size=self.validation_fraction)\n",
    "        self._check_params()\n",
    "        self._init_state()\n",
    "\n",
    "        # fit initial model - FIXME make sample_weight optional\n",
    "        #For Binomial       - init_ = LogOddsEstimator\n",
    "        #For Multinomial    - init_ = PriorProbabilityEstimator\n",
    "\n",
    "        self.init_.fit(X, y_lower,y_higher, X_val, y_lower_val,y_higher_val, sample_weight)\n",
    "        # init predictions and update in the inplace self\n",
    "        initial_pred,initial_val_pred  = self.init_.predict(X,X_val)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            self.fitted_[0,k], self.prev_valid_[0,k]          = initial_pred[:,k],initial_val_pred[:,k]\n",
    "            if self.Nestrov == True:\n",
    "                self.g_fitted_[0,k], self.g_prev_valid_[0,k]  = initial_pred[:,k],initial_val_pred[:,k]\n",
    "\n",
    "        begin_at_stage = 1\n",
    "        # fit the boosting stages\n",
    "        \n",
    "        n_stages = self._fit_stages(X, y_lower,y_higher, sample_weight, self.random_state,\n",
    "                                    X_val, y_lower_val,y_higher_val, sample_weight_val,begin_at_stage)\n",
    "        # change shape of arrays after fit (early-stopping or additional ests)\n",
    "        self.n_estimators_ = n_stages\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _make_estimator(self, append=True):\n",
    "        # we don't need _make_estimator\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def _init_decision_function(self, X):\n",
    "        \n",
    "        \"\"\"Check input and compute prediction of ``init``. \"\"\"\n",
    "        #self._check_initialized()\n",
    "        #X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
    "                self.n_features_, X.shape[1]))\n",
    "        score = self.init_.predict(X).astype(np.float64)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _decision_function(self, X):\n",
    "        \n",
    "        # for use in inner loop, not raveling the output in single-class case,\n",
    "        # not doing input validation.\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        predict_stages(self.estimators_, X, self.learning_rate, score)\n",
    "        return score\n",
    "\n",
    "    def _staged_decision_function(self, X):\n",
    "        \n",
    "        #X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        for i in range(self.estimators_.shape[0]):\n",
    "            predict_stage(self.estimators_, i, X, self.learning_rate, score)\n",
    "            yield score.copy()\n",
    "    \n",
    "\n",
    "\n",
    "class GradientBoostingClassifier(BaseGradientBoosting):\n",
    "\n",
    "    _SUPPORTED_LOSS = ('survival')\n",
    "\n",
    "    def __init__(self, loss='aft', learning_rate=0.1, n_estimators=100,\n",
    "                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n",
    "                 max_depth=3, min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None, init=None,\n",
    "                 random_state=None, max_features=None, verbose=0,\n",
    "                 max_leaf_nodes=None, warm_start=False,\n",
    "                 presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,Nestrov=False,metrics = 'logloss',dist='normal',sigma=1,tol=1e-4):\n",
    "\n",
    "        super().__init__(\n",
    "            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "            criterion=criterion, min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth, init=init, subsample=subsample,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state, verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            warm_start=warm_start, presort=presort,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,Nestrov=Nestrov,metrics=metrics,\n",
    "            dist=dist,sigma=sigma,tol=tol)\n",
    "\n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        #check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        n_trim_classes = np.count_nonzero(np.bincount(y, sample_weight))\n",
    "        if n_trim_classes < 2:\n",
    "            raise ValueError(\"y contains %d class after sample_weight \"\n",
    "                             \"trimmed classes with zero weights, while a \"\n",
    "                             \"minimum of 2 classes are required.\"\n",
    "                             % n_trim_classes)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        score = self._decision_function(X)\n",
    "        if score.shape[1] == 1:\n",
    "            return score.ravel()\n",
    "        return score\n",
    "\n",
    "    #def staged_decision_function(self, X):\n",
    "    #    \n",
    "    #    yield from self._staged_decision_function(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        score     = self.decision_function(X)\n",
    "        decisions = self.loss_._score_to_decision(score)\n",
    "        return self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def staged_predict(self, X):\n",
    "       \n",
    "        for score in self._staged_decision_function(X):\n",
    "            decisions = self.loss_._score_to_decision(score)\n",
    "            yield self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        score = self.decision_function(X)\n",
    "        try:\n",
    "            return self.loss_._score_to_proba(score)\n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        proba = self.predict_proba(X)\n",
    "        return np.log(proba)\n",
    "\n",
    "    def staged_predict_proba(self, X):\n",
    "       \n",
    "        try:\n",
    "            for score in self._staged_decision_function(X):\n",
    "                yield self.loss_._score_to_proba(score)\n",
    "                \n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "def data_creation(file_name,K=5):\n",
    "    \n",
    "    df_train   = pd.read_csv(file_name)\n",
    "    y          = list(df_train['Y'])\n",
    "    req_cols   = [i for i in df_train.columns if i != 'Y']\n",
    "    X          = np.array(df_train[req_cols])\n",
    "    y_median   = np.percentile(y, 50) # return 50th percentile, e.g median.\n",
    "    bin_y      = list(map(lambda x : 0 if x < y_median else 1,y))\n",
    "\n",
    "    percentile = np.percentile(y, np.arange(0, 100, 100/K)) # deciles\n",
    "    multi_y    = list(map(lambda x : 0 if x >= percentile[0] and x< percentile[1] else 1 if x >= percentile[1] and x< percentile[2] else 2 if x >= percentile[2] and x< percentile[3] else 3,y))\n",
    "    \n",
    "    return X,y,bin_y,multi_y\n",
    "\n",
    "def chart_creation(gb,chart_title,chart_name):\n",
    "    \n",
    "    min_valid = round(np.min(gb.valid_score_),4)\n",
    "    min_train = round(np.min(gb.train_score_),4)\n",
    "    min_iter  = round(np.nanargmin(gb.valid_score_),0)\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "                    'Min Train = %.2f' % (min_train, ),\n",
    "                    'Min Valid = %.2f' % (min_valid, ),\n",
    "                    'Min Iter  = %.2f' % (min_iter, )))\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5,edgecolor=\"black\")\n",
    "    \n",
    "    fig,ax1       = plt.subplots()\n",
    "    ax2           = ax1.twinx()\n",
    "\n",
    "    ln1 = ax1.plot(gb.train_score_,color='blue',label='Training')\n",
    "    ln2 = ax2.plot(gb.valid_score_,color='orange',label='Validation')\n",
    "    \n",
    "    #ax1.axvline(x=np.nanargmin(gb.valid_score_),color='r')\n",
    "    #ax2.axhline(y=np.min(gb.valid_score_),color='b')\n",
    "    lns = ln1 + ln2\n",
    "    \n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of Iterations(Trees)\")\n",
    "    ax1.set_ylabel(\"Training Negative Likelihood(Loss)\")\n",
    "    ax2.set_ylabel(\"Validation Negative Likelihood(Loss)\")\n",
    "    #ax1.legend([\"Training\",\"Validation\"],loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax2.text(0.7, 0.90, textstr, transform=ax1.transAxes, fontsize=8,\n",
    "        verticalalignment='top', bbox=props)\n",
    "    plt.title(chart_title)\n",
    "    plt.show()\n",
    "    fig.savefig(chart_name)\n",
    "    \n",
    "def generate_result(X,y_lower,y_higher,param):\n",
    "    \n",
    "    gb_manual = GradientBoostingClassifier(**param)\n",
    "    gb_manual.fit(X,y_lower,y_higher)\n",
    "    \n",
    "    return gb_manual    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEWCAYAAADsPHnaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4FUUXh9+ThA4hdIEAofcqXUCqCohgxY8qoth77wULKlawgaCioqKCUkW6ItKkg3QpQTqEAKElnO+P2U1uknuTTSEhMO/z7HPvzs7Mzu4tvz0zZ86IqmKxWCwWS04mKLsbYLFYLBZLRrFiZrFYLJYcjxUzi8ViseR4rJhZLBaLJcdjxcxisVgsOR4rZhaLxWLJ8Vgxs5zXiMgrIvJFdrfDcvEhIhtEpPU5qHe+iNyS2fVe7Fgxy0JEZJuI7BORAj5pt4nI3AzU2VZEIjOlgecQEZkrIidF5JjP1iKb2vK1iLyYHef2h4iEiIiKSEQm15stDwIiUsW5Hvdz3iMik0SkQxrqyNDvwkPbliRJLyUiZ0Rks5umqtVV9Y/MboPl3GDFLOsJBh7I7ka4iEhIFp7uXlUt6LP9lYXntmQx7ucMNARmAxNFpE82N8slVERq+uz3BrZmV2MsGceKWdbzFvCoiIQlPSAiNURkhogccro4bvI51kVE1onIURHZJSKPOhbeNKCMz1NwGREJEpEnRWSLiBwUkXEiUtSpJ8J5Mh0oIjswfzKIyDUislZEohwrqqaT/oSI/Jikne+LyAeZdUNEZLiIRIpItIgsEZGWAfLlF5GxzjVFichiESnuHAsTkc9FZLdT18sikubvt4i0EpGlInLEqb+Zz7GBjnV9VES2isjNTno1EfndKXNARMam9174aU+QiDwvItsdq/4LEQn1OT5ARHY4533aufa2HuqtLSLznPu4WkS6+hy7WkT+ca4zUkQectJLishUp8whEfndyzWo6m5VfRcYDLwpIuLU96xzH486371rnPS6wHCgtfOdPuCkXyMiK5zvyQ4Rec7zjUzOV0A/n/1+wBjfDO69FMN0EXnD59iPIjLCZ/82EVkvIodFZJqIlPM5dpXzez4iIu8DkoF2WwKhqnbLog3YBnQExgOvOGm3AXOBAsBOYAAQgnmaPQDUcvLtBlo774sAjZz3bYHIJOd5AFgIhAN5gE+Bb51jEYBifrgFgHxANeA40AnIBTwObAZyAxWAGKCQUz7YaUtzZ/8jICrAtsqnTXOB2wLcl75AUee6nwB2AXmcY68AXzjv7wF+dtocDDQGCjrHJjltyQ+UAv4GBgY439fAi37SiwNHgP85bekLHHTud6hzrKqTt7TPZ/OD0+4gIC9wmU+da1O4Px84eUKczyTCT5sGARuBikAh4Bfgc+dYXeAo0NL5nN8FYoG2Se9dkjpzA/86n3MuzHfyGFDFOb4faOm8L0rCd+0tjMjkcupoE+D+VgHUT3o15zrde3iTcx+DgF5OG0r5/i6SlG8P1Hby18f8Pq72+V4Gus9RwKO+bcN8r7c7ddUF1gBXAZt9zhfpcy/LOPelDdAf8/so4By7HtgAVHc+yxeBP5xjJZ3ruta5b485n9Et2f1/dKFt2d6Ai2kjQczqYP4YS5AgZj3dH4BP/k+BF5z3O4A7gNAkedqSXMz+ATr47JcGzjg/tAjnx1zJ5/hzwDif/SCMoLR19ucD/Zz3nYAt6bj2uRhRdP9clgXIJ5g/6NrOvq+YDXLaUjdJmbLACRwBdNL6AjMCnCOQmA0AFiRJWwL0wYhZlPOnlDdJnrHAx0DZdH4vUhKzecAgn/3awCnnM3oZ+MrnWAG8iVk75/MVn7QfgGed9/8538tCScq9hnkQq5zK9QQSs4LOdTYLUG4N0NV5n0zM/OQfDryVxnsd3zbnO9kBGIp5GAkoZs5+T8zv8CDQwid9BtA/yed5yvle3grMT/Lb2o0Vs0zfbDdjNqCqa4DJwJM+yRWAZk4XTpSIRGH68S9xjl8PdAG2O91DKTlPVAAm+NTzDxCHsVhcdvq8L4N5SnXbd9Y5XtZJGouxVsA8Qae3G+1+VQ1ztkZuoog87nTRHAEOY/6Ui/sp/wUwExgnpqt1iJgxvwoYy2SvzzV/mOR6vZDoPjhsx4hUNOYe3APsEZHJIlLNyfMI5ql7qdNl1z+N501Lm7ZjrKISzrH4z1FVj2Pun5c6d7j/6D71up/3tcA1wA6ny9ntah3i5Jslpgv7sTRei1v/IQARuUVEVvp8ZjXw/7nj5G/htGe/8125LaX8HhiDeYC5GfOAkxq/YL5nazTxeG8F4EOf6zgAnMX0jCT9jM5iRNKSyVgxyz5eAG4n4Qe+E5jn82cfpmYA/S4AVV2iqt0x3RY/A+Occv6WPdgJdE5SV15V3eWTx7fcf5gfJADOmEY5zNM7mKf2tiISjvmjG+uT9xNJ7KHou61N7SaISDvgYYxYh2G69I7hZ1xBVU+r6ouqWhNo5bSlt3O9MUBRn+sNVdV6qZ0/CYnug0N5nPugqtNUtSPG0t2MsZxRMyZ0m6qWxojdCBGp6FzfhhTuz/B0tKk8cBrT5bUb84eJc64CmPvnpc5y7tiVn+tcpKrXYL5rk4HvnPRoVX1IVSOAHsATInK5h/O5XAvsATaLSCWMNXsXUExVw4D1JHzu/r7X3wE/AeVUtTDwmZtfRIJTuM/HRORxP/X94FzHP0l+G4F4HVgJRIjIjT7pOzFd2r6/t3yqugjzGfmOnwXh85lZMg8rZtmEqm4Gvgfud5ImA9VEpK+I5HK2JiJSU0Ryi0hvESmsqmeAaMyTH8BeoJiIFPap/hPgVRGpACAiJUSkewrNGQd0FZEOIpILY2mcAhY4bd2P6ZL5HPhXVf/xuY47NbGHou9W28OtKITpGjuAsW5exFhmyRCR9iJSx/lDiMZ0nZ5V1Z2Y7rihIhIqxmmiioi0ccq57ti+fyIhIpLXZ8uN+Qxqi0hPMe7yvTDdUlNEpLSIdBOR/BgxOY7zGYjITSLiPpREYf6I45z7Uz2F+3NvkkvMk6RNwcC3wMNiHHcKAa9ixj/P4vwZi0hzp/0v+7ltwUnqzIP5XGOBR5zvWXuM1f+9iOQTkV4iEup81476XGc3EansiOAR5xrdY1+LyGcBPrdSInI/8CzwhGMRul2O+00WuR1jmbnsBcKd76NLIeCQqp4UkeYYiwrnPselcJ8LquqbSdulqkcxXa53+Gt3kmtoj3lw6ocZM/tIREo7hz8BnpEEp6kwEbnBOTYZaCAi3Z1reQhjVVsym+zu57yYNpwxM5/9csBJnLEBzADyFMwP/CDG07ABplvpV0wXUjRmHKeVTz2jnfxRmG6NIIy1swHzZ7QFeM3JG4H5EwlJ0rZrgXWYP6l5OGNWPsf7OuUeS+e1z8WPAwhmfOEL57r+wwip78C775hZH4wzxDHME/57QLBzrAjGUop0rmE5cJNzrJ1zD0Kc/a+da/Hd3M/gcmCZU8cSEhwhwoHfnfQoYA5Qwzn2ttP24xiLza/jSQr3JsRPexS4BePY8BLm6X8/pmussE/Zgc6xA8DTGBFo4XPvkta5zTlWF/jDuZ41wDVOej5gus93bbFPfY9iuhmPO+d82qcd84ABznvXyeKYs+3FfK+vSHLdbzjn2Y8Zt/oTZywJ0503DdMlucdJc8esjgITMQ4/X6TxXvsdz3OO+R0zw/QY7ABu8Dn2NjDVZ/8W5z5GO3lH+hzrivneHgHe971Ou2XeJs7NtlguWMRMkN6pqqOyuy3nEjEu+1FABTXWaladNy/mAaCeqsZm1XktFl+smFksORgxc7NmYqzxd4GGqto4e1tlsWQ9dszMYsnZXIvp4ozEdCH/L8XcFssFirXMLBaLxZLjsZaZxWKxWHI8WRlkNssICgrSfPnyZXczLBaLJUcRExOjqpojjZwLUszy5cvH8ePHs7sZFovFkqMQkRPZ3Yb0kiMV2GKxWCwWX6yYWSwWiyXHY8XMYrFYLDkeK2YWi8ViyfFYMbNYLBZLjseKmcVisVhyPFbMLBaLxZLjsWLmw87Nh1gw7EF2bInK7qZYLBaLJQ1YMfPh1MGtNCsyjFML07oavMVisViyEytmPkRc2pj3f3uUqvIZ7JmZ3c2xWCwWi0esmPkQEgJTdrzI9sPVYNHtcOZYdjfJYrFYLB6wYpaE+o3yMeCT0ejx7bDymexujsVisVg8YMUsCU2awJw1l3Gg6L2wcRisfxfOnsnuZlksFoslBayYJaGxs+D8lMjXoPRVsOxhmNYQ9s7J3oZZLBaLJSBWzJJQpQqEhcFfSwpC2ynQ5meIPQ6z2sOsDrBrKujZFOs4exZuuw0mT86iRlssFstFjhWzJIgY62zJEmcnvDt0XQcN3oDo9TCvK0ypA7t/C1jHTz/BqFHw3XdZ126LxWK5mLFi5ocmTWD1ajh50kkIyQe1Hodr/oUWXwMKc66E5Y9B3OlEZePi4PnnzftNm7K02RaLxXLRckGuNJ1RmjSB2FhYsQKaN/c5EJwbKvaGctfB8kfgn6FmLK31eChQHoBvvoH166FiRdi8OXvab7Gcz8TGxjLjt+ns2rWD2FjrXJUWcuXKTdVqNWndug0ikt3NOa8QVc3uNmQ6BQoU0OPHj6e7/M6dUL48DBsG996bUsafYWF/CK0JneZzOjaEGjWgSBHo1QsefRQOHoSiRdPdFIvlgkJV+Xbs15w9dYhmjeuSK8Q+T6eFU6fPMOf3JURUrcdVnbtkev0iEqOqBTK9Yu/nLwKUAU4A21RTcVDwwX6T/BAeDqVKOeNmKVGuB8R9Agt6wbo3GD3/Gf79Fz78EM44D5ybNkGzZue8yRZLjuDw4cPs2rGZe2/vSXBwcHY3J0dyyQ3Fef/T77niyqsICsr5I0UiUhi4B/gfkBvYD+QFSonIQuAjVU3VnTzn34lzgIjpanTF7IsvoGRJmJPkdsbFQbf7/sfk1T05s/xFRg9dzmWXwVVXQdWqJo/tarRYEoiJiaFQwQJWyDJAvnx5CQkO4tSpU9ndlMziR2An0FpVq6tqK1VtrKrlgCFAdxEZmFolVswC0KSJGfvq3RsGDID9+2H69MR5Nm827vef/P0Rx2NLMPGpPnz1xUlEoFIlI4rWCcRiCcy8+YvIX6I2+/YfBGDpstXkKVqDbTsimT7zD6b+NjfF8j+Mn0qnbn2p26wzdZpeRadufflh/NRUz/v5Vz+ycvU/mXEJnD17lseeeZ0re9xCn4EPJzrWvecdDB4yDIDRY36gbrPOdOrWl2dffjtZPT373UfHq/vQvktvNm3ZBsA1Nw2ifZfeXHXtAP7bvTc+74U0XqaqnVT1K1VNtlyJqv6tqg+q6qjU6rHdjAFo3BhU4dtvjXfihAmwalXiPO7+4DeKElZqNMztDP92hGIfkqdIfcqXt2JmsaRG/bo1mDR1FgP738QvU2ZwacM6AFzZsXWqZW+8rgs3XteFMWPHExsbx639bkx0/OzZs3674gb0vSFzGg+MGz+FenVq8NarTyVKX75yLWfOJHZweeyB2+nX6zq/9Xw96h1y5crF7Hl/8fHIb3hnyDO8/9bzVKwQzq8zfmf4p1/x2ouPZlq7zzdE5DJghaoeF5E+QCPgfVXd7qV8ipaZiDQRkfdFZJmI7BaRrSIyUUTuEJFCmdD+85a2beHWW4019tJL0KBBcjFbuRKCg6FmTaDMVdD8C4jeAL82giV307D2YdvNaLGkQtvWzZnz+0IA1q3fTK0aVQAYM3Y8o8f8wLYdkbTv0pue/e6jebvriNy1J9U6W3W8ibsfep6nXniLqb/NpVO3vrRofz3f/jAJgBdefY958xcxa+4CrrlpED1uvoP2XXoTE3Mize2fOn0uq9duoFO3vnzx9U/x6R+P/IZBA25OlPe9Dz+n49V9mDd/UbJ6cuXKBcDxmBPUrV0dgIoVwp1jIQQHX/AdaR8DMSJSH3gE2AKM8Vo44N0RkSnAvcA8oAdQEaOUrwBhwBQRuTr97T6/yZ/fTHzu1Mns16sHu3YZ70SXVaugRg3Im9dJqNQfum2EqvfC5hF80L0d+yIPZ3nbLZacRO7cucibNzeLlqygRrXKfvMcOx7Dt1+8zwN3D2DCpMABC1z2HTjIs4/fwxuDn6Btq2bMmPQVv0//jhGjv02WN1/ePPz83ae0v7wFc5OIzMuvf0Cnbn0Tba7wuuzdf5BaNaoybcLnfPXtBA4cPMy6fzZRpnQpChUqGJ/vuu5X8vf8iXwz+j0ee2YIZ88mdtQ7ceIk7Tr34rFnXqfJpXXj02NjY3nz3U8Z2P+mVK87hxOrxr2+OzBcVT8EPBtNKXUz3qqqe5OknQQWO9sbIlIyra3NqdSrZ15XrzZWGxjL7LLLkmTMXQQavw9lu1J6dje+vaMzB/fOoFipC9qQtVgyxFUdL+feR17ko3df5tPRY5Mdr1m9MkFBQZQpXZItW1PvdSpdqgRlSpcCYOny1bz61kfExcayYdPWZHlr1zTeWmVKl+LIkaOJjj3/1P2pnqtwaCFaX9aEkJAQmlxaj63/7mD0mB94+bmHWL12Q3y+sMKhAJQqWZyKFcI5cPAwJUsUiz+eL19e5kwby+KlKxk8ZDjfjzFjbY8+8zoD+t5ARPnwVNuSwzkqIk8BfYA2IhIE5PJaOKBl5gqZiOQTZ7RRRCqLSBcRCXHy7MtQ03MQrpi5XY1RUbBjB9SvH6BA6StYlm8cjSsuJdefV0NsTJa002LJiVzVqQ2N6temcaO6fo/7Ojx4mRvrO0721nsjGfXhEKaOH53IUvJStxfLrHmTBqxxRGvNuo2UCy/Ntp27uPWuJ3hu8DuM/WESfy78m+hosz5iTMwJtu3YRbGiYfF1nD17ltjYWAAKFSpIvnymu2fkF9+RN08ebr6hW6rXfAHQEzgFDFTVPUA48JbXwl4cQP7AqGRhYDawDLgZ6Jf2tuZcSpWCEiUSxMx9dUXOH6G1utP31q8Ye09v+PVSqP+6ifV4AXkiWSyZQcGCBfh02KvnpO4eV3fi2v/dSf26NeKtI694scxu69+TW+9+gneHj6bzFZdT+pKS/DrhcwBmzV3AgoV/c1nzS3nptQ+YNfdPzp5Vnnz4DoKDg1m2Yg1r1m3khh6d6d5zECKCiPDB0BeIi4vj4SdfpUmjenTq1pe2rZvzzOP3pOse5BCOYhw+4kSkGlADSN4vHIBUI4CIyDJVbSQi9wIFVXWIiKxQ1QYZavY5JKMRQALRsSNER8PixTB8ONx3nxlHK1PGf/5Tp8zY25evT6VPrUdMoOLiLaDh21CiRaa3z2I534mMjGTyhLHc2qd7djclR/P28K958NGnyZcvX6bWm50RQETkb6A1UAT4E1gCnFbV3l7Ke3GPCRKRJkBvwF3U5KKc8VivHqxZYyZLr1wJxYtD6dKB8+fJY8JiTVvZBbqshqYj4fh2mNESFt0Opw4GLmyxWCwXF6KqMcB1mKgfNwJ1vBb2ImYPAy8Bk1V1jYhUwnQ9XnTUqwcnTsCWLaabsV691HsMq1Z15poFhUCV2+DqDVDzMdj6BUyuDpETs6LpFovFcr4jItICYzhNcdI8z0dINaOqzlbVLqr6quMIsldV705fW3M27vjY8uXGqzGg84cPVaokCWmVqyA0fBM6L4f85WFBbzi+45y012I538loBJANm7byv1seiN+Pi4ujZQf/E6K37YjkljseA+DBJwYnO96pW990XcPDT75Kx6v70KrjTSxYuAyAmXP+pHWnnlxxTT/WbzQelF98/RPVGnSIb0NSZs75kyu796dTt74sW7GGAwcPc/mVN9Px6j5c1+suTpw46bfcBcSDwFPABFVd6xhOqcZkdElVzERkjIiEikh+YDWwWUQeTq3chUitWhAUZKKBnDiRsvOHS9WqcPhw4vlpAITVMUvHoLB4kAk3YrFchLgRQIBkEUC6XNE2xbLVq1ZiZ+RuTp40cQr/WLCEVi0ap3rO9954LmON9uGNwY8zc/LXfPP5u7zx7qcAvPbWR/z68+d8OWJofDirqzu3Z+r40X7rOHHiJJ998T1Tx49mxqSvaNSgDkXCQpkzbSwzJ39No/q1mTp9bqa1+XxEVeep6jXAhyJSUFW3qmrqHjgOXky4eqoajZk4PQOoANySrtbmcPLmherV4ZdfzL5XywwChLUqGGFWsN49Hf79Mt3tiouDo0dTz2exnI9kNAJIh3YtmTVvAQC/TJlJ96s7cebMGa7scQsduvahZ7/7iIuLS1SmXedegLEEm7W9jl4DHuRwVHS62h8fueNYDPXqVI9PL1AgP6UvKcnWbabnpXixIoSE+Hc3WLhkBUFBQXS78XYG3Pk4x4/HEBwcHD/FIC7uLFUqV0hX+3IKIlJXRJYDa4F1IvK3iNT2Wt6LmOVy5pV1B35R1dNAqmvMiMhoEdknImt80oqKyAwR2eS8FnHSRUQ+EJHNIrJKRBr5lOnv5N8kIv29Xti5ol49swJ1fBirVEg1en7Vu6BEa/j7IYj5L11tevJJqF3bGneWnElGI4D0uLoTk6YYy27RkhW0aNqQkJAQfv72E2ZN+Zoa1Ssnmxvm8upbH/LD18MZMexVdv2XPEzWTf3uSzbPbP+BQ8ny3dj3XrreMJD2l7eMT9u77wDrN26N72ZMiX37D7Bn734m/TCS5k0bMvKL7wFY8vcqWrS/nrl/LCSiwgU/afpT4GFVraCq5TEhrUZ6LexFzD4DdmDcJeeJSHngmIdyXwBXJUl7EpilqlWBWc4+QGegqrMNwsToQkSKAi8AzYCmwAuuAGYXbtdiojBWKVCxoumaDBhwWIKg2Sg4exKW3JlmRYqJgZEjzYKi+/enqWiGOXrUiOjvv2fteS0XHm4EkB5Xd/J73DcCyJEjiS2ohvVrs3rdBhYvXUn9ujUJCgri+PEY7rj/GTpe3YfxE6eze4//+A5HjhylfHgZChYsQNXKEcmOjxszjBmTvkq0lSiefLXdH74azh+/jeP5we8C8NqLj9L3tocZ+v4IWjRtmOr1h4YWomXzRgQHB9O2dTM2OALY5NJ6/DX7J67p2jFR3MfsRETCRORHEVkvIv+ISIv0GCp+KOC7bpmqzgU8TxPw4gDyrqqWUdUrnLhZO4H2Hsr9DiR9hOkOuP1pX2K6Lt30MWpYCISJSGngSmCGqh5S1cOYbs6kApmluGLmZbwMjHt+gwYwdiycPh0gU2hVqPcq7JoE275OU3vGjYMjR8z7rA5qvGEDrFsH33yTtee1XHhkNAJIi6aNeOaloXTvasRwxuz5VK0cwczJX3NttysCRg0JDS1I5K49HD8ew2Y/YbK8WGanTpkfdsGC+clfwMz7at60Ib9NHMMTD98Z0Nr0pXHDuvEW3KrV64moUJbTPn8YoT5RQc4D3gd+VdUaQH3gH9JoqARgq4g8JyIRzvYskLpZ65BqBBAnOv5zQBsnaR4m2HCgv+aUKKWqu533e4BSzvuyGJF0iXTSAqX7a+cgzM0id+7c6WiaN9xxsoapP2zFM3gwdO0Kn3wC9wcazqz+AESOh6X3Q6n2kN/vZSZjxAgoUsQ4mWzaBC1bpl4ms9i1y7zOmpV157RcmGQ0AkiPbp348pufaH95cwCaXFqfIe98yt8r1lA4tBBVKvkfb3r60bu5vvfdVK0cQbnw5NEPxjnxEVOi98CHOHIkmri4swx+3vjGDXn7E2bPW0DRImF8+O5LAEyZPoeh741k67ad9Ox3H9+PGcaYseOpU6sajRrUoXXLJnTo2od8+fIyZuRQVq5ez1MvvElQUBBFwgrz+Sdvpvf2ZBpOJKg2OH4TzrDTaRHpDrR1sn0JzAWewMdQARY6Vl1pHx3w5VbMNDDHM44/gAGe2+YhAsgPwEYSLKq+QE1VTXVBIBGJwMxPq+PsR6lqmM/xw6paREQmA0NUdb6TPgtzI9oCeVX1FSf9OeCEqg5N6bznKgKIy4wZ0KIFFEwe5s0vqnDFFbBsmbGeigTqKI3eBNPqQ6l2cPnkVCexrV5tLMQhQ+Dpp802OLnH8Tnjww/h3nvN+23boMKFPT5tyQRsBJDM4RxGADmN8Vp3GaGqI3yONwBGAOswVtnfwAPALve/3ZnCdVhVwwL9t6vqUo/tGaqqnhZx8zJmVlVVn1HVjc72HFDFS+V+2Ot0H+K8uh3Zu4ByPvnCnbRA6dlKp07ehQyMJg0daqynV52HzyNH4J13YN48n4yhVaHBEPhvKmxKyRo3jBgBuXPDbbdBRETWdzNGRia8t9aZxXJBEKuqjX22EUmOh2CWAvtYVRsCx0noUgTAscIyyx3N87o3XsTspIg0d3ec9+mdvTcRcD0S+wO/+KT3cwYLmwNHHDN0OnCFiBRxBhSvcNJyHPXrwy23wLBh8NRTxjHkkUfgzaQ9B9XuNd2MS++BOZ3hyDq/9cXEwFdfwQ03QLFiZgpAVq9qvWsXlCtngjBbMbNYLgoigUhVdRd++xEjbmk1VLziOSq7FzG7GxjleKNswbhK3plqC0S+Bf4CqotIpIgMBIYAnURkE9DR2QeYihno2+zUfzeAqh4CBmMCTi4BXnbSciSvvAIhIaZbsFUr4wkYFZUkkwRB26nQcCgc+Aum1oO/H4TYxCvgfv+9se4GDTL7Vasayywr3fMjI42YtW8Ps2fbqQEWy4WOszTLThFxJ9R1wHQ5ptVQicfxhPS3FSMzxUxVl6lqbYxrfBNVrYuZOJ1auf+pamlVzaWq4ao6SlUPqmoHVa2qqh1dYXK8GO9R1cqqWte3P1VVR6tqFWf73OuFnY+UKQNz5pixs4kTjXt/MjEDCM4DNR+Bbps5VPR22PA+TG8KUWsBs47a448ba6+N45ZTpYoRtwMHsu56IiMhPBw6dIA9e+Cff7Lu3JYLg4yGswK47Z4n2bx1OytX/8PylWvPcYv9h6X6b/deruzen8uvvJlZcxcETPPl7Q9G0a5zL/oPepQzZ84ETDsPuQ/4RkRWAQ2A10ijoZKEv4GlzqvvtpQ0OBp6DuLouMe7VlHqLj4WvzRtmuAJGRYWQMwcDsUUp/YtH9P5zWnEHN4H0xtzZv1obrjBLC/z/fcJPiKpTs7OZFRNN6MrZmC7Gi3pIyPhrHwxYua/Wz46UquxAAAgAElEQVQpZ8+mGvchIP7CUr31/kheeOoBpvw0iiFvfxwwzWXf/oPMm7+IOdPGUrd2dSZOmeU37XxEVVc442n1VLWHqh5Oj6HiU19FVa3kvCbdKnltl2cxS4JdXTITSE3MHnzQWFonwq6i4j2r2BLdmlzLBtKw0KeMGWNCa7mkGDbrHBAVZcbtypY1zieVKlkxs6SPjIazchn15TjeGT6K/oMeRVW595EXubJ7f7r3vIPDUUeYN38R1/W6i+t63cVvs+anu73+wlKtXbeRFs0aUrBgAQoWLEB09DG/aS5/r1hDm1ZNAWh/eQsWLlnuN+1iwPF6T+m4iEiq4U+8rDTtDzs6kgmEhRlBOHMGnPBu8UyaZBw8nn8ennsObr+9FDXvmsz4h67j41vvIqh+fswsCYMbaSSrLDPXkzHc+Yp16GAmcMfGmnFBi8UrScNZ7d2XPJTNseMxzJz8Fd//NIUJk37jvjuTL3Q/sP9NxMbGcWu/G5n862zKh5dm+Nsv8uuM3xn5+Xc0a9KA06fPMPnHzwK25b5HX2L9hsQ/onffeJY6taoHKGGIizsbP7G7cGghoqKj/aaFhho36CNHogktZN6HhhbiyJGjftMuEt4SkSDMONvfwH4gL8Zrvh1mXO4FjPNJQAL+7TgBH/2JlgAl09dmiy9hzoy7I0fMQp8uhw/DHXdA3brwzDNGHEaPhooVczP1vx/pesnVsPAWCMoDFYznau7cZp5XVllm7oRpXzEbOdKMBzZtmjVtsFw4uOGsPnr3ZT4dPTbZcd9wVlv8ROpIyvqNWxk3fiozZs8nNjaOZk0aANCwfq0Uyw0b+kK62h8UlNBZFX30GGGhoX7TXEJDCxH5314Ajh49RuHChfymXQyo6o0iUguzjtmtQGngBCayyBTgVVVN1YM+pWfoVCdFWzKGK2ZRUYnF7LnnYN8+mDzZiBSYsbHnnwfIC7G/wJyr4M+esG+eibyfq2C8R2NW4FpmZZ1AJW3bmtcFC6yYWdLOVZ3aMGP2fBo3qsunflZJSS2cFZjo9aecEFDVqlSkd8/uPHTvrQCcOXOGBYuWxUehD0R6LbM6tauzcPFy6tauztGjxwgNLeg3zaVxw7p8OupbHr3/NmbN+4tmjRv4TbtYUNV1wDMZqSOgmKnqloxUbEkdXzHzZelSuPxyaBQoJGdIAWj3G6x8Bja8B/9Ng2YjqFKlA998I6ga8Vu9GsaMgRdfhAKew3V6IzLSnKN0abNfsiSEhsK//2bueSwXBxkNZwXQtHF9br/nKdb+s4l3hzzLQ0++wpXdjbf4vXf2J7RQ6j8CL5aZv7BUj9x3GwPvfoITJ07y3JP3AfhNSxy+qjHtOveiXHhp7r+zH7lz506WdjEgIteldFxVx3uqJ9BTjojMAcZhln35zyc9BGiJmUsw/3x0lz/X4awyiz/+MK71M2ZAx44J6dWqGSH77jsPlez7w3Q5HtvKwdiavPb9QJ4e2Y9iZUrQqRPMnAmtW8OUKVAoE3stbr/dWI67fWaM1Ktnxu7c9d4slqTYcFaZw9BhX/HQY8+ci3BWMaqayY++qZ7T1ZCSGG2Z7ey3Axao6tVe6knJ5u4K5AImOJOeVzlzCP7FBH/8+HwUspxEIMvs4EET1cMTJVtDl9XQdCRBeQrzdu9HCZtXkci5I5k5U7nqKtP1d+WVCdH1M4PIyIQuRpeICBOj0WIJRP78+Tl6PCbZYpkW75w4cZLYuLPkyZMnu5uSKajqAFUdgNGbWqp6vapeD9R20jyRUjdjDPAB8IGI5MGo5glVzcJpuRc2/sQsLs44gHgWM4CQ/FDlNvbF3UarDmuZ+cYDhP83iCmPT6TFgyOZveASbr4ZOnc21mCw/8Vu00RkJFROsrJFRISJNel2c1osSSlSpAhlwisxftJMmjWuSy7r+pomTp0+zZzfl9Kk2WWpjv/lQMoliQ6yFyjvtXBK3oyhSZKO+KaravrWGLfE40/MoqKMGKRJzBwqVoT1u2vz8h+/kT9yGK/3fJLcC+pwfaP3eeONXjzyiLBtW3IRSg+7dplxPV8iIiA62lxDwJUBLBc1IkLPm3vx2/Rfmb1gHXGx1kJLC7ly56JGvWa0aXN56plzHrNEZDrwrbPfE5jptXBKj0VrMa75ApQBjjrvCwL/kTh4pCUdFCxo5ob5itlBE9WHoskXs00V1z1/5GdBxMU9wL2vXEHFvbfCX33oV2Es7xX7mO3by2dYzI4fN9ajv25GMF2NVswsgQgJCaFLV0/DIJaLCFW9V0SuJWHtzBGqOsFr+YB2qqqWU9XyGD//a1U1TFULY1aHnpyRRlsMIsmjgLhilh7LDEwkkLg4sxhoxQY1odN8aPQeRc/MZe0btSkU+RbEpWdd1QSSzjFz8RUzi8ViSQcLMA4gs4A/01LQS6frZao60d1R1UnAZWlqniUgYWGJHTMyKmZujMaHHnISgoKhxgOcuWIts9e1p0nI42YB0N0z0t3m1MRse+pzWi0WiyURInITsBgzx/kmYJGIeJ7v7GX0dbeIPAl87ez3xgzMWTKBpJbZISeUc3rFrH9/KFzYLMviS56iEdw59hf+DZ7Kg63uhzlXQJmroeGbULhmms6RdMK0S5Eixv3fWmYWiyUdPINZmWUfgIiUwIyZ/eilsBfLrBdmfGyas5UH/peuplqSkdndjE2bwmuv+fcmLF8epizvAl3XmKgh+3+HqXVhyd0QG5Mob0wMvP22ic6flEBiJpJ+9/xPPjHz1iwWy0VLkCtkDgdJQzD8VC0zxxX/HhHJb3b1RGplLN4pXDhxPMWDB41TSOHCmX+uChVg5UogOC/UehwqDYDVL8Gmj+DQMrh8EuQtAZhYkI8+CjVrQpcuievZtctYYf6iiqRHzFTh6afh7FnYuNFEE7FYLBcdv/rxZpzqtXCqqicitUVkCbAR2CQii5ygkJZMwJ9lVrSoEbTMpnx5s7BnfNCXvCWgyXBoPR6iVsJvLSDaKOvnznT4SD9xqv1NmHZJj5jt32+8I48cgaeeSltZi8VyYaCqjwGfAvWcbYSqPuG1vJe/zE+Bp53VosMx/Zoj0tNYS3L8iVl6uxhTo3x5OHnSiEciyvWADnPgzBH4rTl7Zr7Cri1mzSjX2cMXd4Vpf0REGFFKaZ22pKxfb16bNDEW4cKF3staLJYLij+BORiPxkz3ZiykqvGub6o6E7g41ibIAsLC4Ngxsw4YJFhm54IKFczrjh1+DhZvDlf8BUUv5ZJ9z7Hzg3KMe7AXh/ccSpbVXWE6pXOkxTpzxWz0aChTBu65x0wvsFgsFw8Z9Wb0ImbbROQpEQl3tieBbelqrSUZvmuawbm3zCCAmAEUqsLpVr/R7JUN/PrvffRo9CP9qvSCswnKcuYM7N2bcjcjpF3M8uWDWrWM08myZTBqlPfyFovlgsD1Zuyvqv2ApsBzXgt7EbNbMd6MU52tnJNmyQSShrQ6dOjciZlrNaU0D2zKFFj8TzWCGr/DZyuG0bjsdFj9Yvzx3bvNmFtK3YyQdjGrXt2ME/bsCTVq2Mj7FstFyDn3ZjwI3G29Gc8NWWmZuR6IAS0zjONH6dImyv5Dvw7iqwWL6csrUKwJhF8Tv16ZK4xJKVrUhOlKq5g1a2beu2ukRdvInxbLxYb1ZszJ+FpmJ0+a+V3nSsxEEjwa/bF3L0ydCn37QkgIlC0r3D7iQ+IKXwp/9YV9f7B1q8kbKL5jWueanTxp8taokZAWGmrFzGK52HC8GUdgvRlzJu58sqiojE+Y9kKFCoG7GadNM44XvXub/bJl4dSZvGwv/xPkKQ4zL6fqsUcokPcE5VIIMx0R4T2k1aZNptvSipnFYlHVn1T1YWfzHGQYrDdjtuNrmWWFmKVkmS1YYNpTp47Zd8fFth+oAJ1XQtW7aFXsHVYOaUiu3T/C2Vi/9aTFMnM9GX3FrHBhK2YWy8WGiFwnIptE5IiIRIvIURHx/E9gvRmzmewQs/374YSfkc8FC6B584QJ267HYmQkkKsgNPmQe8fPIG+eWJh/I0ysDP8MhbiTieqJiDDX42Wu2fr1pmvSDZAMxjI7csRncrfFYrkYeBO4RlULq2qoqhZS1aTragbEejNmM4UKmT9zXzE7V/PMIMFxY+fOxOlRUbBuHbRsmZDmipnvxOnv53Vk8PIN0OZnKFgJlj8GC3qDno3Pk5bo+evXmzblz5+QFhpqujv9Ca7FYrlg2auq/6S3sGdvxvSewJIybhzGqKiMR8z3gjvXbPt2qFYtIX3RImMJ+YpZgQLGcnRDWkVHw4EDUKlyMIR3N9v6d2HZw7DyaWgwBEjsnl+/fsrtWb8+cRcjGDFzz+crchaL5cJDRK5z3i4Vke+Bn4H4EOeqOt5LPamKmYhUAR4GInzzq+oVaWivJQXckFZZ1c0IycfNFiwwwtq0aeL08PAEy8z1ZKxUySdD9QcheiOsewMKVYXKA+PFzHXjD8TZs0bMWrdOnO4rZpdc4uWqLBZLDqabz/sYwFdbFMgcMcOsJTMKs56ZDTJ0DnAX6Dx40ETCyJfv3J2rbFkjWknF7K+/oG5d0+2ZNH+KYiYCjT+AY1tg8Z0Q8x9FK91KiRJlWbMm+fknTIDatY1VuGuXmYqQ1DJzPTytE4jFcuGjqgMyox4vYnZWVYdlxsks/vG1zM6lVQaQK5eJf+g7nhUXZ4L79umTPH/ZsrBqlXm/ZYt5TTbHLCgXtPoB/rwZVj+PrHmRiY905q2ZbwPV47OdPAk33WS6IZcv9+/JCAmWme8K3BaL5cJERB5X1TdFZBjGEkuEqt7vpZ6AYiYirhfJLyIyCJhA4n5M+9ycSYSFGasnK8QMkrvnr10LR48mHi9zCQ+HPXtMTMatW41zit+11nIXhnbT4OgW2Po5dc98zNCrO3Pm2BJyFTQXtWKFCai8eTM8/LCxBCHlMTOLxXLB4zp9LM1IJSlZZmsxKumuWewb8FExK05bMgHXAaRgwawRswoVYPHihP0FC8xrixbJ85YtaxxD9uwxllmgyB/xFKoM9V9h/tputA1rw6nZN5Hr6ukQFMJS56vapw+MHGm6GwsXhlKlEldhxcxiOX8RkW3AUcywU6yqNhaRF4HbAXeBqadVdaqT/ylgoJP/flWd7lufqk5yXr/MSLsCipmqphDjwZKZuN2M+fJBvXrn/nzly8NPPxkHjKAgM15WsmSSsTAHd+L0rl3GMmvc2Ns5yjVoxqA7R/DlnbfA8kfh0vdYssQ4dHz2GaxZYyy1Zs3MsJsvVswslvOedqp6IEnau6o61DfBCX14M1AbKAPMFJFqqhrnk2cSfroXXVT1Gi8NSqmb8XJVnScifitS1YleTmBJnbAw88cdHJw1lllEBJw+De+9Bw8+aCyzli2TiwokzDXbts2Ms/Xs6e0c1arBuCX9GXjdctrwPhRpyJIl/WncGPLkga+/hksvTYg24osVM4vlgqE78J2qngL+FZHNmKVd/vLJM9RvyTSSUjdjJ2AecKOfYwpYMcsk3Cgghw+f2wnTLv/7n1li5ZFH4PvvzRjWoEH+87qW2cKFZrzLn/Xmj5AQMyY2ePJQZjy1Cl18J3li6tOkSQPAdDEuWZK8ixEgd27Im9c6gFgs2UCIiPiOXY1Q1aSxeBX4TUQU+NTn+L0i0g8z9vWIqh4GygK+a8dHOmkJlanOc9+LSD6gvKpuSHPDAx1Q1Wed175prdSSNlwxg6yxzAoXNtHxv/rKWGbg3/kDjLjmyQO//272vYoZQIMG8NNPIWiLbzk9sRE/PnA9W6v9DZgLdh1A/GGDDVss2UKsqqY2mNBKVXeJSElghoisBz4GBmOEbjDwNmmMFCUi3TBWWm6goog0AF7OjG7GFN0hVfWDtDTUEpisFjMwXYr9+pl1y+bODSxmIqarceVKs5+qA4gPDRoYR4/Ig6X4Y+8P3FjscsJz9QP9GSTlSGpWzCyW8xNV3eW87hORCUBTVf3dPS4iI4HJzu4uTAhEl3AnzR8vYrog5zr1rxCRil7bldI/SolUtnQjIg+IyBoRWSsiDzppRUVkhhM1eYaIFHHSRUQ+EJHNIrJKRBpl5NznI9khZi6lSplxMH/jZS7h4cZZJFeuhDE0LzQwPYqsWAET/2rJq9PeJs+BSbDuzVTLWjGzWM4/RKSAiBRy32OidawRkdI+2a4F3JAJE4GbRSSPI0xVgcX454yqJh1c8BxuPKVuxucCHcsIIlIH48LZFDiNWV10MjAImKWqQ5zI/E8CTwCdMTegKtAMY842Oxdtyy6yU8y84ApYxYrGScUrdesakVyxwoyPxTW6D8r/CauehZKXQwk/cwEcrJhZLOclpYAJYp5+Q4CxqvqriHzldAsqZlWVOwBUda2IjAPWAbHAPb6ejElYKyK9gGARqQrcDyzw2jAvK01XEZHpIrLS2a/nzBtILzWBRaoao6qxGCeT6zBeL+48gy+BHs777sAYNSwEwpI8BeR4fCchn49i5jqBpGW8DExorCpVYPZs161foOkIyF/eRAs5fThg2cKFrQOIxXK+oapbVbW+s9VW1Ved9L6qWldV66nqNaq626fMq6paWVWrq+q0FKq/D+PCfwoYC0QDD3ptm5clYD4DXgLcNT5WA34CH3lmDdBaRIqJSH6gC6ZPtZTPDdiDeQIA4/niu2BJMm+YnE5OsczSMl7m0qCBGZMDaNIEEynksu/gxH+w6LaAi5ZlhmU2cyY89ljG6rBYLFlGKVV9RlWbONszQApuYonxImYFVDXe1FNVBc6ko6Fu+X+AN4DfgF+BFSQJYOycI01LM4rIIBFZKiJLY2P9r4B8vuLOqxJJLGznC+m1zCBh3AzMvDIAijc1y8XsHA/LHoLTyVfxzAwx+/JLePttM6XAYrGc9/wkIvGGioi0AUZ7LexFzA46A3fqnKAHxnJKN6o6SlUvVdU2wGFgI7DX7T50Xvc52T15w6jqCFVtrKqNQ0K8xE8+fwgONn/eYWFpG5PKKqpUMa+1aqW9rCtm1aolielY4yGofDtseB9+qQhrX4czx+IPu2KWkdWmN20y5ffuTX8dFosly7gD+FlELhGRLsAwTM+dJ7yI2b2YJWBqiMh2jGPGXelpqYszPwERKY8ZLxuL8Xrp72TpD/zivJ8I9HO8GpsDR3z7Yy8UwsLOzy5GMAtsLlli3PjTiitmTZokOSBB0GwEdF4OJVqZxT1/qQArn4OT+wgNNRbVyZPpb/emTeZ19wX3bbFYLjxUdQnG6eM3jJt+R1XdmWIhH7yYMDtUtb2IFAZEVaNEJKOdYT+JSDFMd+U9Tp1DgHEiMhDYDtzk5J2KUefNmIXbMmXtm/ONsLBzu45ZRvEakzEppUvDXXfBjf7iyAAUaQBtJ8GBhWaBz7WvwvqhXF7iZeAxjhxJ3305dChh5e49GepHsFgs5xI/sRnzA0eAUSKS8diMPvwkIj1c/3/HqpoCJH3W9oyqtvaTdhDo4CddgXvSe66cQpcuJoTThYYIfPSRh4zFm0ObCRC9AVY8QYvIx/lfy7JER/eKX2360CEz36148dSrc60ysJaZxXKec85jM7pMxVhMN2LGqyZhuhotmcjrr2d3C84TQqvDZeM48OMVjL79Vv7dWxmqmWmFAwea1QXmzEm9GitmFkvOwDc2Y0ZIVcxU9WMRyQ2MByoDd6vqH5lxcovFL8G52VDiRy5Z2YxKu3rA8cVQoBzr1xthUk05YgkYMQsKMmvEWTGzWM5fRGS+qrYSkaMk7m4UTOdcaICiiQjoACIi97ubkxQBLAcapha30WLJKPmLFOeatycSdPY4zLgMjZzEzp1mIvX+/amX37jRLEJavrwVM4vlfEZVWzmvhVQ11Gcr5FXIwHtsxuKY7sXtZEJsRoslNQoXhnW7avNb7EzIFYr8fg1f3HYDpcP+Y+PGxHl//RWGDUuctmkTVK1qHFCsmFksORMR2eE1b5bHZrRYvOBOJN96pCn0XsbeeUPp2mAwDSss588NK2jVqlB83qFDYf58uO024/moasSseXM4ehQ2pHllpMTExcG0adC1a+rdmxaLJVPx/ItLqZvxbed1goiMT7plRistlkAUcrQqOhoIzs3y009zxZDfiCixjZonHojPp2qWpzl1Cv5y1q7dv9+Ucy2zPXsyNvl64kTo1s0IpleOHcvYOS0WC5AZUfOB753X4Rlri8WSdvLkMZsb0mrnTpi/oTXvTH+Kxzq/Cju6Qvnr2bMHDhwweebMgfbtEzwZq1Y1gnL6tHHrT++k9FWrzOuaNdA62aSS5Bw+bEKAffedEUGLxRIYEXk40CGgoNd6AlpmqrrYeZ2VdCONK4haLOnBNz5jZKTp4psf9QKr/2sMiwdBzK54ocmXL8Fl31fMSjvrK2Rk3GztWvP6zz/e8u/aBTExsH59+s9psVxEFAqwFQTe91pJeoMYeng+tVgyRuHCicXskkugRq1c3Pz+N6wZ2hCZcxUntr5AkFxLv37BjBoFx48bMQsOhoiIBBHbvRvq1ElfO9Y4ywx6FbMoJ27ywYPpO5/FcjGhqi9lRj1eYjNaLNlCaGjCmmaRkabrrnp1WBdZjb1VvoO4GHoUu5Gt71floc7vUDjvAebPN275lSqZlbEzapmdPp1g6aVVzNzuT4vFcu5JyQGkXoCtPpArC9touUhJ2s1YrpyJvg+wfF83uHojD/w0nmNxZal+/BF2DS/LJVt6UiDmT6pWNfkyKmYbN5qAx3XqmO5DL8vSWMvMYsl6UrLMPgywDccE/bVYzim+YrZzp7HMXDHbuBFOnQnmo4nX8s2+P6DLKn755y4i8sxk9P9ac0frN0GVggVNFJBAwYaPHIGffw7cBne87IYbzKuXcTArZhZL1pOSA0jrlLasbKTl4sQVs+hoM18sPBxKlDArDGzcaLr9YmPNEjWE1WVN7vcoc88Oflh8I9eUfwL+6g9xJ1OcOP3JJ3DttYljOfqydq0Ji9Wjh9n30tVoxcxiSTsiUkpERonINGe/lrOKiifsmJnlvMV1AImMNPvh4cajsVo1MxHa9WSsV8+8tmsHMacKcPOw79iUfzBs+wpmXk79KtsDitnKleZ14UL/x9euNYuT1q5txuCsmFks54wvgOlAGWd/I/Cg18JWzCznLa4DyE5neb5yznrj1aoZy2zlSrNsjjs+1qKFmZsGQkj9Z6H1BIhez+c3NaR6ocl+z+EK4qJF/tuwdq0RspAQc560ipmdOG2xeKa4qo4DzgKoaiwQ57WwFTPLeYu72rTbBRgebl6rVzcC99dfCUIDRthatoTcuU2AYcr1gKv+JupMBUb06gZLH4CYyPj6T51KGAPzZ5mdPAmbN5tzANSsmTYxi4013aMWi8UTx51FmxVARJpjFun0hCcxE5GbReQZ5305Ebk0PS21WNKCG59x3TrzWsbpfHCdQP76yxkv8+GJJ+CFF8w8MwAKVeG7Q3/x0Yy70I3D4JcKMO8a2DOT9etN3MXKlY2Vd+JE4ro2bDDHfcVsyxYjginhihnYrkaLJQ08AkwEKovIn8AY4D6vhVMVMxEZDrQD+jhJx4FP0t5OiyVt+IpZqVLG4oIEMYOE8TKXK6+Ep59OnFaydF7u+eIjttffArWehIOLYXYnold/B5gAxbGxsGxZ4nKuJ6OvmJ09G9hZxCUqyjiNgBUzi8Urqvo3cDnQErgDqK2qq7yW92KZtVTVO4CTzgkPAbnT0VaLJU0ULmxe161L6GKEhDEySG6Z+cOda7bzUEWo/yp03wYlWtOcW2hb+0/69jXHk3Y1rl1rLDxXPGvWNK+pdTVGRTndnNiJ0xaLV0RkFfA4cFJV16jqmbSU9yJmZ0QkiIR+zGI4A3QWy7nEtcz2709w/gAoUCBB3JJaZv5INnE6OC+0mcDeo+UZ/2B3yoZuJiIiuRPI2rVGyIxTiRmrE0no9gxEVJTpugRrmVksaaAbEAuME5ElIvKoiJT3WtiLmH0I/ASUEJGXgPnAG+lqqsWSBkJ91pj1tczACEt4OBQtmno9fqOA5CnGTR9NJThEYHYnHr1+DMuXnkxUzvVkdMmf36xenZJlpmrErEoVs2/FzGLxhqpuV9U3VfVSoBdQD/jXa/lUxUxVxwDPAkOBw8CNqvpdOttrsXgmJTF77TX47DNv9RQtauaI+YrZ/v3w15oqTD46GYLzcE+j/ix4vBxH5z8Lscc5ccI4e/iKGaTu0Xj8uHEaqVjRWHFJxSwqyhy3WCzJEZEKIvI48B1QA9Pt6AkvDiDvAAVU9X1VfU9V16S/qRaLd1ISs6ZNjbOHF0RMxH1fMVu92ryWrNkMuv7DutIzmb+hFQV3vAbTGrF9+VJUk4tZrVoJXo7+cD0ZixUzkUp8xezkSSNyo0Z5a7fFcjEhIouACUAwxmhqqqpvey3vpZtxLfCKiGwSkSEi0iCdbbVY0kRKYpZW3BWnXdzJ0nXrAiJUatGBnh9OYOSWWZw9E0OVrS14tscrNG6YuOuxZk3jmr9tm//zuGIWFmYEzVfMduwwxzduzNi1WCwXKP1UtZGqvq6qW9Na2Es34yhVvQLjLrkdeE9E7LKDlnOOu9o0JHYASQ9J4zOuXg0lSxqXfzATrhs2hJET29Fl+Cp+Wnw9g298joqrK8P69yHWTEJr3NjkD9TFmZKYbd9uXq2Ho8WSgIi40766isjDSTev9aQlAkg5IAIoSxoG5SyWjOBaZ+6E6fSSVMxWrUruCdm8OSxdCrPnFyGkzbfQfiYUqgrLHoSJFWHta9SvcYhbb4U334QlS5KfJyUxc6056xRiycmIyDYRWS0iK0RkqZNWVERmOD14M0SkiJMuIvKBiGwWkVUi0shPlQWc10CrTXvCy5jZayKyAXgT2AQ0V9XOXk9gsWSE0FATKT9v3ozVU7eusYhefNGMd61Zk1zMuneH4sXNkjDX3yBwSQfoOBc6/g5FGsLKZ+CX8nw08AGqRkQzYKhWM18AACAASURBVEDyaCCHD5tXV8x8rTBrmVkuINqpagNVdfoqeBKYpapVgVnOPkBnoKqzDQI+TlqRqn7qvJ2pqi/5bk5dnvBime0C2qhqR1X9TFXtc6UlywgNzfh4GcAdd8CAAfDSS3DLLcYZo27dxHnat4d9+6BLlySFS7aGdtOgyyoodz15tn/IkldbcnzfvwwenDirr2VWvLh/y8yKmeUCpDvwpfP+S6CHT/oYNSwEwkSkdIA6hnlM80tIoAMiUlVVNwF/AKVEpJTv8bSEGbFY0svNNxu3+owSHGzGudxX8D/hWiSFSsLqQosvoWI/Cv1xAyvfbEbXIT+zvk9LatQwWVwxK1zYWGbHjxvrLU+eBMvMdjNacjgK/CYiCnyqqiOAUqrqduTvAVy9KAvs9Ckb6aTFd/qLSAuMT0aJJGNkoRjPRk8EFDOMmTgQM2na38W08XoSiyW9PO55lknqBAXBp58aYfnhB+Nmny4u6QBXLiTvjKuZ+VQ7li9+B6rfDSJERZkIJblyGTEDI15lyiRYZocPm1iQISn9+iyW7CHEHQdzGOGIlS+tVHWXiJQEZiR1CFRVdYTOK7kxY2MhmHEyl2jgBs8ND3RAVd0VPtsnjZElIpnwrGyxZD1BQTB8OLz3XgbFJLQ6ZzstYvYrfejS4F74fTo0G01UVHHCwkwWXzErXhz++89M4D50yGwlS2b4ciyWzCbWZxzML6q6y3ndJyITgKbAXhEpraq7nW7EfU72XRjnQZdwJ823vnnAPBH5QlW3p7fhXsbM/C1bGGApQ4slZ5AZVlHe0KLcOmYy3216F3ZPh2n1KCZL/IpZZKSJuH/ppQlpFktOQ0QKiEgh9z1wBbAGs3RLfydbf+AX5/1EoJ/j1dgcOOLTHZmUGBF5S0Smishsd/PatoBiJiIlRaQ+kE9E6opIPWdrBeT3egKL5UKmXLkgPl/wIFy5CILy8kKrDrSu8SeQWMzc8TJXzKwTiCWHUgqYLyIrgcXAFFX9FRgCdBKRTUBHZx9gKrAV2AyMBO5Ooe5vgPVAReAlYBvgZwKMf1J6Pu0K3IoxCz/yST8KPOf1BBbLhUy5cs5q1UUaQKff2T+6A+9ecwXsmUSxYu0BI2bR0Sa/tcwsORknMkeyhZccL/cOftIVuMdj9cVUdZSIPODT9ehZzAJaZqr6uaq2BgaqamufrYuq/uD1BBbLhUz58iZMlSqQP5ybRvzO/hOVYF5XSh4dBWi8ZSYCDZxgcNYys1iS4fpm7BaRriLSEPCwLobBSzircSJypRNa5Gl3S29rLZYLifLljfu965K/ZVcphv+/vfMOr6pa+vA7IYGEDlIldBAJIkVUEEQ6FqQI2AuWC1awYEfsV7HX6/30KqBiRRREikqRZqP3EjpSRXov8/0xe5OTk3OSk0JCkvU+z3r22X3ts+H8MrNmzSyZBKc1peCc25g0oB26eyVr1lhEo5/JxImZw5GC50SkBPAA0B/4H3BfpCenOQwuIv8BSmKh+IOB7sBvqZ7kcOQT/JyR69bZROmdOyGmaBloOwFW/o/GBx+kWUx9nt30OdWqdaFwYYiLc25GhyMYVR3tfdwFtE7v+ZHEdLVQ1bNFZJ6qPiEiLwE/pPdGDkdepIpXB3fdOqhRwyIWS5YEJApq9abHzZfxzpXdeKzVtRyLnQE0SJHmyuFwgIi8FWLzLmCmqo4MsS8ZkYTmH/CWB0WkAnAQyGTaV4cjb+CL2fr1yVNZ+RwvVIl7R4xkx76SPNS0CxzcRpkyTswcjhDEAg2xHMArsErT8cCtIvJGWidHImZjRaQkVml6LhYumakAEBG5T0QWichCEflcRGJFpLqI/O5lV/5SRAp6xxby1hO9/dUyc2+HIyspX96yffi1yiC5mJ12Gkz5syJdXh1JsZgtMLU7FcsfdG5GhyMlZ2MJjN9W1bexEP8zgW7YfLZUiSQA5ClV3elFMFYH6qvqoxntrYhUAvoCTVT1LCz31tXAIOB1Va0F7MBSaeEtd3jbX/eOczhOCaKiLBFyOMvMz884a3UTFhX7CLZN5dtrS/N6p1aWhX/Pyhzpt8NxClKK5CVfigClVfUYcCj0KUlEUgKms9+A9kALEblIRE7LaI+xsbo4EYnGJmBvAtoAw739wVmX/WzMw4G2Iqmmg3U4spXKlVO3zHxi61wDrX9kxtbexMg+WDwIxtS34p96PHs77XCcerwEzBWRwSIyBJgDvOxlGvk5rZMjCQC5A2gG/OKttwRmA1VFZKCqfpae3noJKl8B1mHjcT8Cs4CdqnrUO8zPrAwBWZdV9aiI7AJOA5KNOohIb6xeDgULFkxPlxyOTFGlCkyZElrMypRJfhxx7Zm8pz3PPguHd/5F9Ow+Vvxz/TfQ+DUofU4aqftTZ+NG2L8fatXK8CUcjhzBmzA9Bsv1CPCYqm70Pj+Y1vmRjJlFAXVVtYuqdgESgMNAUyDd8828CqRdMJfl6ZgpeXF6rxOMqr6vqk1UtUm0S0fuyEaqVIG//koKtw9lmZUvbyH5YAKnCjsOVYKLvoemQ2HnAhh/Low5G5a8CvvWkxH69bMiow5HbsPzuLUFGnjRi9Eicl4ap50gEjGrHJgY0vtcVVX/Bo6GPy0s7YDVqrrNy8Y/AmiOFW3zVSgws/KJrMve/hKAGz53nDJUrmzVq5cssfUSJZL2+WJWtWrSNt9a274ds8Jq3AhdVsO5/4XoojCnP4ysYsI252HYkxhxX1assH7s35+5Z3I4coD/YF7Aa7z1PYQuQRaSSMRsioiMFJHrvPYdMNXzY+5Od3fNvdhURAoHKPFiYBJJtWuCsy772Zh7ABO9fF8OxymBH56/YEFSLTMfX8yqVUu5LVl4fsGSULsPdPwVOi2FRi9DoTKw9DUYfz5sDywxFZ61a83qW7w4w4/jcOQU56vqXdj0L1R1B1brLCIiEbM7gc8wt2JT4AvgDlXdp6rpLtCpqr9jgRyzgQVeH94HHgbuF5FEbEzsQ++UD4HTvO33Y0VDHY5ThkAxC3QxQuqWWdi5ZsXrQN3+0HYiXL4MYkrAhDawdVqq/di9O2ncbsGC9D2Dw3EKcERECmDFnxGRskDEkVFpDi6p6nERmQ5sVdVJIhILxAH7MthhVPVJ4MmgzatIGvgLPPYg0DOj93I4TjZ+Squ9e5OLFlguxrJloWnTpG3J3IxpUbQGtJ8CE9vBpA7QciRUbB/y0PUBw2xOzBy5kLeAb4FyIvI85okbEOnJkeRmvAW4GxurqglUwXyb7TLSW4cjr1GiBBQvbpZRsGUWFwdbt3pZ9T1CuhlTo3A8tJsCE9vDL52gxdcQ3znFYevW2bJgQSdmjtyHqg4TkVnY0JMAXVV1SaTnR+Jm7Iu5F3d7N1wOuILvDkcAvqsxWMx8AqPtCxeG2NjkYvb777BlSyo3iC0HbSdZ3bSpV8CaL1Ic4ovZRRc5MXPkTlR1qaq+q6rvpEfIIDIxO6iqh/0Vz6fpJi07HAH4rsZwYhaIiLkafTfjgQPQujU8/njq5z30RGlenfMzlG0OM66FxA+S7V+3DqKjoUMHE8Zt2zLwIA5HNiMie0Rkt9cCP+8XkYgj5iMRs+ki8hAQKyKtgS+B0Wmc43DkK9KyzIIJzJz/668maNNSie84cADeegseHViMdTXGQsWO8EdvmDfghA9z3TpLrdXAqwPsrDNHbkBVi6lqca8Vw+YfPw9sBt6M9DqRiNlDWLz/UqAfMAFI429IhyN/kR7LDEiWOX/iRFsuWxZ+HG3GDDh0CI4cgedeLAwXjYKat8Ki5+HXG+DYIdauNVGtX9/OcWLmyE2ISEkReQqYDxQDzlXVByI9P5JEw8dU9T1V7aaqXb3PLpGcwxFARiwz3804aRIU9dKrzpgR+viffzYXYq9eMHgwrF4bA+d9AA2ehzXD4MdmVC34I1WqKOXLm1g6MXPkBkSkjIi8gE3XOgo0UtUBqpqu5BhhxUxEfhKRH8O08Znsv8ORp0ivmPmW2Z498McfcNttNtk6NTFr1gyefx4KFIDnnsMG3+o9Bi2Go4e288ktHXmmZStk21Tq18+fYrZrl0WVOnIVa7GsH0OB/Vj9svv9FulFUrPMBgBPBLWRQB1cNKPDkYz69eGss6BJk8iOL1MGduywBMVHj8Kll8I558D06SmP/ecfmDUL2rWzeWu33w5Dh0Kin+WqSnf+arycu4e8Tfm4ZfBzS96/siUVdDzHj+WvZDnXXQc335zTvXCkk5eBwd7nYiFaZKhqmg24ABgH/ApcHsk5OdkKFy6sDsepzJtvqoLqzTerxsSo7tunev/9qoUKqR46lPzY4cPt2OnTbX3jRtXYWNVbbkk6Zvp0O2b8mH2qS97QvZ9UUh2GHvy2kWriR6pH9qerf3PmqF5/veqBA5l80Gymdm3Vxo1zuhe5F2CfngK/4RlpqY6ZiUhbEZmMRZa8qqrNVPX79Imuw+EIxs8C8u23lh2kcGFo3tyCPGbPTn7szz9DsWJw7rm2XrEiXHEFjB6dNBnbn2MWX7UwnNmPxbVXctsHH3DowGH4/Rb4Lh7mPQFHI0vc88EH8Omn8OWXWfCw2cjWreZqdOQ/Uhsz+w3Li/g1FsW4RUTO9lt2ddDhyIv4YrZzJ7RpY58vuMCWwa7Gn3+GVq2SJzBu1cp+uJcts/W1a23pR1UmnFWIj365jTcTF9hk63IXwaLnYHQCbEj779EJE2z55pvJs5ecyhw8aELm56d05C9Ss8yOYkUxrwbewVLx++2dk981hyPvEliBunVrW1aoADVqJA8CWbPGxsbaBSWPu+giW/7ilcxdtw5KlTILDix7f40asGCBQPlW0HKEpcSKKQZTOsO0q+HYYUKxYYOJZP36MGdO+KCUUw1/kvjOnblHgB1ZR9jcjKraIjs74nDkJ3zLLDY2eRLi5s3hxx/tx1jErDJIKWa1a5v4/fIL9OljYhac5DhFRGO5C+Hi2bB4ECwYCAUKQdMhKSpb+1bZf/8LnTrZZO3mzTP9yCcdPx3YsWOwb1/SdAdH7kBECgHdgWoEaJOqPhPJ+ZFMmnY4HFmML2bNm0OhQknbL7jAfpRXrbIf5e+/tzGyunWTny9irsZffjHhW7cuaXqAT716VqzzcKABVqAg1H8C6j8Nqz+G+QNT9G3CBOtf06Y2ZeCbb8xaO9XZujXps3M15kpGAl0wr+C+gBYRTswcjhygcGE4/3y4/vrk230L6KGHoFYtGDUKevZMYTwB5mrcuNHckKHELCHBBHHFihAdOOsJL4PIc7Di/05sVjUxa9MGoqLgzjtt23vvZe55gzlwwJ5vdBYmxgsUMxcEkiuJV9WrVPUlVX3Vb5Ge7MTM4cgBROC33yyjRyD16kHp0jBihLkNhw+HV8P8d/bHzUaPNksklGUGsGhRmA6c+x5UvAT+vB2mXAF7VrJsmQmk79asVg06d4b/+z8LsMgqli+HlSstL2VWEVh1wFlmuZIZIlI/oydHUs8sVOTiLmC9urRWDkeWEhVlllF0tE3CTo0zz4Ry5eCTT2w9WMzOOMOut3hxuJvFWGDI0tdg0b/hhx84uP8Ozq1xLW3bNMH/W/eGG+C772DePLMmswJ/wndWui+dmzHX0wLoJSKrgUNYdRZV1Yii59MUMyw8vyGwyLt4XWAxUExEeqvqhAx12+FwhKRhw8iOE4GWLc16g5RiFhdnEY1hxQygQKylxKpxM8x7jPqJ7/DHs2/CvAqwvSvU7U+jRjUBmD//1BazLVvsO1F1YpZLuSQzJ0fiZlwDnKOqDVW1AXAOsBzoCETsz3Q4HFmP72qElNGMYONmqYqZT1xFjp07mFoPb+F/iz+Bci1h9RAYXYdqm2+hfrWVzJ8feb/++Sf1/SfLMqtWzT47MTu5iEgBEZkjIqO99SEislpE5nqtobddROQtEUkUkfki0jjcNVV1LVASuNxrJb1tERGJmNVV1RP/jFV1AZCgqompnONwOLKBVq1sGRNjofrB1Ktn41NHjqR9rVmzYM3G0yh61vXQ4kvovBrOuAdZ9znzn6/FHTXPh4XPw86FqV5n3jxzf06dGv6YQDHLqjlhW7eaaxVcAEg20A8IrgT9oGf0NFTVud62S4DaXusNhA0lEpF+wDAs92854FMRuSfSDkUiZktF5G0Rae61t7xthbAQSofDkUMkJNgE7Ph4Gx8Ltf/IkYCkxKngi48/iZu4CnDO69B5FSNXP8uB/cD8ATCmPvzUEtZ/B8ePpbjO8OEWRbkwFc3z+7N/f9ZZUVu2WAaU2FhnmZ1MRCQeuAz4XwSHdwE+9lI//gaUFJGKYY69FThfVQeq6kCgKfCvSPsViZjdCGwAHvHaRuAmTMjaRnojh8OR9URFWUTkxReH3p+QYMtIXI1Ll0LZslC+fNCOuIpsKDmAJo//zqamG6Hxa7B/HUztBt/Xhj/vhnXD4aCl4Pjey5YVzoV44IDt8wNc/vor7b6lxfHjlgGkfHkrw+PELMNEi8jMgNY7xDFvYEWbgwMAn/dcia97xg5AJSyTlM8Gb1soBAj86+iYty2yjqd1gKruBwZ5LRhnzDscOcwrr4Tfd+aZFhSxeDF07576dRITLbNIKPzq1XOXVaTiJffBGffAhm9h5Yc2trbiXZAodle4h8SlzwFFw4rZqlW2bNXKrLdAYcso//xj1mC5ck7MMslRVQ1byEhEOgFbVXWWiLQK2PUosBkoCLwPPAxElLkjgMHA7yLyrbfeFQtAjIg0LTMRaSoiY0VksYgs91s6O+lwOHKAwoWhevXILLMVK9IWsxPpsaKioUpPaD0OeuyADr9CzX9RfNObLHqpHte2GsOGDaEHw3wXoz/elxVBIH5YvhOzk05zoLOIrAG+ANqIyKequslzJR7CROk87/i/gMoB58d721Kgqq8BNwP/eO1mVX0j0o5F4mYcDPwHaAdcGNAcDkcuICEhzMTpAPbvN3dfODErVcrGo0JGNEbFQJmmcN5/uW/MNI5oEYb96zIGd6sFM/vBpp+Sja35YnbhhWY1ZqWYlS8PJUq4AJCThao+qqrxqloNS0I/UVWv98fBREQwi8ofMR0F3OhFNTYFdqnqpsBrikhxb1kai57/1GtrvW0REck8s92uhpnDkXtJSLDkxUeP2mTsUPgCE07MwKyz1MLz9+yB/3zdnIIV59Bk/1CK7hxF5bLvI8vfghIJlg+y8hUkJkZRurRZURUqZI2Y+dk/fMts9erMX9ORLoaJSFlsjGsucLu3fQxwKZAI7Mcsr2A+AzoBs4BAc1689RqRdCASMZsoIi8AI7BZ2QAEhus7HI5Tl4QESza8alVS6Howfv7GWrXCX+fss+Gnn+xaBQum3P/jj7bv0k6FmD27N/e/1JvtW/dTet9IWPgMTOsJpRpS8cjjnFG7G1CASpWcmzG3oqqTgcne5zZhjlHgrjSu08lbVs9MfyJxM7bw2mu4emYOR64jkohGX8zSssyOHEkqCBrMqFHmjmzePKlI6IZNhaHaNXDpQmj2MRzZy8A2PRlxS11I/ICqlY9EFM147JhFbX78cej9W7ZYZOdppyWJmatplrsQkRTZpEJtC0eaYqaqF4ZoLdPbUYfDkTP45WMWLTJX48CBlm8xkBUrbLzJL+4ZirO9DHnJaqR5HDsGP/wAl15qrsz4eNu+3g/KjioA1W/gUIelXPX2VxyPLg5/9OaZtp3ZvmV/smvt3GnXC+Sll2DoUKuxFoqtW21aQVSUidnhw1mbGNlx8hCRWG9srIyIlBKR0l6rRvgw/hSEFTMRucZb9g3VMvsADocjeyha1FJdTZ5sEYTPPguffgprAxIFpRbJ6FOnjmUaCTVu9scfsH07XH65rftiFuxCXLO2AF/91pOJMX/Cef9H3ZLj+az3pezduQcwEapTx3JO/v23nTNzpglw4cLw558WrBLMli1J8+NKlLClCwLJNfTBxsvO9JZ+G0k6vICpWWalvGXZMM3hcOQSEhKsavW8eTBggG0LTDeV2hwzn5gYs/JCidkvv9iyjTdyUqGCWUnBYuYHmtSqJVCrNzP4lBZ1plHgl/Zw6B9mzzYra8YMK1S6YAFcd51d7/33zbL87beU99+61cbLwCwzcONmuQVVfdMbL+uvqjVUtbrXGqhqxGIWNgBEVf/jLZ/Igv46HI4c5Morzep5910L8njrLZg2zYqD7t0LmzalHvzhU79+knAFMnWqTdAu6/2ZGx1tFbLDi5ktj1S6lh79CzPi/qtgXGNWrf0caMbw4dC7t1UQ8AuGNm5sAjllSpJo+mzdahUCwIlZbkVV3xaRs4AEIDZge5iR0uREUs+sDHALUC3weFUNlebE4XCcgvTqlbwQaPPmSZZZJGH5PmefDcOGWcaN0t4MoGPHYPp0E8xAKlcOLWbFi0OZMrYeHw8jZ3Vl7NEpXMbVXFX6Qjbc9Bzdr3iI+vWj6NnTMpf4+SIbNjQxCybQzejELHciIk8CrTAxG4MlKZ4GRCRmkUQzjgTKexedENAcDkcupUULi27cvj2ySEaf87y8DpMnJ21buNDGpy4MSqUQHx8QAOKRmGhWmXgZ9yp5w/vzNpyPXjyX0fO681CHR2FaT86oeYh582y8zKdlS6tOffhw0rZ9+6zlJjfj7t1WvmfmzJzuySlFDyzf72ZVvRloAJSI9ORIxKyIqj6gqp+p6pd+y2BnHQ7HKYAvPNOmRTbHzKdFC7Oq/IKgkGThhRKz4BIvvpj5xMVZOP2GDbByfQm6vvIFMw6+ButHwC+d4MjeZNds2dKiFANFIDD7B2RfAMjq1eYKDRTWSJkzxyxMf/zSAcABVT0OHPWygmwleSqsVIlEzMaKSIeM9s7hcJx6nHuuTXz2xaxiRYt6TIvoaOjWzTLj+6Hv06aZcAUXB42PN4vJF5UjR2DNmpSi6Yve9OkAQvHz7oOmg2HLRJjYHvYn+SpbtLBloKsxcMI0ZJ9l9uWX8MEHoacqpMXKlbYcP96EzQHATBEpCXyARTPOBn6N9ORIxOx2YJyI7BWRf0Rkh4ikUUfW4XCcysTGmstw6lQTs0isMp8ePSxo5McfzeqaOjUpz2IgweH5S5ZYNOKZZ6Y8bsMGE8WSJb1J3jV6QYvhsGM2fFcZfqgPs+6n7KHvadb4n1TFLC7OIi9PtpjNm2fLNWvSf25iov1hULw4DApVjyQfoqp3qupOVf0v0B64yXM3RkQkYlYGiMF8l2W9dRea73Dkci680KpLL14c2XiZT+vWlulj+HBztW3cmNLFCElZQPxxs/HjbRkcieintJo+3cLxTxQZrdwNLp0PDQdZodAV/4EpnZnxwGm83Lo+x1d8BCTlZfTdjCLZk9LKn6KQkTyQK1dCtWpwxx3w9deRFU/Nq4hI4+AGlMZqqzWO9DqpTZr2/3nXC9McDkcupkULs5R27EifmMXEQNeulr5qghcKFkrMgi2zceMstL9SpZTHbdtmllvz5kEXKV4HEh6CNj9ZqZl2vzCP59h3MI6oP2+FZe+ksMzAxs1OppgdPJiU1iujllmtWtCvn32fqdWkywe86rV3gd+xemgfeJ/fjfQiqVlmj3jLd0O0DOdmFJE6IjI3oO0WkXu99CU/icgKb1nKO15E5C0RSfSqmEas1A6HIzwXXJDkGkyPmIG5Gnftgn//26w0P/9jIBUrJpV42bvX3JGhKmL7ogchxCyQ6Dgo15LTWj5Oi6enkXiwK8y6hzN4h+LFzXXqU7LkyQ0AWbw4KeVWesVM1cSsZk37jm66CYYMgc2bs7qXuQNVba2qrYFNQGNVbaKq5wCNCFP7LBRhxUxVb/WWWZqbUVWXqWpDVW0InIOVBfgWE88JqlobC/33xfQSoLbXegPvZfTeDocjiZIlk/ItplfM2rY162fNGrPwokL8ksTEJJV4mTTJAkBSE7PoaAtMSYv4eKhdpyDn3f8lKw50pUe1e3jp2kfg4NZkzxbOMvv776Rq1xnFHy9LSEi/mG3fbqH5/jjl/ffDoUPw1VeZ61MeoI6qnginUdWFQN1IT45kzAwROVNErhCRa/2WgY6Goi2wUlXXAl2Aod72oViBN7ztH3tVTH8DSvqF4BwOR+Zo2dKEqGbN9J1XqBB07myf/QjDUPjBHePGQZEioS0vX8waN7b8i5EwejS0aFmQen2+5OOpN9DnwkHwXRX47VbYtTRVMXv4YWjWzFysGWX+fAs0adfOxszSk6E/OAvKGWeYi3Tu3Iz3J48wX0T+JyKtvPYBEHGpsTTFTEQGYD7M/2JW0hvY5Las4Grgc+9z+YAKpJuxidpgWZMDp15uIEQmZRHpLSIzRWTm0cz8K3U48hGPP27Z7osUSf+5119vbsQOqUzcqVzZAkDGjrXAj0KFUh4TH2/XSU0Ug6le3cbsvh1ZkEFTPuaVJYuhxs2w9nMYU59ejR7n4N4DIc9dvtwiICdNivx+wcyfb+N/NWta4mM/KXIk+GH5/h8QItCgQZK1F479++H48Yz1N5dwM7AI6Oe1xYQu5hkaVU21AQuAAsA8b70iMD6t8yK4bkHgb0zEAHYG7d/hLUcDLQK2TwCapHbtwoULq8PhOPls3pz6/r59VaOiVEH13XfDH/fdd6pbtmRBhw5sUZ1xo+owNPH1mqqrP1M9sC3ZIVWrWn9uuy1jtzh+XPW00+z8kSPtWn/8Efn5Tz2lKqJ64EDStgcfVC1YUPXw4dDn7N+vWr686qBBGetzpAD7NJO/7TnVInEzHlDVY9is7GKY1VQ1jXMi4RJgtqp6gbVs8d2H3tJ3gP9F8lng8aRjUNDhcJw8/HD4cMTHJ1kTocbLfLp0SR6NmGFiy0GzoXy6cQLHjkXBjGthRFkY0wDmPsqxHctORFeOGGHjeOll0yYb9zr7bAuvh/SNmyUm2vcSGLDSoIFlEglX+PT7720KQmasyVMVEfnKWy7wgvyStUivk2aiYWCONyv7I2AmsBv4I0O9Ts41iQg2PQAAGkJJREFUJLkYAUYBNwEvesuRAdvvFpEvgPOBXZrkjoyII0eOsH7dag4eCO12yI/ExsVRuUp1YmJicrorjjyMPx5Wu3ZSVvvsYGdsG+rdu4itS2ZS6tBEyyay5GUKLH6RyY83Z/aOG3nhk8uZOLEiHTum79q+O7BBg6SsJ+mZa7ZyZcpJ6g0b2nLuXDjrrJTnDBtmy1mzbHwueIJ6Lqeft+yUmYukKmYiIsBTqroTeFdExgPFVXV2Zm4qIkWwGd59Aja/CHwlIrcCawE/B/cY4FIgEYt8jNyH6rF+3Wri9B8qljyS1/4RZAhV2HnwAOvXQY2aZ+R0dxx5GF/MUrPKTgYlS8LRYzH8TTNKndUMznocDmxm7S+fUKbYh/St04e+TfuwatW5sOQqOOMuKBCb9oVJmixdv75FdJYqlX7LrGvX5Nvq1LHxxLlzbSwykH/+sTHHsmVtPt6GDUkT0vMCvnGiFgiYYVJ1M3o+1J8C1hMzK2Tedfap6mmquitg23ZVbauqtVW1nar+4/dBVe9S1ZqqWl9V051n+uCBA5SMdULmIwIlY484S9Vx0jnrLGvBP9Anm5D5GeMq8PvuB6n74BKW157P18ufZ8cOgTn9YXQCrP8uorDEefOgShUTMbBglEAxW7PGohz9zCSB7N5tghQcPRodbd9TqCCQr782d+jTT9v6rFlpdjFXISJ7vPnGwW2PiOyO9DqRjJnNFZFGmejrKYETsuS478ORHZQqZYl4/dIx2UW4zPmWWksoV7s+cU0eo8njv/N7kZ85JoVhajdWvX8hx5e+BXvD+w3nz0+anwc2bhYoZl98YZlRRoxIea4fyRgqF2bDhmaZBevpsGFW4fumm2waxexMmxOnFqpaTFWLh2jFVLV4pNdJLZ2V74JsBPwpIstEZLaIzBGRPPZ1Zg27du+lQ4++dOjRl/J1L6FDj770vv+FVM/5a9M2Xn7n07D77xvwRlZ30+HI84TLnL9uHRQrZmLXvr0tb3msLeV6zeXuIW9zaPd2omb3g1E1zFr7825Y9w0cstzqBw/C0qU2Xubji5kvQj95viw/F2Ug/hyzUPP6Gja0EP9NAREBa9da5pTrrrM5eAkJec8yC0ZEyolIFb9Fel5qY2Z/AI2BzpnuXT6hRPGi/Dj8LQDadLvrxGfAn1aABJlElSqW5cG7w/tgXn/u3pPQU4cjbxNOzNavt/EmERujuvJKK+PSvXs0tzx2N7ffdzd7NyUyedj3FNs7HlYPgRXvQlRBqH0nK44/yrFj5VJYZgcO2Ny1YsUs+3+BAmadHT5spXZ8gueYBeIL5Ny5cPrp9vlzL0Tummts2bixiWS4IJC77rJAmwceSM+3dWogIp2xHI2nY9HsVYElRJgLODU3owCo6spQLZP9zjc89dIH3P7Ai3S69gG2/r2DS666l3bd7+baPgM5fvw4K1dv4F/3/RuACzv14Y7+gzi/wy1MmPInYKIIcPM9z9Lvsddo3fVOXnzTEqX8NmshzS6+lV53P8MFl9yWMw/ocJyCpCVmPm+8Ydba8OEmFO+9BwvW1OLud+6D1uMsuXH76VD9Blj+Fmcur8GLVz9M0+qT4Og+wMbMwKyzKVNMwP71L8tH+WtQNa7ERJuCUKxYyj77AumPm6mai7FZs6RI0HPOsbG4jRtTnr9vH3z4YVJi51zIs0BTYLmqVscyRP0W6cmpWWZlReT+cDtV9bWIu3gK0f/JGsxflIF0BwGcXW8frzwdeXK3M2pV5b+vPsLx48f5duggYmMLMeDf/2Xqr3OJPz1pcs0/O3bz7GN92Lf/II8++x/atkyeqK5D6/N54/n7aHn57TzS7yZefGMoI4YOoljRwiRccHWmnsnhyEsULWrjS6HcjI0CIgAKF06eQishAR580BIo9+oFrVvHQNkLrNV9kJn/N5AHL3uZqBUvQWIBOO086pZ7HTifNWvgjz/MEnvySbP4xo+Hiy5Kun5wpe1ASpQwYfTTWg0ZAgsXmkD5nHOOLWfNSll9YOJEy/F42WWRf0+nGEdUdbuIRIlIlKpOEpGIx1lSs8wKAEWBYmGaI0Ian23h7/v2H6T3Ay/Svvs9jBo3lY1bkufAKVe2FGVKl6RShTLs2r03xXXq1amOiBAXazmB9u4/QMXyZShapDDVq6bI8OVw5FtETBwCA0AOHjRXYFph7QMGmCV0551JmfEBjhauw6X//pK+U7ZDqzGQ8Cjs30CNxAt4tucA1q05zE8/WVquChWsKkHwuFmoOWaB+EEgGzbAffdZ7sxevZLvFwkdBPLDDybiLTOcBj7H2SkiRYEpwDAReRPYF+nJqVlmm1T1mcz27lQjPRZVVhEl9jfDuIm/knBGNT5+90kef/49CIpaChxP0xAhwsHjbUULx7F563aKFS3M6rUuKYrDEUhwsmHf/ZaWmMXFwXPPwbXXWsaNdu1s+4wZdr3WHUvB6ZdYq9sfmX0vA7o+z+odo/mz8GM0ad8NiKFjRxPGrVvNtXjggPUhtaTODRvCd9+ZgB05Ah99lLwiQZEiVqk7OAhE1cSsffvkY3S5jC7AQeA+4DqsIHTEGpTmmJkj6zivcT2+GzOF7r0eYf3GrWmfkAaP3HsTV9z0MLf3H0TlSmnkFXI48hnBYuZXvK4SQXxct25m2X38cdK2H36wsjbt2wccWLAENB3MAyO/g6O7+KrvVdxbvSrMf4rL29gcYD+60V+mZpk1aGDCNGECvPhiaOE755yUYrZggQllbnQxisi7ItLcm398TFWPqupQVX1LVbdHfJ1QFoB3g9L+xOXcRpEiRXTfviTrdPHCedQoFfHcu1zD0aNHiY6OZs/e/XS98SEmjEhfzdRVO4qTcFaDtA90OHIhbdrYGNL06bY+dKhZPMuXR1a/rU8f+PRTK5pZrBjUq2fFNH/+OeWxPXvCiG+OcWWLcXz29LvIpnEoMGVZG5Yc7EW9jpfTsVMJatWyaMfiYWZPrV1r0ZEtW5pVGKpO3BtvmAty40brD8ALL8BjjyXflhFEZL+qZi6oIP337IdVUKkIfAV8rqpz0nud1Ipz5kohy09M/W0e7bvfQ4ce93D/HdfkdHccjlOKs86COXNM0CDJMgusbJ0aN91kZVe++cYiFRcvDm/5VKsGx7UAxytehrQeA51XIfWfom78Km5vcANN/yrD5AGtmf7hKxQ/OgeOHwt5napVTXS/+CK0kEHyIBCfH36waMzMCFlOoapvqmoz4CJgO/CRiCwVkSdFJOJ8exEV53ScmrRucQ4/ffM2v477kMvap1Zv3uHIf3ToYONU06bZ+vr1lt8wLi6y85s1M5fg0KEmFpC6mPn3BKBoNag/kLEFE2n+9DQG/9qfRvW2U2zFgzCuMXxTGiZdCquGwJHkwV433pi6KPlBIN9/by7J7dttCkB2uhhFpICXQGO0t15dRH4XkUQR+VJECnrbC3nrid7+auGuqaprVXWQqjbCEtF3xeaZRYQTM4fDkSdp1crGuH780dbXrUtfgl4RE5bJk+H99801eUYYO6FVKwv57xSU971nzyguvr45nQa8QEyX+dB1PVwwDKpeA3uWwW83w7cV4LdbYON4OHY4zX4VK2bu0vfft/6NHGlldrJ5vKwfyYVmEPC6qtYCdgC3ettvxWpT1gJe944LiYhEi8jlIjIMGAssA66ItENhx8xyM/llzCyzuDEzR16ndWvYsSOptErt2vDtt5Gfv2ZN0qToe++F11/Pws6pwrbpsGowrPsKju6FmOJw+mUQ3xUqdrQAkzCnPvccDBxo2UZKl7axvXCuyUiJZMxMROKBocDzwP3A5cA2oIKqHhWRZli1lY5epZWnVPVXL0XiZqCsBgiPiLTHLLFLscxTXwAjVTXisHxwlpnD4cjDdOxoGTU2b06/ZQbmPmzVyj5nueUjAuVaQNMP4Yqt0HIUVO4Bm3+C6VdZUdGJHWDr1JCnPvGEhfHHxUH37pkXMo9oEZkZ0HqHOOYN4CHAK7vKacBOVT3qrW8A/ImvlYD1AN7+Xd7xgTwKzADqqmpnVf0svUIGTsyylHbd72bnrj0n1vs/+RZTf52b4rgOPfpy9OhRPvlqLLPnJy8t+8lXY/nkq7Ehr79z1x6+G/PLiXWXhNjhSB1/DOubb2DPnozVAXv4YYuMvPDCrO1bMqLjIP5yE7Zum6HdVKhzL+xeChNawaIXQI+nOK1LF/jrL4twzCKOqmqTgPZ+4E4R6QRsVdUsS3esqm1U9X+quiMz13FiloVc0vYCxv6clIzt15kLueC8+mGPv+HKS2h8dp2Ir79r915Gjp1yYt0lIXY4UqdhQwv6+OADW49kjlkwF19s874KFcravoUlqoBZbI1egssWQZUrYd5jMLkT7JifIhKyePFs7Bs0BzqLyBrMHdgGeBMoGVBpJR7wszj8BVSGE5VYSmARi1mOE7MspOslLfn+RwudmrNgGWfXrclr731O++73cGGnPsxduDzZ8c+9+hETp87k8OEj9LzlUTpf15/R3vlHjhw9kZT46n8N4NixY3w47HsmTp1Jhx592bZ954kkxBOnzqTl5bfT8vLbmTjVapd26NGXh595h+aX9WbI56Oz8VtwOE4doqJskrOfvDfXVWiOKQYXfAbnvgdbJsDYBhYJObEjLH4Jdi2OqKBoVqGqj6pqvKpWw+aGTVTV64BJQA/vsJuAkd7nUd463v6JepICNVJLZ5UniU58i6i9iZm6xvGitThaq2+K7TWrx7Nx8zYOHjzEqHFT6XxJSy66oBEP3n09K1dv4NlXP2LIOwNTnDdq/FSaNKzLw31v5K6HXrZ+RhdgxJBBxMUV4qmXPmDy9Nncet3lrP9rC4PffiLZ+c+9NpjRn70KQOfr+9PmwiYAXHNFB555uDeXXXs/va4JCrNyOPIJHTvCZ5/Z54xYZjmOCNS+HSp1gi2TYNsM2DYN5j5srWgNqH0H1OkHUTE51cuHgS9E5DlgDuCnR/4Q+EREEoF/MAE8KeQ7MTvZtL3wXCZOm8XEqbN4pO+NfPL1WL749ieiJCpFbkWf1Ws30qCepSRodCIp8QHueugVNm7exta/d1Crejy1qoee7SkiFC9mAUgFChQ4sb1enRrExESfyA3pcORH/PRTBQrkzknFJygcb6Voqt9g6/vWw8YxsO5rmPMgrBoK5/2fZfjPBlR1MjDZ+7wKSFFPXFUPAj2zoz/5TsxCWVRZSZdLW9J/4FtUrlSOQoUK8v7Q7/ht/IesWvMXd3pWVzDVqlRkwZKVXNy2GfMWruC8xvX4afIf1K4Rz9B3B/LkoA9QhejoaI4dTzkIfPz4cXbvseCfYwFpvsNop8ORr6hY0WqF7dhhgpZnKFIZavextmEUzLwbfmoOZ94PjV/N6d5lO/lOzE42ZyfU4q9N27jthi4ANGlYl3bd76HF+eHnc3XueCHX9hnI5dc9QMkSVl3n3EYJvPT2J8yev4zixYpQq3o8FcqVZsfO3VzT+wneHfTgifMfv68Xl11jpecG9r815D0cjvzMCy/Atm053YuTSHxnKN8GFjxlbsd8iJs0nY9xk6YdDkcgOZFoOKtwgykOh8PhyPU4MXM4HA5HriffiFke9KZmCvd9OByOvES+ELPYuDh2HoxxP+AeqrDzYAyxkdbCcDgcjlOcfBHNWLlKddavgx07D+R0V04ZYuPiqFylek53w+FwOLKEfBHN6HA4HI60cdGMDofD4XDkIE7MHA6Hw5HryZNuRhE5DmRmgCwaOJrmUXmH/Pa84J45v+CeOX3EqWquNHLypJhlFhGZqapNcrof2UV+e15wz5xfcM+cf8iVCuxwOBwORyBOzBwOh8OR63FiFpr3c7oD2Ux+e15wz5xfcM+cT3BjZg6Hw+HI9TjLzOFwOBy5HidmDofD4cj1ODELQEQuFpFlIpIoIo/kdH9OBiJSWUQmichiEVkkIv287aVF5CcRWeEtS+V0X7MSESkgInNEZLS3Xl1Efvfe9ZciUjCn+5jViEhJERkuIktFZImINMvL71lE7vP+TS8Ukc9FJDYvvmcR+UhEtorIwoBtId+rGG95zz9fRBrnXM9PLk7MPESkAPAucAmQAFwjIgk526uTwlHgAVVNAJoCd3nP+QgwQVVrAxO89bxEP2BJwPog4HVVrQXsAG7NkV6dXN4ExqnqmUAD7Pnz5HsWkUpAX6CJqp4FFACuJm++5yHAxUHbwr3XS4DaXusNvJdNfcx2nJglcR6QqKqrVPUw8AXQJYf7lOWo6iZVne193oP9wFXCnnWod9hQoGvO9DDrEZF44DLgf966AG2A4d4heep5AUSkBNAS+BBAVQ+r6k7y8HvGMl/EiUg0UBjYRB58z6o6BfgnaHO499oF+FiN34CSIlIxe3qavTgxS6ISsD5gfYO3Lc8iItWARsDvQHlV3eTt2gyUz6FunQzeAB4CjnvrpwE7VdVP+ZMX33V1YBsw2HOv/k9EipBH37Oq/gW8AqzDRGwXMIu8/559wr3XfPO75sQsnyIiRYFvgHtVdXfgPrX5GnlizoaIdAK2quqsnO5LNhMNNAbeU9VGwD6CXIp57D2XwqyQ6sDpQBFSuuLyBXnpvaYHJ2ZJ/AVUDliP97blOUQkBhOyYao6wtu8xXc/eMutOdW/LKY50FlE1mCu4zbYWFJJzx0FefNdbwA2qOrv3vpwTNzy6ntuB6xW1W2qegQYgb37vP6efcK913zzu+bELIk/gdpe9FNBbPB4VA73Kcvxxos+BJao6msBu0YBN3mfbwJGZnffTgaq+qiqxqtqNeydTlTV64BJQA/vsDzzvD6quhlYLyJ1vE1tgcXk0feMuRebikhh79+4/7x5+j0HEO69jgJu9KIamwK7AtyReQqXASQAEbkUG18pAHykqs/ncJeyHBFpAUwFFpA0hvQYNm72FVAFWAtcqarBg8y5GhFpBfRX1U4iUgOz1EoDc4DrVfVQTvYvqxGRhljQS0FgFXAz9gdsnnzPIvI0cBUWsTsHuA0bH8pT71lEPgdaAWWALcCTwHeEeK+esL+DuVz3Azer6syc6PfJxomZw+FwOHI9zs3ocDgcjlyPEzOHw+Fw5HqcmDkcDocj1+PEzOFwOBy5HidmDofD4cj1ODFznFREREXk1YD1/iLyVBZde4iI9Ej7yEzfp6eXdX5S0PZqfuZyEWnoTe3IqnuWFJE7A9ZPF5HhqZ2Twfu8ISItReRbEZnrZVff5X2eKyIXZPU9vftWEJExJ+PajvyJEzPHyeYQcIWIlMnpjgQSkBUiEm4F/qWqrVM5piGQLjFLow8lgRNipqobVTVLhVtETgOaquoUVe2mqg2xuVlTVbWh12ako88R403q3i4i52fF9RwOJ2aOk81R4H3gvuAdwZaViOz1lq1E5BcRGSkiq0TkRRG5TkT+EJEFIlIz4DLtRGSmiCz38jD6tcteFpE/vRpOfQKuO1VERmHZIYL7c413/YUiMsjbNhBoAXwoIi+HekAvY8wzwFWeNXOViBQRqzv1h5fot4t3bC8RGSUiE4EJIlJURCaIyGzv3n6lhheBmt71Xg6yAmNFZLB3/BwRaR1w7REiMk6srtVLAd/HEO+5FoiI/y66A+PSeoEissF7B3OAbiJSW0TGi8gsEZkiImd4x5X37j/Te+6m3vY2IjLPe5bZYgmPwSb6XpfW/R2OiFBV11w7aQ3YCxQH1gAlgP7AU96+IUCPwGO9ZStgJ1ARKITlknva29cPeCPg/HHYH2W1sXyEsVjdpgHeMYWAmVgC2lZYwt3qIfp5OpYSqSyWpHci0NXbNxmrkxV8TjVgofe5F/BOwL5/Y9kmwKys5Vjy215eP0t7+6KB4t7nMkAiIIHXDnGvB7AMNQBnev2O9a69yvueY7FMEJWBc4CfAq5V0lsOBS4PeqZWwOigbRuA+wPWJwE1vc/NgR+9z19ill5wf8cC53ufiwIFvM9VgTk5/W/UtbzRssRl4HCkhqruFpGPseKJByI87U/1csiJyErgR2/7AiDQ3feVqh4HVojIKuzHvQNwdoDVVwITu8PAH6q6OsT9zgUmq+o2757DsHpg30XY32A6YAmO+3vrsViqITBh8VNICfBvEWmJpRerRNplWVoAbwOo6lIRWQuc4e2boKq7vGdYjAnGIqCGiLwN/EDSd1kRKxMTCV961yyJFXX9RkT8ff7vSDugTsD2UiISB0wH3vS+029Uda+3fyv2R4TDkWmcmDmyizeA2cDggG1H8VzdIhKF5RD0Ccyfdzxg/TjJ/90G52NTTCDuUdXxgTvEcjPuy1j3040A3VV1WVAfzg/qw3WYNXiOqh4Ry+4fm4n7Bn5vx4BoVd0hIg2AjsDtwJXALdgfFpHey++zAH+rja8FI8B5asVtA3nOc+1eBvwmIm1VdYV370j/uHE4UsWNmTmyBc8S+YrkZevXYC4wgM5ATAYu3VNEorxxtBrAMmA8cIdYqRtE5IyAcZpw/AFcJCJlRKQAcA3wSzr6sQcoFrA+HrhHPDNFRBqFOa8EVm/tiDf2VTXM9QKZijfW5I1XVcGeOyRe8E2Uqn4DDMBKwYBVGa+VxnMlQ1V3AJtEpJt37ShPKAF+Bu4KuG9Db1lTVeer6gvYHzR+Jv8zgIXpub/DEQ4nZo7s5FVsXMjnA0xA5gHNyJjVtA4TorHA7ap6EMsUvxiY7QVN/B9peCE8l+Yj2HjQPGCWqqanXMgkIMEPAAGexcR5vogs8tZDMQxoIiILgBuBpV5/tgPTvaCN4MCT/wBR3jlfAr009UzwlYDJIjIX+BR41Nv+AzZGll6uBm733tsioJO3/S6guRd0sxj4l7e9v/cc87ExVN/N2drrg8ORaVzWfIcjHyMi04BOqrozm+8rmIV5mT/G53BkBidmDkc+xhvDO6Cq87P5vuWxCMc8VwDXkTM4MXM4HA5HrseNmTkcDocj1+PEzOFwOBy5HidmDofD4cj1ODFzOBwOR67HiZnD4XA4cj3/D6gn+HlZIj+2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data     = pd.read_csv('simulate_survival.csv')\n",
    "    X        = data[['x1','x2','x3']]\n",
    "    y_lower  = data['left']\n",
    "    y_higher = data['right']\n",
    "\n",
    "    param    = {'n_estimators' : 100,'learning_rate': 0.01,'Nestrov' : False,'subsample': 0.5,'min_samples_split': 10,\n",
    "                 'max_depth': 2,'metrics':'logloss','dist':'normal','sigma':2,'random_state' : 0}\n",
    "\n",
    "    gb_manual = generate_result(X,y_lower,y_higher,param)\n",
    "    chart_creation(gb_manual,'Nesterov=False,Loss=LogLoss,Data=Mixed','Nesterov_False_Loss_LogLoss_Data_Mixed.png')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
