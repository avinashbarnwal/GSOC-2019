{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                                   as np\n",
    "import pandas                                  as pd\n",
    "import matplotlib.pyplot                       as plt\n",
    "import math\n",
    "import random\n",
    "from   sklearn                                 import ensemble\n",
    "from   sklearn                                 import datasets\n",
    "from   sklearn.utils                           import shuffle\n",
    "from   sklearn.metrics                         import mean_squared_error\n",
    "from   sklearn.datasets                        import load_boston\n",
    "from   sklearn.model_selection                 import cross_val_score\n",
    "from   sklearn.tree                            import DecisionTreeRegressor\n",
    "from   sklearn.model_selection                 import train_test_split\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stages\n",
    "from   sklearn.ensemble._gradient_boosting     import predict_stage\n",
    "from   abc                                     import abstractmethod\n",
    "from   scipy.special                           import expit\n",
    "from   sklearn.utils                           import check_array\n",
    "from   sklearn.tree._tree                      import DTYPE\n",
    "from   sklearn.tree._tree                      import TREE_LEAF\n",
    "from   scipy.special                           import logsumexp\n",
    "from   sklearn.utils                           import check_random_state\n",
    "from   sklearn.ensemble.gradient_boosting      import ZeroEstimator\n",
    "from   _aft_loss                               import loss, negative_gradient,hessian\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(object):\n",
    "    \n",
    "    \"\"\"Abstract base class for various loss functions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classes : int\n",
    "        Number of classes\n",
    "    Attributes\n",
    "    ----------\n",
    "    K : int\n",
    "        The number of regression trees to be induced;\n",
    "        1 for regression and binary classification;\n",
    "        ``n_classes`` for multi-class classification.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    is_multi_class = False\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        self.K = n_classes\n",
    "\n",
    "    def init_estimator(self):\n",
    "        \n",
    "        \"\"\"Default ``init`` estimator for loss function. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, y_lower, y_higher,pred,dist,sigma, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Compute the loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            True labels\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted labels\n",
    "        sample_weight : array-like, shape (n_samples,), optional\n",
    "            Sample weights.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def negative_gradient(self, y_lower, y_higher, pred,dist,sigma, **kargs):\n",
    "        \n",
    "        \"\"\"Compute the negative gradient.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array, shape (n_samples,)\n",
    "            The target labels.\n",
    "        pred : array, shape (n_samples,)\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_terminal_regions(self, tree, X, y_lower,y_higher, residual, y_pred, dist, sigma, sample_weight, sample_mask, learning_rate=1.0):\n",
    "        \n",
    "        \"\"\"Update the terminal regions (=leaves) of the given tree and\n",
    "        updates the current predictions of the model. Traverses tree\n",
    "        and invokes template method '_update_terminal_region'.\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : tree.Tree\n",
    "            The tree object.\n",
    "        X : array, shape (n, m)\n",
    "            The data array.\n",
    "        y : array, shape (n,)\n",
    "            The target labels.\n",
    "        residual : array, shape (n,)\n",
    "            The residuals (usually the negative gradient).\n",
    "        y_pred : array, shape (n,)\n",
    "            The predictions.\n",
    "        sample_weight : array, shape (n,)\n",
    "            The weight of each sample.\n",
    "        sample_mask : array, shape (n,)\n",
    "            The sample mask to be used.\n",
    "        learning_rate : float, default=0.1\n",
    "            learning rate shrinks the contribution of each tree by\n",
    "             ``learning_rate``.\n",
    "        k : int, default 0\n",
    "            The index of the estimator being updated.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute leaf for each sample in ''X''.\n",
    "        \n",
    "        terminal_regions                      = tree.apply(X)\n",
    "\n",
    "        # mask all which are not in sample mask.\n",
    "        masked_terminal_regions               = terminal_regions.copy()\n",
    "        masked_terminal_regions[~sample_mask] = -1\n",
    "\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            \n",
    "            self._update_terminal_region(tree, masked_terminal_regions,\n",
    "                                         leaf, X, y_lower, y_higher, residual, y_pred,dist,sigma, sample_weight)\n",
    "        \n",
    "        y_pred = y_pred + (learning_rate* tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
    "        return y_pred\n",
    "\n",
    "    @abstractmethod\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual,pred,dist,sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Template method for updating terminal regions (=leaves).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroEstimator:\n",
    "    \n",
    "    \"\"\"An estimator that simply predicts zero.\n",
    "    .. deprecated:: 0.21\n",
    "        Using ``ZeroEstimator`` or ``init='zero'`` is deprecated in version\n",
    "        0.21 and will be removed in version 0.23.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y_lower,y_higher,X_val, y_lower_val,y_higher_val, sample_weight=None):\n",
    "        \n",
    "        \"\"\"Fit the estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : numpy, shape (n_samples, n_targets)\n",
    "            Target values. Will be cast to X's dtype if necessary\n",
    "        sample_weight : array, shape (n_samples,)\n",
    "            Individual weights for each sample\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.issubdtype(y_lower.dtype, np.signedinteger):\n",
    "            # classification\n",
    "            self.n_classes = np.unique(y_lower).shape[0]\n",
    "            if self.n_classes == 2:\n",
    "                self.n_classes = 1\n",
    "        else:\n",
    "            # regression\n",
    "            self.n_classes = 1\n",
    "\n",
    "    def predict(self, X,X_val):\n",
    "        \"\"\"Predict labels\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : array, shape (n_samples,)\n",
    "            Returns predicted values.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, 'n_classes')\n",
    "\n",
    "        y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y.fill(0.0)\n",
    "        \n",
    "        y_val = np.empty((X_val.shape[0], self.n_classes), dtype=np.float64)\n",
    "        y_val.fill(0.0)\n",
    "        return y,y_val\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFT(LossFunction):\n",
    "    \"\"\"Cox Partial Likelihood\"\"\"\n",
    "\n",
    "    def __call__(self, y_lower, y_higher, y_pred, dist, sigma, sample_weight=None):\n",
    "        \"\"\"Compute the partial likelihood of prediction ``y_pred`` and ``y``.\"\"\"\n",
    "        # TODO add support for sample weights\n",
    "        return loss(y_lower, y_higher, y_pred.ravel(),dist, sigma)\n",
    "\n",
    "    def negative_gradient(self, y_lower, y_higher, y_pred,dist,sigma,k=0,sample_weight=None, **kwargs):\n",
    "        \"\"\"Negative gradient of partial likelihood\n",
    "        Parameters\n",
    "        ---------\n",
    "        y : tuple, len = 2\n",
    "            First element is boolean event indicator and second element survival/censoring time.\n",
    "        y_pred : np.ndarray, shape=(n,):\n",
    "            The predictions.\n",
    "        \"\"\"\n",
    "        ret = negative_gradient(y_lower, y_higher, y_pred.ravel(), dist, sigma)\n",
    "        if sample_weight is not None:\n",
    "            ret *= sample_weight\n",
    "        return ret\n",
    "\n",
    "    def init_estimator(self):  # pragma: no cover\n",
    "        return ZeroEstimator()\n",
    "\n",
    "\n",
    "    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y_lower,y_higher,\n",
    "                                residual, pred, dist, sigma, sample_weight):\n",
    "        \n",
    "        \"\"\"Least squares does not need to update terminal regions\"\"\"\n",
    "        \n",
    "        \"\"\"Make a single Newton-Raphson step.\n",
    "        our node estimate is given by:\n",
    "            sum(w * gradient) / sum(w * hessian)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        hess            = np.array(hessian(y_lower, y_higher, pred, dist, sigma))\n",
    "        terminal_region = np.where(terminal_regions == leaf)[0]\n",
    "        residual        = residual.take(terminal_region, axis=0)\n",
    "        hess            = hess.take(terminal_region, axis=0)\n",
    "        sample_weight   = sample_weight.take(terminal_region, axis=0)\n",
    "        pred            = pred.take(terminal_region, axis=0)\n",
    "\n",
    "        numerator       = np.sum(sample_weight * residual)\n",
    "        denominator     = np.sum(sample_weight * hess)\n",
    "\n",
    "        # prevents overflow and division by zero\n",
    "        \n",
    "        if abs(denominator) < 1e-2:\n",
    "            tree.value[leaf, 0, 0] = 0.0\n",
    "        else:\n",
    "            tree.value[leaf, 0, 0] = numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _random_sample_mask(n_total_samples,n_total_in_bag, random_state):\n",
    "    \n",
    "    \"\"\"Create a random sample mask where ``n_total_in_bag`` elements are set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_total_samples : int\n",
    "        The length of the resulting mask.\n",
    "\n",
    "    n_total_in_bag : int\n",
    "        The number of elements in the sample mask which are set to 1.\n",
    "        \n",
    "    random_state : np.RandomState\n",
    "        A numpy ``RandomState`` object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample_mask : np.ndarray, shape=[n_total_samples]\n",
    "         An ndarray where ``n_total_in_bag`` elements are set to ``True``\n",
    "         the others are ``False``.\n",
    "    \"\"\"\n",
    "    \n",
    "    #random_state = np.random.RandomState(random_state)\n",
    "    rand         = random_state.rand(n_total_samples)\n",
    "    sample_mask  = np.zeros((n_total_samples,), dtype=np.bool)\n",
    "    n_bagged     = 0\n",
    "    \n",
    "    for i in range(n_total_samples):\n",
    "        \n",
    "        if rand[i] * (n_total_samples - i) < (n_total_in_bag - n_bagged):\n",
    "            sample_mask[i] = 1\n",
    "            n_bagged += 1\n",
    "            \n",
    "    return sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Attributes and Parameters\n",
    "\n",
    "class BaseGradientBoosting():\n",
    "    \"\"\"Abstract base class for Gradient Boosting. \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self, loss, learning_rate, n_estimators, criterion,\n",
    "                 min_samples_split, min_samples_leaf, min_weight_fraction_leaf,\n",
    "                 max_depth, min_impurity_decrease, min_impurity_split,\n",
    "                 init, subsample, max_features,\n",
    "                 random_state, alpha=0.9, verbose=0, max_leaf_nodes=None,\n",
    "                 warm_start=False, presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None, Nestrov=False,dist='normal',sigma =1,\n",
    "                 tol=1e-4):\n",
    "        \n",
    "        #Initial = 1\n",
    "        self.n_estimators             = n_estimators + 1\n",
    "        self.learning_rate            = learning_rate\n",
    "        self.loss                     = loss\n",
    "        self.criterion                = criterion\n",
    "        self.min_samples_split        = min_samples_split\n",
    "        self.min_samples_leaf         = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.subsample                = subsample\n",
    "        self.max_features             = max_features\n",
    "        self.max_depth                = max_depth\n",
    "        self.min_impurity_decrease    = min_impurity_decrease\n",
    "        self.min_impurity_split       = min_impurity_split\n",
    "        self.init                     = init\n",
    "        self.random_state             = random_state\n",
    "        self.alpha                    = alpha\n",
    "        self.verbose                  = verbose\n",
    "        self.max_leaf_nodes           = max_leaf_nodes\n",
    "        self.warm_start               = warm_start\n",
    "        self.presort                  = presort\n",
    "        self.validation_fraction      = validation_fraction\n",
    "        self.n_iter_no_change         = n_iter_no_change\n",
    "        self.tol                      = tol\n",
    "        self.Nestrov                  = Nestrov\n",
    "        self.dist                     = dist\n",
    "        self.sigma                    = sigma\n",
    "\n",
    "    #Very Important loss class is defined here.\n",
    "    \n",
    "    def _init_state(self):\n",
    "        \n",
    "        self.estimators_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.fitted_        = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.prev_valid_    = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "        self.train_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.valid_score_   = np.zeros((self.n_estimators, ),dtype=np.float64)\n",
    "        self.random_state   = check_random_state(self.random_state)\n",
    "        \n",
    "        if self.Nestrov == True:\n",
    "            \n",
    "            self.g_fitted_      = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.g_prev_valid_  = np.empty((self.n_estimators, self.loss_.K),dtype=np.object)\n",
    "            self.lamb           = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma          = np.zeros((self.n_estimators,),dtype=np.float64)\n",
    "            self.gamma[0]       = 1\n",
    "            \n",
    "            for i in range(1,self.n_estimators):\n",
    "                self.lamb[i] = 0.5*(1+math.sqrt(1+4*self.lamb[i-1]**2))\n",
    "                \n",
    "            for i in range(1,self.n_estimators-1):\n",
    "                self.gamma[i] = (1-self.lamb[i])/self.lamb[i+1]\n",
    "                \n",
    "        \n",
    "        #do oob?\n",
    "        if self.init is None:\n",
    "            self.init_ = self.loss_.init_estimator()\n",
    "        elif isinstance(self.init, str):\n",
    "            self.init_ = INIT_ESTIMATORS[self.init]()\n",
    "        else:\n",
    "            self.init_ = self.init\n",
    "\n",
    "        \"\"\"Initialize model state and allocate model state data structures. \"\"\"\n",
    "\n",
    "        if self.subsample < 1.0:\n",
    "            self.oob_improvement_ = np.zeros((self.n_estimators),dtype=np.float64)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        \n",
    "        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n",
    "        \n",
    "        \n",
    "        if self.loss == 'aft':\n",
    "            self.loss_ =  AFT(1)\n",
    "            \n",
    "\n",
    "    def _fit_stage(self, i, X, y_lower, y_higher, sample_weight, sample_mask, random_state):\n",
    "        \n",
    "        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n",
    "        \n",
    "        assert sample_mask.dtype == np.bool\n",
    "        loss       = self.loss_\n",
    "        #original_y = y_lower\n",
    "        pred       = np.zeros((X.shape[0],self.loss_.K),dtype=np.float64)\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "            if self.Nestrov == True:\n",
    "                pred[:,k] = self.g_fitted_[i-1,k]    \n",
    "            else:\n",
    "                pred[:,k] = self.fitted_[i-1,k]\n",
    "        \n",
    "        for k in range(loss.K):\n",
    "   \n",
    "            residual = loss.negative_gradient(y_lower,y_higher,pred,self.dist,self.sigma,k=k,sample_weight=sample_weight)\n",
    "        \n",
    "            # induce regression tree on residuals\n",
    "            tree     = DecisionTreeRegressor(\n",
    "                                            criterion                 = self.criterion,\n",
    "                                            splitter                  = 'best',\n",
    "                                            max_depth                 = self.max_depth,\n",
    "                                            min_samples_split         = self.min_samples_split,\n",
    "                                            min_samples_leaf          = self.min_samples_leaf,\n",
    "                                            min_weight_fraction_leaf  = self.min_weight_fraction_leaf,\n",
    "                                            min_impurity_decrease     = self.min_impurity_decrease,\n",
    "                                            min_impurity_split        = self.min_impurity_split,\n",
    "                                            max_features              = self.max_features,\n",
    "                                            max_leaf_nodes            = self.max_leaf_nodes,\n",
    "                                            random_state              = random_state,\n",
    "                                            presort                   = self.presort\n",
    "                                            )\n",
    "\n",
    "            if self.subsample < 1.0:\n",
    "                # no inplace multiplication!\n",
    "                sample_weight = sample_weight * sample_mask.astype(np.float64)\n",
    "                \n",
    "\n",
    "            tree.fit(X, residual, sample_weight=sample_weight)\n",
    "\n",
    "            # update tree leaves    \n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                y_pred                  = self.g_fitted_[i-1,k]\n",
    "                self.fitted_[i,k]       = loss.update_terminal_regions(tree.tree_, X, y_lower, y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "                self.g_fitted_[i,k]     = (1-self.gamma[i-1])*self.fitted_[i,k]+self.gamma[i-1]*self.fitted_[i-1,k]\n",
    "                \n",
    "            else:\n",
    "                y_pred            = self.fitted_[i-1,k]\n",
    "                self.fitted_[i,k] = loss.update_terminal_regions(tree.tree_, X, y_lower,y_higher, residual, y_pred,self.dist,self.sigma,sample_weight, sample_mask,self.learning_rate)\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "    \n",
    "    def n_features(self):\n",
    "        return self.n_features_\n",
    "    \n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        self.classes_    = np.unique(y)\n",
    "        self.n_classes_  = len(self.classes_)\n",
    "        return y\n",
    "    \n",
    "    def _fit_stages(self, X, y_lower, y_higher,sample_weight, random_state,\n",
    "                    X_val, y_lower_val, y_higher_val,sample_weight_val,begin_at_stage=0):\n",
    "        \n",
    "        \n",
    "        n_samples    = X.shape[0]\n",
    "        do_oob       = self.subsample < 1.0\n",
    "        sample_mask  = np.ones((n_samples, ), dtype=np.bool)\n",
    "        n_inbag      = max(1, int(self.subsample * n_samples))\n",
    "        loss_        = self.loss_\n",
    "        \n",
    "        # create one-hot label encoding\n",
    "        pred     = np.zeros((n_samples, self.loss_.K), dtype=np.float64)\n",
    "        pred_val = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            pred[:,k] = self.fitted_[0,k]\n",
    "            pred_val[:,k] = self.prev_valid_[0,k]\n",
    "            \n",
    "        if do_oob:\n",
    "            \n",
    "            sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "            self.train_score_[0] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,sample_weight[sample_mask])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.train_score_[0] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,sample_weight)\n",
    "            \n",
    "            \n",
    "        self.valid_score_[0] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,sample_weight_val)\n",
    "\n",
    "        # perform boosting iterations\n",
    "        # validation loss performance\n",
    "        \n",
    "        for i in range(begin_at_stage, self.n_estimators):\n",
    "\n",
    "            # subsampling\n",
    "            if do_oob:\n",
    "                sample_mask = _random_sample_mask(n_samples, n_inbag, random_state)\n",
    "                #file_name   = \"sample_mask\" + str(i) + \".csv\"\n",
    "                #temp_date   = pd.DataFrame()\n",
    "                #temp_date['col'] = list(sample_mask)\n",
    "                #temp_date.to_csv(file_name)\n",
    "                \n",
    "                \n",
    "            # fit next stage of trees\n",
    "            self._fit_stage(i, X, y_lower,y_higher, sample_weight,sample_mask, random_state)\n",
    "\n",
    "            if self.Nestrov == True:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.g_prev_valid_[i-1,k].copy()\n",
    "                    \n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "\n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "                    \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.g_prev_valid_[i,k] = (1-self.gamma[i-1])*self.prev_valid_[i,k]+self.gamma[i-1]*self.prev_valid_[i-1,k]\n",
    "            else:\n",
    "                \n",
    "                score = np.zeros((X_val.shape[0], self.loss_.K), dtype=np.float64)\n",
    "                for k in range(self.loss_.K):\n",
    "                    score[:,k] = self.prev_valid_[i-1,k].copy()\n",
    "\n",
    "                predict_stage(self.estimators_, i, X_val, self.learning_rate, score)\n",
    "                \n",
    "                for k in range(self.loss_.K):\n",
    "                    self.prev_valid_[i,k] = score[:,k].copy()\n",
    "\n",
    "            for k in range(self.loss_.K):\n",
    "                \n",
    "                pred[:,k] = self.fitted_[i,k]\n",
    "                pred_val[:,k] = self.prev_valid_[i,k]\n",
    "            \n",
    "            if do_oob:\n",
    "                self.train_score_[i] = loss_(y_lower[sample_mask],y_higher[sample_mask],pred[sample_mask],self.dist,self.sigma,sample_weight[sample_mask])\n",
    "            else:\n",
    "                self.train_score_[i] = loss_(y_lower,y_higher,pred,self.dist,self.sigma,sample_weight)\n",
    "                \n",
    "                \n",
    "            self.valid_score_[i] = loss_(y_lower_val,y_higher_val,pred_val,self.dist,self.sigma,sample_weight_val)\n",
    "    \n",
    "        return i + 1\n",
    "\n",
    "    \n",
    "    def fit(self, X, y_lower,y_higher, sample_weight=None):\n",
    "        \n",
    "        # Check input\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        #y_lower                     = self._validate_y(y_lower, sample_weight)\n",
    "        #y_higher                    = self._validate_y(y_higher, sample_weight)\n",
    "        X                           = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        sample_weight               = np.ones(n_samples, dtype=np.float32)\n",
    "        \n",
    "        X, X_val, y_lower, y_lower_val,y_higher,y_higher_val,sample_weight, sample_weight_val \\\n",
    "        = train_test_split(X, y_lower,y_higher,sample_weight,random_state=self.random_state,test_size=self.validation_fraction)\n",
    "        self._check_params()\n",
    "        self._init_state()\n",
    "\n",
    "        # fit initial model - FIXME make sample_weight optional\n",
    "        #For Binomial       - init_ = LogOddsEstimator\n",
    "        #For Multinomial    - init_ = PriorProbabilityEstimator\n",
    "\n",
    "        self.init_.fit(X, y_lower,y_higher, X_val, y_lower_val,y_higher_val, sample_weight)\n",
    "        # init predictions and update in the inplace self\n",
    "        initial_pred,initial_val_pred  = self.init_.predict(X,X_val)\n",
    "        \n",
    "        for k in range(self.loss_.K):\n",
    "            self.fitted_[0,k], self.prev_valid_[0,k]          = initial_pred[:,k],initial_val_pred[:,k]\n",
    "            if self.Nestrov == True:\n",
    "                self.g_fitted_[0,k], self.g_prev_valid_[0,k]  = initial_pred[:,k],initial_val_pred[:,k]\n",
    "\n",
    "        begin_at_stage = 1\n",
    "        # fit the boosting stages\n",
    "        \n",
    "        n_stages = self._fit_stages(X, y_lower,y_higher, sample_weight, self.random_state,\n",
    "                                    X_val, y_lower_val,y_higher_val, sample_weight_val,begin_at_stage)\n",
    "        # change shape of arrays after fit (early-stopping or additional ests)\n",
    "        self.n_estimators_ = n_stages\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _make_estimator(self, append=True):\n",
    "        # we don't need _make_estimator\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def _init_decision_function(self, X):\n",
    "        \n",
    "        \"\"\"Check input and compute prediction of ``init``. \"\"\"\n",
    "        #self._check_initialized()\n",
    "        #X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
    "                self.n_features_, X.shape[1]))\n",
    "        score = self.init_.predict(X).astype(np.float64)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def _decision_function(self, X):\n",
    "        \n",
    "        # for use in inner loop, not raveling the output in single-class case,\n",
    "        # not doing input validation.\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        predict_stages(self.estimators_, X, self.learning_rate, score)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def _staged_decision_function(self, X):\n",
    "        \n",
    "        #X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        \n",
    "        score = self._init_decision_function(X)\n",
    "        for i in range(self.estimators_.shape[0]):\n",
    "            predict_stage(self.estimators_, i, X, self.learning_rate, score)\n",
    "            yield score.copy()\n",
    "    \n",
    "\n",
    "\n",
    "class GradientBoostingClassifier(BaseGradientBoosting):\n",
    "\n",
    "    _SUPPORTED_LOSS = ('survival')\n",
    "\n",
    "    def __init__(self, loss='aft', learning_rate=0.1, n_estimators=100,\n",
    "                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n",
    "                 max_depth=3, min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None, init=None,\n",
    "                 random_state=None, max_features=None, verbose=0,\n",
    "                 max_leaf_nodes=None, warm_start=False,\n",
    "                 presort='auto', validation_fraction=0.25,\n",
    "                 n_iter_no_change=None,Nestrov=False,dist='normal',sigma=1,tol=1e-4):\n",
    "\n",
    "        super().__init__(\n",
    "            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "            criterion=criterion, min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth, init=init, subsample=subsample,\n",
    "            max_features=max_features,\n",
    "            random_state=random_state, verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            warm_start=warm_start, presort=presort,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,Nestrov=Nestrov,\n",
    "            dist=dist,sigma=sigma,tol=tol)\n",
    "\n",
    "    def _validate_y(self, y, sample_weight):\n",
    "        #check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        n_trim_classes = np.count_nonzero(np.bincount(y, sample_weight))\n",
    "        if n_trim_classes < 2:\n",
    "            raise ValueError(\"y contains %d class after sample_weight \"\n",
    "                             \"trimmed classes with zero weights, while a \"\n",
    "                             \"minimum of 2 classes are required.\"\n",
    "                             % n_trim_classes)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return y\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        X = check_array(X, dtype=DTYPE, order=\"C\",  accept_sparse='csr')\n",
    "        score = self._decision_function(X)\n",
    "        if score.shape[1] == 1:\n",
    "            return score.ravel()\n",
    "        return score\n",
    "\n",
    "    #def staged_decision_function(self, X):\n",
    "    #    \n",
    "    #    yield from self._staged_decision_function(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "       \n",
    "        score     = self.decision_function(X)\n",
    "        decisions = self.loss_._score_to_decision(score)\n",
    "        return self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def staged_predict(self, X):\n",
    "       \n",
    "        for score in self._staged_decision_function(X):\n",
    "            decisions = self.loss_._score_to_decision(score)\n",
    "            yield self.classes_.take(decisions, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        score = self.decision_function(X)\n",
    "        try:\n",
    "            return self.loss_._score_to_proba(score)\n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        proba = self.predict_proba(X)\n",
    "        return np.log(proba)\n",
    "\n",
    "    def staged_predict_proba(self, X):\n",
    "       \n",
    "        try:\n",
    "            for score in self._staged_decision_function(X):\n",
    "                yield self.loss_._score_to_proba(score)\n",
    "                \n",
    "        except NotFittedError:\n",
    "            raise\n",
    "        except AttributeError:\n",
    "            raise AttributeError('loss=%r does not support predict_proba' %\n",
    "                                 self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "def data_creation(file_name,K=5):\n",
    "    \n",
    "    df_train   = pd.read_csv(file_name)\n",
    "    y          = list(df_train['Y'])\n",
    "    req_cols   = [i for i in df_train.columns if i != 'Y']\n",
    "    X          = np.array(df_train[req_cols])\n",
    "    y_median   = np.percentile(y, 50) # return 50th percentile, e.g median.\n",
    "    bin_y      = list(map(lambda x : 0 if x < y_median else 1,y))\n",
    "\n",
    "    percentile = np.percentile(y, np.arange(0, 100, 100/K)) # deciles\n",
    "    multi_y    = list(map(lambda x : 0 if x >= percentile[0] and x< percentile[1] else 1 if x >= percentile[1] and x< percentile[2] else 2 if x >= percentile[2] and x< percentile[3] else 3,y))\n",
    "    \n",
    "    return X,y,bin_y,multi_y\n",
    "\n",
    "def chart_creation(gb,chart_title,chart_name):\n",
    "    \n",
    "    min_valid = round(np.min(gb.valid_score_),4)\n",
    "    min_train = round(np.min(gb.train_score_),4)\n",
    "    min_iter  = round(np.nanargmin(gb.valid_score_),0)\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "                    'Min Train = %.2f' % (min_train, ),\n",
    "                    'Min Valid = %.2f' % (min_valid, ),\n",
    "                    'Min Iter  = %.2f' % (min_iter, )))\n",
    "\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5,edgecolor=\"black\")\n",
    "    \n",
    "    fig,ax1       = plt.subplots()\n",
    "    ax2           = ax1.twinx()\n",
    "\n",
    "    ln1 = ax1.plot(gb.train_score_,color='blue',label='Training')\n",
    "    ln2 = ax2.plot(gb.valid_score_,color='orange',label='Validation')\n",
    "    \n",
    "    #ax1.axvline(x=np.nanargmin(gb.valid_score_),color='r')\n",
    "    #ax2.axhline(y=np.min(gb.valid_score_),color='b')\n",
    "    lns = ln1 + ln2\n",
    "    \n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs, loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    \n",
    "    ax1.set_xlabel(\"Number of Iterations(Trees)\")\n",
    "    ax1.set_ylabel(\"Training Negative Likelihood(Loss)\")\n",
    "    ax2.set_ylabel(\"Validation Negative Likelihood(Loss)\")\n",
    "    #ax1.legend([\"Training\",\"Validation\"],loc='lower left',fancybox='round', facecolor='wheat',fontsize=8)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax2.text(0.7, 0.90, textstr, transform=ax1.transAxes, fontsize=8,\n",
    "        verticalalignment='top', bbox=props)\n",
    "    plt.title(chart_title)\n",
    "    plt.show()\n",
    "    fig.savefig(chart_name)\n",
    "    \n",
    "def generate_result(X,y_lower,y_higher,param):\n",
    "    \n",
    "    gb_manual = GradientBoostingClassifier(**param)\n",
    "    gb_manual.fit(X,y_lower,y_higher)\n",
    "    \n",
    "    return gb_manual    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data     = pd.read_csv('simulate_survival.csv')\n",
    "    X        = data[['x1','x2','x3']]\n",
    "    y_lower  = data['left']\n",
    "    y_higher = data['right']\n",
    "\n",
    "    param    = {'n_estimators' : 100,'learning_rate': 0.01,'Nestrov' : False,'subsample': 0.5,'min_samples_split': 10,\n",
    "                 'max_depth': 2,'dist':'normal','sigma':1,'random_state' : 0}\n",
    "\n",
    "    gb_manual = generate_result(X,y_lower,y_higher,param)\n",
    "    #gb_manual = generate_result(X,multi_y,param)\n",
    "    chart_creation(gb_manual,'Nesterov=False','Nesterov_False.png')\n",
    "    #chart_creation(gb_manual,'K=2,Nesterov=True','K_2_Nesterov_True.png')\n",
    "    #chart_creation(gb_manual,'K=5,Nesterov=False','K_5_Nesterov_False.png')\n",
    "    #chart_creation(gb_manual,'K=5,Nesterov=True','K_5_Nesterov_True.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
